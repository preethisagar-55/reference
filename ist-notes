--------notes   reference---------------------


-----------------------------------------opa------------------------------------------
def call(Map params = [:]) {
    def SEC_RESULTS
    try {
        dir('pac') {
            enaGit.checkoutRepo(
                sourceUrl: 'https://bitbucket.fi.dev/scm/tdodso/policy-as-code.git',
                branchName: 'master',
                credentialsId: "${params.credentialsId}",
                targetDirectory: '.'
            )
            sh 'ls -la'

            String FILENAME = sh(script: "ls | grep json", returnStdout: true).trim()
            def files = FILENAME.split('\n')
            def resultsFile = null

            files.each { file ->
                archiveArtifacts(artifacts: "${file}")
                if (file ==~ /.*_results\.json/) {
                    resultsFile = file
                }
            }

            if (resultsFile) {
                withCredentials([string(credentialsId: 'IST_EOPA_LICENSE_KEY', variable: 'EOPA_LICENSE_KEY')]) {
                    SEC_RESULTS = sh(script: """#!/bin/bash
                        set +e
                        export EOPA_LICENSE_KEY="${EOPA_LICENSE_KEY}"
                        output=\$(./eopa eval -d . "data.fi.pac.enterprise.asg.sdp.change_gate_report_status" --format=pretty -i ${resultsFile})
                        status=\$?
                        echo "STATUS: \$status"
                        echo "OUTPUT: \$output"
                    """, returnStdout: true).trim()
                }

                if (SEC_RESULTS) {
                    def lines = SEC_RESULTS.split("\n")
                    def statusLine = lines.find { it.startsWith("STATUS:") }

                    if (statusLine) {
                        def exitCode = statusLine.split(":")[1].trim().toInteger()
                        println "Exit Code: ${exitCode}"

                        def outputLines = lines.findAll { !it.startsWith("STATUS:") }
                        def output = outputLines.join("\n").replace("OUTPUT: ", "").trim()

                        if (exitCode == 0) {
                            def json = readJSON text: output
                            println "Json Output: ${json}"

                            def SASTStatus = json.evaluation_details.sast_status
                            def SCAStatus = json.evaluation_details.sca_status

                            echo "SASTStatus: ${SASTStatus}"
                            echo "SCAStatus: ${SCAStatus}"

                            def subject = "Security Scan Alert: Issues Found in ${params.cxProjectName}"
                            def body = """
                            Security scan detected issues in:
                            Project Name: ${params.cxProjectName}
                            CheckmarxOne Project: ${params.CheckmarxoneProjectname}
                            Exit Code: ${exitCode}

                            Please investigate the results.
                            """
                        } else {
                            echo "OPA command failed with exit code: ${exitCode}"
                            echo "OPA output: ${output}"
                            error("Build failed due to OPA command failure")
                        }
                    } else {
                        error("STATUS line not found in SEC_RESULTS.")
                    }
                } else {
                    error("SEC_RESULTS is null. OPA command might have failed.")
                }
            } else {
                error("resultsFile is null. No matching JSON file found.")
            }
        }
    } catch (Exception e) {
        echo "Exception occurred: ${e.getMessage()}"
        error("Build failed due to an exception")
    }
}


What is OPA?
OPA = Open Policy Agent

An open‚Äësource, general‚Äëpurpose policy engine.

Lets you define rules (‚Äúpolicies‚Äù) in a language called Rego.

You can then evaluate JSON data against those policies.

Commonly used for:

Policy‚Äëas‚ÄëCode (codifying compliance/security rules).

Kubernetes admission control.

CI/CD security gates (like here).

Cloud/IaC compliance checks.

üëâ In this pipeline, OPA is used to evaluate scan results JSON against enterprise security policies.
If the results violate rules, OPA returns a non‚Äëzero exit code ‚Üí Jenkins build fails.


---------------------------------------------------------------------------------------------

CheckmarxScan.groovy decides what to scan and what to ignore based on component type.

Writes a config file for Checkmarx.

Calls the Jenkins Checkmarx plugin to run the scan.

Ensures reports are generated and the build fails if vulnerabilities exceed thresholds.

‚öñÔ∏è Difference vs CheckmarxOne:

CheckmarxScan.groovy ‚Üí legacy SAST only, plugin‚Äëbased.

CheckmarxOneScan.groovy ‚Üí cloud API, unified scans (SAST + SCA + IaC).

CheckmarxScan.groovy (Classic SAST)
Logic executed:

Read parameters ‚Üí project name, branch, config, incremental flag.

Decide exclusions & filters based on component type (switch, mas, clearing).

Builds excludeFolders and filterPattern.

Write a config file (.checkmarx/cx.config) with SAST settings.

Trigger Jenkins plugin (CxScanBuilder) with:

Exclusions, filters, team path, project name.

Credentials to connect to the Checkmarx server.

Flags for incremental/full scan.

Generate PDF/HTML reports.

Fail build if vulnerabilities exceed thresholds.

Reports & IDs ‚Üí plugin generates reports, logs include Scan ID, pipeline extracts it.

üëâ Focus: Runs legacy Checkmarx SAST engine via Jenkins plugin.
üëâ Scope: Static code analysis only.

üîπ CheckmarxOneScan.groovy (Cloud‚Äënative CxOne)
Logic executed:

Read parameters ‚Üí project name, tag ID, project group, config.

Validate inputs ‚Üí ensures all required values are present.

Prepare environment:

Downloads ScaResolver CLI.

Sets SOURCE_PATH and ADDITIONAL_OPTIONS (project groups, tags, scan types, report formats).

Trigger Checkmarx One scan:

Uses Jenkins checkmarxASTScanner step.

Passes credentials (CXONE_SWITCH_API).

Calls cloud server (https://cxone.cloud).

Runs unified scan types (SAST, SCA, IaC depending on options).

Extract Scan ID ‚Üí parses Jenkins logs for CxOne Scan ID.

Archive results ‚Üí saves JSON, HTML, SBOM reports.

üëâ Focus: Runs Checkmarx One unified platform via API/CLI.
üëâ Scope: Broader ‚Äî not just SAST, but also open‚Äësource dependency analysis (SCA), IaC scanning, etc.

‚öñÔ∏è Key Logic Differences
Step	CheckmarxScan.groovy (SAST)	CheckmarxOneScan.groovy (CxOne)
Tooling	Jenkins plugin (CxScanBuilder)	CLI (ScaResolver) + Jenkins AST plugin
Scope	Static code analysis only	Unified scans (SAST + SCA + IaC)
Exclusions/Filters	Hard‚Äëcoded patterns per component type	Options passed via CLI (tags, groups)
Reports	PDF/HTML reports	JSON, HTML, SBOM (multi‚Äëformat)
Scan ID	Extracted from plugin logs	Extracted from AST logs
Server	Legacy Checkmarx server	Cloud‚Äënative Checkmarx One API
‚úÖ In Simple Terms
CheckmarxScan.groovy ‚Üí ‚Äúclassic‚Äù static analysis, plugin‚Äëdriven, focused on source code vulnerabilities.

CheckmarxOneScan.groovy ‚Üí modern cloud logic, CLI/API driven, covers multiple scan types, produces richer outputs.


üîπ Classic Checkmarx (SAST only)
Scope: Static code analysis only

What it does:

Examines your source code line by line.

Looks for insecure coding patterns (SQL injection, XSS, buffer overflows, etc.).

Runs against the codebase you commit into Jenkins.

Limitations:

Does not check open‚Äësource dependencies (libraries).

Does not analyze infrastructure or configuration files.

Focused purely on your own application code.

üîπ Checkmarx One (Unified scans)
Scope: Unified scans (SAST + SCA + IaC)

What it does:

SAST ‚Üí Same static code analysis as above.

SCA (Software Composition Analysis) ‚Üí Scans open‚Äësource libraries and dependencies for known CVEs (vulnerabilities).

IaC (Infrastructure as Code) ‚Üí Scans Terraform, Kubernetes YAML, CloudFormation, etc. for misconfigurations and insecure defaults.

Can also include API security and container scanning depending on setup.

Strength:

Gives a holistic view of risk: not just your code, but also the libraries you use and the way you deploy infrastructure.

Cloud‚Äënative, integrates multiple scan types in one run.

‚öñÔ∏è Side‚Äëby‚ÄëSide
Feature	Classic Checkmarx (SAST)	Checkmarx One (Unified)
Scope	Static code only	Code + dependencies + infra
Scan Types	SAST	SAST + SCA + IaC (and more)
Coverage	Application source code	Full software supply chain
Output	Vulnerabilities in code	Vulnerabilities in code, libraries, infra configs
Deployment	On‚Äëprem / plugin	Cloud‚Äënative platform
‚úÖ In simple terms:

Checkmarx (SAST) = ‚Äúlook at my code only.‚Äù

Checkmarx One = ‚Äúlook at my code, my libraries, and my infrastructure together.‚Äù



Checkmarx/CheckmarxOne Groovy files ‚Üí run scans, produce results.

CxFlowIntegration.groovy ‚Üí takes those results and turns them into actionable Jira tickets automatically.


üîπ What CxFlowIntegration.groovy Adds
CxFlowIntegration.groovy uses the cx‚Äëflow jar ‚Äî a tool from Checkmarx designed to integrate scan results directly into issue trackers like Jira or GitHub Issues.

Bridges the gap between security scans and project management.

Automatically creates or updates Jira tickets when vulnerabilities are found.

Assigns tickets to the right team or user (assignee parameter).

Adds context (project name, app version, team path) so developers know exactly where the issue came from.

Archives ticket info back into Jenkins for traceability.


What Checkmarx/CheckmarxOne Groovy Files Do
CheckmarxScan.groovy ‚Üí runs a SAST scan (static code analysis) against your source code.

CheckmarxOneScan.groovy ‚Üí runs a Checkmarx One unified scan (SAST + SCA + IaC, etc.).

Both produce security findings (lists of vulnerabilities, severity levels, reports).

üëâ But by themselves, they only generate results inside Jenkins or Checkmarx dashboards. They don‚Äôt automatically connect those findings to your issue‚Äëtracking workflow.


CheckmarxScan.groovy ‚Üí runs the traditional SAST scan.

CheckmarxOneScan.groovy ‚Üí runs the newer Checkmarx One unified scan.

CxFlowIntegration.groovy ‚Üí uses the cx‚Äëflow jar to bridge scans with Jira tickets, automatically creating/updating issues based on findings.

-------------------------------------------------checkmarxscan groovy-------------------------------------------------

package fi.scan

class CheckmarxScan implements Serializable {

    def call(Map params) {
        def script = params.script
        def cxProjectName = params.cxProjectName
        def configval = params.configval
        def isIncrementalScan = params.isIncrementalScan

        def swComponentType = configval.swComponentType ?: ""
        def excludeFolders = ""
        def filterPattern = ""

        switch (swComponentType) {
            case "switch":
                excludeFolders = "bdir,pdir,release_info,sdir,buildlog,gitroot,nighty_checkmarxone_tgz,checkcommit,bldir"
                filterPattern = getSwitchFilterPattern()
                break

            case "mas":
                excludeFolders = "bdir,pdir,release_info,sdir,buildlog,gitroot,nighty_checkmarxone_tgz,checkcommit,bldir"
                filterPattern = getMasFilterPattern()
                break

            case "clearing":
                excludeFolders = "bdir,pdir,release_info,sdir,buildlog,gitroot,nighty_checkmarxone_tgz,checkcommit,bldir,test,w3c_libwww,fcgi,xmlrpc_c,xmlapi_engine,xmlapi_xmlrpc,bin_file_name,bld_template"
                filterPattern = getClearingExtraFilter()
                break

            default:
                script.error("Checkmarx scan failed: Unsupported or missing swComponentType '${swComponentType}'. Please check configuration.")
        }

        def configContent = '''{
          "sast": {
            "multiLanguageMode": 2,
            "languageThreshold": 0.0
          }
        }'''
        script.writeFile file: '.checkmarx/cx.config', text: configContent
        script.step([
            $class: 'CxScanBuilder',
            excludeFolders: excludeFolders,
            exclusionsSetting: 'job',
            filterPattern: filterPattern,
            generatePdfReport: true,
            generateHtmlReport: true,
            teamPath: 'CxServer\\SP\\fi\\BankingSolutions\\Retail Payments - Intl\\ISTApps',
            incremental: isIncrementalScan ? 'true' : 'false',
            jobStatusOnError: 'FAILURE',
            preset: '100000',
            configuration: 'Multi-language Scan - AbsInt Disabled',
            projectName: "${cxProjectName}",
            teamId: "653",
            sastEnabled: true,
            sourceEncoding: '2',
            vulnerabilityThresholdEnabled: true,
            vulnerabilityThresholdResult: 'FAILURE',
            serverUrl: 'https://fi.checkmarx.net',
            useOwnServerCredentials: true,
            credentialsId: 'IST-CheckMarx',
            comment: "${script.env.BRANCH_NAME}_${configval.RELEASE_FILE}_${cxProjectName}_${configval.selectedOsName}",
            waitForResultsEnabled: true,
            configAsCode: true
        ])
    }

    private String getSwitchFilterPattern() {
        return '''!**/_cvs/**/*, !**/export:BLD_CREDENTIALS*, 
        	!**/export:JAVA_HOME*, !**/export:ORACLE_HOME*, !**/export:PGSQLPATH*, !**/export:PGSQL_HOME*,
            !**/.hg/**/*, !**/.git/**/*, !**/*profile**, !**/*.jar,
            !**/obj/**/*, !**/*README*, !**/*pkg**, !**/*Jenkinsfile,
            !**/*Readme.Md, !**/*.gitignore, !**/*.tmp, !**/*.txt, !**/*.dll,
            !**/*.mpa, !**/*.tgz, !**/*.xml, !**/*.m4, !**/*.la, !**/*.hpp, !**/*.swf,
            !**/*.tar.gz, !**/*.zip, !**/*.tar, !**/*.gz, !**/configure_fast/*,
            !**/*.war, !**/site/*, !**/configure/*, !**/*.db2, !**/*.yaml, !**/*.yml,
            !**/*.log, !**/*.json, !**/*.so, !**/*.in, !**/*.sl, !**/*.a,
            !**/exclude/*, !**/*demo*/*, !**/test/*, !**/tests/*, !**/*.rel,
            !**/INSTALL, !**/*NOTES, !**/NEWS, !**/COPYING, !**/*.release, !**/*.sh,
            !**/misc/*, !**/*.pm, !**/*.scr, !**/*.class, !**/*.list, !Checkmarx/Reports/*.*'''
    }

    private String getMasFilterPattern() {
        return getSwitchFilterPattern() // Same as switch for now
    }

    private String getClearingExtraFilter() {
        return '''!**/*insysbal.cxx*, !**/*HelperWrapper.cxx*,
            !**/*xercesc_lib-0.2.7*, !**/*xalanc_lib-0.0.8*, !**/*jsoncpp_lib*,
            !**/*openssl_lib-1.0.10*, !**/*p1t_lib/*, !**/*openssl_lib/*,
            !**/*xercesc_lib/*, !**/*xalanc_lib/*, !**/*jsoncpp_lib/*,
            !**/*w3c_libwww/*, !**/*fcgi/*, !**/*xmlrpc_c/*, !**/*xmlapi_engine/*,
            !**/*xmlapi_xmlrpc/*, !**/*bin_file_name/*, !**/*bld_template/*,
            !**/*.am, ''' + getSwitchFilterPattern()
    }
}
-------------------------------------------cxone-------------------------------
package fi.scan

class CheckmarxOneScan implements Serializable {

    def call(Map params) {
        def script = params.script
        def configval = params.configval
        def cxOneProjectName = params.cxOneProjectName
        def cxonetagId = params.cxonetagId
        def cxOneProjectGroup = params.cxOneProjectGroup

        // Validate required parameters
        if (!script || !configval || !cxOneProjectName || !cxonetagId || !cxOneProjectGroup) {
            error "Missing one or more required parameters: script, configval, cxOneProjectName, cxonetagId, cxOneProjectGroup"
        }

        script.echo "Checkmarx One scan is starting..."

        script.dir("${script.env.WORKSPACE}/checkmarx_One") {
            // Download and extract ScaResolver
            script.sh """
                curl -L https://sca-downloads.s3.amazonaws.com/cli/latest/ScaResolver-linux64.tar.gz -o ScaResolver-linux64.tar.gz
                tar -xzvf ScaResolver-linux64.tar.gz
                rm ScaResolver-linux64.tar.gz
                chmod +x ScaResolver
            """

            def scaResolverPath = script.sh(script: 'realpath ScaResolver', returnStdout: true).trim()
            script.env.SOURCE_PATH = "${script.env.WORKSPACE}/nighty_checkmarxone_tgz"
            script.env.ADDITIONAL_OPTIONS = """--project-groups ${cxOneProjectGroup} --project-tags scid:${cxonetagId} -s \$SOURCE_PATH --sca-resolver "${scaResolverPath}" --sast-preset-name "ASA-Default" --scan-types sca --tags ${cxonetagId} --report-format json,summaryHTML,SBOM --output-name cx_result"""

            try {
                script.withCredentials([script.usernamePassword(credentialsId: 'OPA_CXONE_SWITCH', passwordVariable: 'cx_secret', usernameVariable: 'cx_client')]) {
                    // Run the actual scan using Jenkins plugin
                    script.checkmarxASTScanner additionalOptions: script.env.ADDITIONAL_OPTIONS,
                        branchName: "${script.env.BRANCH_NAME}",
                        checkmarxInstallation: 'CxASTCLI',
                        credentialsId: 'CXONE_SWITCH_API',
                        projectName: "${cxOneProjectName}",
                        serverUrl: 'https://fi.cxone.cloud',
                        tenantName: 'fi',
                        useOwnAdditionalOptions: true,
                        useOwnServerCredentials: true

                    def output = script.currentBuild.rawBuild.getLog(10000).join("\n")
                    def scanId = script.extractCxOneScanId(output)
                    if (scanId) {
                        script.echo "Extracted CxOne Scan ID: ${scanId}"
                      	script.env.CXONE_PROJECT_NAME = "${cxOneProjectName}"
						script.env.CHECKMARXONE_SCAN_ID = "${scanId}"
                    }
                }
            } catch (err) {
                script.echo "Error in CxOne Scan: $err"
                script.currentBuild.result = (script.getCheckmarxBranchType() == 'develop') ? 'UNSTABLE' : 'FAILURE'
            } finally {
                script.archiveArtifacts "cx_result*"
                script.env.CXONE_ARCHIVED = 'cx_result*'
            }
        }
    }
}          
/*          
            // Stash the PDF report
            if (script.fileExists("${script.env.WORKSPACE}/checkmarx_One/cx_result.pdf")) {
                script.stash name: 'cxone-ast-results', includes: 'cx_result.pdf', allowEmpty: false
            } else {
                script.error("File cx_result.pdf does not exist.")
            }
        }
    }
}*/


----------------------------------------cxflowintegration-----------------------------
package fi.scan

class CxFlowIntegration implements Serializable {

    def call(Map params) {
        def script = params.script
        def configval = params.configval
        def cxProjectName = params.cxProjectName
        def jiraTicket = params.jiraTicket

        // Credentials passed from Jenkinsfile
        def vaultUser = params.vaultUser
        def vaultPassword = params.vaultPassword
        def checkmarxUser = params.checkmarxUser
        def checkmarxPasswd = params.checkmarxPasswd

        def CXFLOW_JAR = "cx-flow-1.7.11.jar"
        def CXFLOW_PATH = "${script.env.WORKSPACE}/cxflow"

        script.sh "mkdir -p ${CXFLOW_PATH}"

        // Download cx-flow jar using vault credentials
        script.sh """
            curl -u ${vaultUser}:${vaultPassword} -o ${CXFLOW_PATH}/${CXFLOW_JAR} \\
            https://artifactory.fi.dev/artifactory/emeaistswitch-generic-snapshot-local/cxflow/${CXFLOW_JAR}
            chmod +x ${CXFLOW_PATH}/${CXFLOW_JAR}
        """

        script.dir("checkmarx_flow_execution") {
            def appYaml = "${script.env.WORKSPACE}/Jenkins/cxflow_params.yml"
            def checkmarxflowJarPath = "${CXFLOW_PATH}/${CXFLOW_JAR}"
            def checkmarxflowParams = [
                teamPath: 'CxServer\\SP\\fi\\BankingSolutions\\Retail Payments - Intl\\ISTApps',
                appName: "Version-${configval.RELEASE_FILE}",
                projectName: "${cxProjectName}",
                scanners: "sast",
                javaHome: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.392.b08-4.el8.x86_64",
                assignee: jiraTicket
            ]

            def teamPathFormatted = checkmarxflowParams.teamPath.replaceAll('\\\\', '/')

            script.sh """
                java -jar '${checkmarxflowJarPath}' --project --spring.config.location='${appYaml}' \\
                --checkmarx.username='${checkmarxUser}' --checkmarx.password='${checkmarxPasswd}' \\
                --jira.token='token' \\
                --cx-team='${teamPathFormatted}' \\
                --cx-project='${checkmarxflowParams.projectName}' \\
                --assignee='${checkmarxflowParams.assignee}' \\
                --app='${checkmarxflowParams.appName}'
            """
        }

        // Extract and archive JIRA ticket info
        def consoleOutput = script.currentBuild.rawBuild.getLog(1000000).join("\n")
        def (updatedJiraTickets, newJiraTickets) = script.extractJiraTickets(consoleOutput)

        def filePath = "${script.env.WORKSPACE}/jira_tickets_${script.env.BUILD_NUMBER}.txt"
        def fileContent = ""

        fileContent += updatedJiraTickets ? "Updated JIRA tickets:\n${updatedJiraTickets.join("\n")}\n" : "No updated JIRA tickets found.\n"
        fileContent += newJiraTickets ? "Newly created JIRA tickets:\n${newJiraTickets.join("\n")}" : "No new JIRA tickets were created."

        script.writeFile file: filePath, text: fileContent
        script.echo "JIRA ticket numbers have been written to ${filePath}"
        script.archiveArtifacts artifacts: "jira_tickets_${script.env.BUILD_NUMBER}.txt", allowEmptyArchive: true
    }
}
------------------------------------------------nightly-build groovy-------------------------------------------------
import fi.ist.*
import groovy.json.JsonOutput
import java.util.TimeZone
import java.util.Date
import java.text.SimpleDateFormat
def extractCxScanId(String logText) {
    def matcher = logText =~ /Scan ID is \s*(\d+)/
    return matcher ? matcher[0][1] : null
}
def extractCxOneScanId(String logText) {
    def matcher = logText =~ /Wait for scan to complete (\S+)/
    return matcher ? matcher[0][1] : null
}
def extractJiraTickets(consoleOutput) {
    def updatedJiraTickets = []
    def newJiraTickets = []
    def updateMatcher = consoleOutput =~ /Updating JIRA issue #(ISTDEV-\d+)/
    while (updateMatcher.find()) {
        updatedJiraTickets << updateMatcher.group(1)
    }
    def newIssueMatcher = consoleOutput =~ /New issue created. #(ISTDEV-\d+)/
    while (newIssueMatcher.find()) {
        newJiraTickets << newIssueMatcher.group(1)
    }
    return [updatedJiraTickets, newJiraTickets]
}
def extractOsInfo(consoleOutput) {
    def matcher = consoleOutput =~ /INFO: OS \[([^\]]*)\]/
    def osInfo = matcher ? matcher[0][1] : null
    if (osInfo == null) {
        error("OS information not found. Failing the pipeline.")
    }
    return osInfo
}
def call(Map configval = [:]){
    echo "Inside agentBuildPipeline.groovy ...."
  	def jobNameParts = JOB_NAME.tokenize('/') as String[]
    def jobNamePart = "${jobNameParts[2]}/${jobNameParts[3]}"
    def datas
    def emailRecipients
    def allowedUsers  
    def failedStage = ''
    def errorMessage = ''
  	def releaseInfoContent = ""
    String PathVar, os_dir, myArtifact
  	def opaPodTemplate = fetchResources.getpodAgents()
  	def foCommitFound
  	def CmpCommitFound
    def triggerTimeEDT = new Date()
    def triggerTimeISTStr
  	def triggerTimeEDTStr
   	def releaseFile = params.RELEASE_FILE
    pipeline {
        agent { 
            node {
              		label configval.selectedOsValue
                    customWorkspace "workspace/" + WsSetup( jobNamePart: "${jobNamePart}" ) 
            }
        }
        environment {
          SOURCE_BRANCH = "${env.CHANGE_BRANCH ?: env.BRANCH_NAME}"
        }
        options {
            timestamps()
            buildDiscarder(logRotator(numToKeepStr: '10', artifactNumToKeepStr: '10'))
            copyArtifactPermission('*')
        }
        stages {
           stage('Set Java and Oracle Home') {
                steps {
                    script {
                      	/*echo 'Cleaning up the default workspace...'
                        WsSetup(cleanup: true, days: 2, jobNamePart: "${jobNamePart}")*/
                        SimpleDateFormat edtFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
                        edtFormat.setTimeZone(TimeZone.getTimeZone("America/New_York"))
                        triggerTimeEDTStr = edtFormat.format(new Date()) // Assign value
                        env.TRIGGER_TIME_EDT = triggerTimeEDTStr
                        triggerTimeISTStr = ocpEmailConfig.convertEDTtoIST(triggerTimeEDTStr)
                        env.TRIGGER_TIME_IST = triggerTimeISTStr
                        echo "triggerTimeISTStr: ${triggerTimeISTStr}"
                        echo "triggerTimeEDTStr: ${triggerTimeEDTStr}"
                      	def params = readYaml file: './Jenkins/params.yaml'
                        def javaVersion
                        def oracleVersion
                        if (configval.buildcomponent == 'nighty_build') {
                            currentBuild.description = "${configval.RELEASE_FILE}:${configval.selectedOsName}"
                        } else {
                            currentBuild.description = "${configval.selectedOsName}"
                        }
                        if (configval.buildcomponent == 'nighty_build') {
                            switch (configval.selectedOsName) {
                                case 'RHEL8':
                                    javaVersion = params.RHEL8[0].java_version
                                    oracleVersion = params.RHEL8[1].oracle_version.toUpperCase()
                                    break
                            	case 'RHEL9':
                                    javaVersion = params.RHEL9[0].java_version
                                    oracleVersion = params.RHEL9[1].oracle_version
                                    break
                                case 'AIX7.3':
                                    javaVersion = params.'AIX7.3'[0].java_version
                                    oracleVersion = params.'AIX7.3'[1].oracle_version
                                    break
                                case 'AIX7.2':
                                    javaVersion = params.'AIX7.2'[0].java_version
                                    oracleVersion = params.'AIX7.2'[1].oracle_version.toUpperCase()
                                    break
                                default:
                                    error "Unsupported OS: ${configval.selectedOsName}"
                            }
                            if (!javaVersion || !oracleVersion) {
                                error "Java or Oracle version not found for OS: ${configval.selectedOsName}"
                            }
                        } else {
                            javaVersion = params.java_version.toString()
                            oracleVersion = params.oracle_version.toString().toUpperCase()
                        }
                        echo "Parsed java_version: ${javaVersion}"
                        echo "Parsed oracle_version: ${oracleVersion}"
                        def javaEnvVar = "JAVA_" + javaVersion + "_HOME"
                        def oracleEnvVar = "ORACLE_HOME_" + oracleVersion
                        def javaPath = sh(script: "echo \$${javaEnvVar}", returnStdout: true).trim()
                        def oraclePath = sh(script: "echo \$${oracleEnvVar}", returnStdout: true).trim()
                        if (!javaPath || javaPath == "\$${javaEnvVar}") {
                            error "Environment variable '${javaEnvVar}' is not set or not visible to the pipeline shell."
                        }
                        if (!oraclePath || oraclePath == "\$${oracleEnvVar}") {
                            error "Environment variable '${oracleEnvVar}' is not set or not visible to the pipeline shell."
                        }
                        env.java_home = javaPath
                        env.oracle_home = oraclePath
                    }
                }
            }
            stage('Get PR Author email') {
                when {
                    expression { return env.CHANGE_ID != null }
                }
                steps {
                    script {
                        ocpEmailConfig.getPRAuthorEmail()
                    }
                }
            }
            stage('Setup') {
                steps {
                    script {
                        println "Setting Parameters"
                        try {
                            String MyOS = sh(script: "uname -s", returnStdout: true).trim()
                            String kernelVersion = sh(script: "uname -r", returnStdout: true).trim()

                            if (MyOS == "Linux") {
                                new CppBuild().env_linux()
                                os_dir = "lin"

                                if (kernelVersion.startsWith("5.14")) {
                                    PathVar = "/share/istprod_india/e1014306/bin/RHEL9:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/usr/bin/bison:/usr/bin:.:/Osrc8/tools/bin:/Osrc8/local/bin/_LINUX2.6_i386/bin:/usr/bin/git:/usr/bin/curl:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home3/istrcc/snmp_bin:$PATH"
                                    println "Linux Build with Kernel 5.14 detected..."
                                } else {
                                    PathVar = "${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/Osrc8/local/bin/_LINUX2.6_i386_13/bin:/usr/bin:/Osrc/tools/bin:/Osrc/oracle/lin64_ora_199:$JAVA_HOME:$CLASSPATH:/usr/share/bcc/tools:/usr/local/lib64:/usr/lib64:/usr/lib:$PATH"
                                    println "This is a Linux Build for RHEL 8 ..."
                                }

                                if (configval.selectedOsName == "RHEL8ISTRCC") {
                                    PathVar = "/home3/Osrc/local/bin/_LINUX2.6_i386/bin:/home3/Osrc/tools/bin:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/Osrc/oracle/lin64_ora_199:$JAVA_HOME:$CLASSPATH:/usr/share/bcc/tools:/usr/local/lib64:/usr/lib64:/usr/lib:/home3/istrcc/snmp_bin:$PATH"
                                    PGSQL_HOME = "/usr/lib64\nPGSQL"
                                    PGSQLPATH = "17.4\nPGSQL-17.4"
                                    println "Custom PathVar and PGSQL paths set for RHEL8ISTRCC"
                                }
                            } else if (MyOS == "SunOS") {
                                os_dir = "sol"
                                PathVar = ""
                                println "This is a Solaris Build ..."
                            } else if (MyOS == "AIX") {
                                new CppBuild().env_aix()
                                os_dir = "aix"
                                String AIXVersion = sh(script: "oslevel", returnStdout: true).trim()
                                echo "Detected AIX version: ${AIXVersion}"

                                if (AIXVersion.startsWith("7.3")) {
                                    PathVar = "/opt/freeware/lib64:/home3/istrcc/BUILD/AIX-730/build/pdir/lib:/home3/istrcc/BUILD/AIX-730/build/pdir/bin:/share/istprod_india/e1014306/bin/AIX/:/share/istprod_india/e1014306/bin/AIX//curl:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/home3/Osrc/local/bin/_AIX4.2_risc6000/bin:/home3/Osrc/tools/bin:/usr/java8_64/bin:/opt/IBM/openxlC/17.1.1/bin/:/opt/freeware/bin:/usr/bin:/etc/:/usr/sbin:/usr/ucb:/usr/bin/X11:/sbin:/usr/java7_64/jre/bin:/usr/java7_64/bin:/usr/boksm/bin:/opt/freeware/bin:/opt/IBM/openxlC/17.1.1/bin:/opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10"
                                    echo "This is an AIX 7.3 Build ..."
                                } else if (AIXVersion.startsWith("7.2")) {
                                    PathVar = "/Osrc/local/bin/_AIX5.3_risc6000/bin:/opt/IBM/xlc/13.1.3/bin:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/Osrc/tools/bin:/Osrc/oracle/aix64_ora_1911:/usr/share/bcc/tools:/usr/lib64:/usr/lib:/opt/freeware/lib:${env.PATH}"
                                    echo "This is an AIX 7.2 Build ..."
                                } else {
                                    echo "Unknown AIX version: ${AIXVersion}"
                                }
                                echo "Final PathVar: ${PathVar}"
                            } else if (MyOS == "HP-UX") {
                                os_dir = "hpux"
                                PathVar = ""
                                println "This is a HP-UX Build ..."
                            } else {
                                error "Unknown Operating System. Will not build."
                            }

                            datas = readYaml file: "./Jenkins/params.yaml"
                            //datares = readYaml text: libraryResource('fi/IST/Parameters.yaml')

                            def component = configval.swComponent?.toLowerCase()
                            def buildType = configval.buildType?.toLowerCase()
                            def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')
                            def useBranchBuildList = false

                            switch (component) {
                                case "pr":
                                case "switch":
                                case "fo":
                                    if (buildType == "development") {
                                        def readContent = readFile './Jenkins/branch-build.list'
                                        writeFile file: './Jenkins/branch-build.list',
                                            text: readContent + "\n${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                        echo "Updated branch-build.list for ${component} with ${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                        useBranchBuildList = true
                                        env.release_file_name = './Jenkins/branch-build.list'
                                    } else {
                                        echo "Release file will be passed as an input to build script for ${component}."
                                    }
                                    break
                                case "mas":
                                case "clearing":
                                    if (buildType == "development") {
                                        def readContent = readFile './Jenkins/branch-build.list'
                                        writeFile file: './Jenkins/branch-build.list',
                                            text: readContent + "\n${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                        echo "Updated branch-build.list for ${component} with ${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                        useBranchBuildList = true
                                        env.release_file_name = './Jenkins/branch-build.list'
                                    } else if (buildType == "release") {
                                        echo "Release file will be passed as an input to build script for ${component}."
                                    } else {
                                        echo "Unknown build type for ${component}. Defaulting to release file."
                                    }
                                    break
                                case "nighty_build":
                                    env.release_file_name = "${configval.RELEASE_FILE}.release"
                                    echo "Collected release file name from ${configval.RELEASE_FILE} for nightly build."
                                    break
                                default:
                                    echo "Unknown or unsupported swComponent: ${component}. Defaulting to release file."
                                    break
                            }
                        } catch (Exception e) {
                            println e
                            currentBuild.result = 'FAILURE'
                        }
                    }
                }
            }

            stage('Check commit and Update Release File') {
                when {
                    expression { configval.buildcomponent == 'nighty_build' }
                }
                steps {
                    script {
                        try {
                            def isManualTrigger = currentBuild.rawBuild.getCause(hudson.model.Cause$UserIdCause) != null
                            def isTimerTrigger = !isManualTrigger
                            echo "isManualTrigger: ${isManualTrigger}"
                            echo "isTimerTrigger: ${isTimerTrigger}"
                            def releaseFileName = env.release_file_name

                            if (isManualTrigger) {
                                echo "Manual trigger detected..."
                                foCommitFound = true
                                CmpCommitFound = false
                                env.foCommitFound = foCommitFound
                                env.CmpCommitFound = CmpCommitFound

                                def fullBuildCheckboxSelected = "${configval.FULL_BUILD_CHECKBOX}"
                                if (!fullBuildCheckboxSelected) {
                                    error("Full build checkbox not selected. Failing the pipeline.")
                                } else {
                                    echo "Full build checkbox selected. Updating release file..."
                                    def releaseFileContent = readFile(releaseFileName)
                                    releaseFileContent = releaseFileContent.replaceFirst(/(?m)^BUILDOPT=/, 'FORCE=1\nBUILDOPT=')
                                    writeFile file: releaseFileName, text: releaseFileContent
                                    echo "Updated release file content:\n${releaseFileContent}"
                                    checkRecentCommits.checkRecentCommitForManualTrigger(releaseFileName)
                                }

                            } else if (isTimerTrigger) {
                                echo "Timer trigger detected..."
                                datas1 = readYaml file: "./Jenkins/params.yaml"
                                def result = checkRecentCommits([
                                    project_repo: datas1.Project_repo,
                                    releaseFileName: releaseFileName,
                                    BITBUCKET_BASE_URL: datas1.BITBUCKET_BASE_URL,
                                    FOUNDATION_BITBUCKET_BASE_URL: datas1.FOUNDATION_BITBUCKET_BASE_URL,
                                    REL_BITBUCKET_BASE_URL: datas1.REL_BITBUCKET_BASE_URL,
                                    BITBUCKET_CREDENTIALS_ID: datas1.BITBUCKET_CREDENTIALS_ID
                                ])
                                foCommitFound = result.foCommitFound
                                CmpCommitFound = result.CmpCommitStatus
                                env.foCommitFound = foCommitFound
                                env.CmpCommitFound = CmpCommitFound

                                if (!foCommitFound && CmpCommitFound.isEmpty()) {
                                    echo "No commit found in the last 24 hours for the release file: ${env.release_file_name}"
                                    currentBuild.result = 'SUCCESS'
                                    env.SKIP_STAGE_NOCOMMIT = 'true'
                                    return
                                }

                            } else {
                                error("Unknown trigger type. Failing the pipeline.")
                            }

                            if (foCommitFound && !CmpCommitFound) {
                                env.trigger = "FullTrigger"
                            } else if (!foCommitFound && CmpCommitFound) {
                                env.trigger = "PartialTrigger"
                            } else {
                                env.trigger = "NoTrigger"
                            }

                            echo "env.trigger: ${env.trigger}"

                        } catch (Exception e) {
                            echo "Error occurred in 'Check commit and Update Release File' stage: ${e.getMessage()}"
                          	currentBuild.result = 'FAILURE'
                        }
                    }
                }
            }
            stage('Download dependency') {
                when { expression { return env.SKIP_STAGE_NOCOMMIT != 'true' } }
                steps {
                    script {
                        try {
                            println "Stage: Download dependency repos."
                            dir('gitroot') {
                                BUILD_TYPE = params.BUILD_TYPE
                                new CppBuild().downloaddependency(
                                    project_repo: "${datas.Project_repo}",
                                    gitCreds: "cm-credentials-id"
                                )
                            }
                        } catch (Exception e) {
                            echo "Error occurred in Download dependency stage: ${e.getMessage()}"
                          	currentBuild.result = 'FAILURE'
                        }
                    }
                }
            }
          
            stage('Build') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                    IST_TOOLS = "${env.WORKSPACE}/gitroot/ist-build-tools"
                    PATH = "${PathVar}"
                }
                when {
                    expression { return env.SKIP_STAGE_NOCOMMIT != 'true' }
                }
                steps {
                    println "Stage: Build the Artifact."
                    script {
                        try {
                            def component = configval.swComponent?.toLowerCase()
                            def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')
                            def repoName = jobNameParts[3]?.toLowerCase()
                            def skipZipPrefixes = ['develop/SW', 'develop/CL', 'develop/MA', 'develop/']
                            def shouldSkipZip = skipZipPrefixes.any { env.BRANCH_NAME?.startsWith(it) }

                            myArtifact = new CppBuild().build(
                                artFile: "${jobNameParts[2]}/${env.BRANCH_NAME.replaceAll('/', '_')}/${BUILD_NUMBER}",
                                build_Flags: "${datas.build.Flags}",
                                os: "${os_dir}",
                                java_home: "${env.java_home}",
                                oracle_home: "${env.oracle_home}",
                                releasefile: (params.productname == 'ist-release-info') ?
                                    sh(script: "cat ${GITROOT}/ist-release-info/rel_info/build.release", returnStdout: true).toString().trim() :
                                    "${env.release_file_name}",
                                ArtCred: "svcacct_istartifact"
                            )

                            if (myArtifact != "NoArtifact") {
                                  def artifactFiles = myArtifact.split(',').findAll { it?.trim() }.collect { "\"${it}\"" }.join(' ')
                                  if (artifactFiles) {
                                      sh "cp ${artifactFiles} ${env.WORKSPACE}"
                                  } else {
                                      println "No valid artifact files to copy."
                                  }
                                println "Component value: ${component}"
                                println "isPRBuild value: ${isPRBuild}"
                                println "repoName value: ${repoName}"

                                def filesToZip = []
                                if (artifactBuildTgz.shouldRenameArtifacts(component, isPRBuild, repoName)) {
                                    println "Inside the rename artifacts if condition"
                                    def (version, buildTag) = artifactBuildTgz.extractVersionAndBuildTag(env)
                                    filesToZip = artifactBuildTgz.renameArtifacts(myArtifact, version, buildTag, env, configval)
                                } else {
                                    filesToZip = artifactBuildTgz.collectTgzFiles(env, component)
                                }

                                if (!isPRBuild && !shouldSkipZip) {
                                    if (filesToZip) {
                                        artifactBuildTgz.zipArtifacts(filesToZip, configval, env)
                                    } else {
                                        error("No artifact generated.")
                                    }
                                } else {
                                    println "Skipping zipping artifacts for PR build or specific develop branches."
                                }
                            }
                        } catch (e) {
                            echo "Build stage failed:"
                            e.printStackTrace()
                            throw e
                        }
                    }
                }
            }

            stage('Upload to Artifactory') {
				when {
					expression {
						if (configval.buildcomponent == 'nighty_build' && env.SKIP_STAGE_NOCOMMIT != 'true') {
							echo 'Detected Nighty Build and SKIP_STAGE_NOCOMMIT is not true'
							return true
						} else if (env.BRANCH_NAME.startsWith('PR') || env.BRANCH_NAME.startsWith('feature-PR')) {
							echo 'Stage skipped because branch is PR or feature'
							return false
						} else if (configval.buildcomponent == 'nighty_build' && env.SKIP_STAGE_NOCOMMIT == 'true') {
							echo 'Stage skipped because no commit found'
							return false
						} else if (env.BRANCH_NAME.startsWith('develop/SW_') || 
								   env.BRANCH_NAME.startsWith('develop/CL_') || 
								   env.BRANCH_NAME.startsWith('develop/MA_')) {
							echo 'Running the stage because branch is develop/SW_, develop/CL_, or develop/MA_'
							return true
						} else {
							echo 'Stage skipped because none of the conditions were met'
							return false
						}
					}
				}
                steps {
					script {
						try {
							def datas2 = readYaml file: "./Jenkins/params.yaml"
							def zipFilesPath = sh(script: "ls ${env.WORKSPACE}/*.zip | awk -F'/' '{print \$NF}'", returnStdout: true).trim().toString()
							def tgzFilesPath = sh(script: "ls ${env.WORKSPACE}/*.tgz | awk -F'/' '{print \$NF}'", returnStdout: true).trim().toString()
							def zipFiles = zipFilesPath ? zipFilesPath.split('\n') : []
							def tgzFiles = tgzFilesPath ? tgzFilesPath.split('\n') : []
							def buildType = "development"
							def repoUrl = datas2.artifactory.Path
							def zipSubPath = "rel_zip/release"
                          	def tgzSubPath = "rel_tgz/release/${os_dir}"
							if (zipFiles.size() == 0 && tgzFiles.size() == 0) {
								echo "No zip or tgz files found!"
							} else {
								zipFiles.each { zipFile ->
									echo "Uploading zip artifact: ${zipFile}"
									new OcpCppBuild().artifactUploadZip([
										artifactPath: zipFile,
										repoUrl: repoUrl,
										buildType: buildType,
										subPath: zipSubPath,
										artifactory: datas2.artifactory
									])
								}
								tgzFiles.each { tgzFile ->
									echo "Uploading tgz artifact: ${tgzFile}"
									new OcpCppBuild().artifactUploadTgz([
										artifactPath: tgzFile,
										repoUrl: repoUrl,
										buildType: buildType,
										subPath: tgzSubPath,
										artifactory: datas2.artifactory
									])
								}
							}
						} catch (Exception e) {
							failedStage = 'Upload to Artifactory'
							errorMessage = e.getMessage()
							throw e
						}
					}
				}
			}
            stage('Triggering Harness CD Pipeline') {
                steps {
                    script {
                        if (configval.buildcomponent == 'nighty_build') {
                            if (env.SKIP_STAGE_NOCOMMIT == 'true') {
                                echo 'Skipping the triggering CD pipeline due to no commit found'
                            } else {
                                if (currentBuild.result == 'SUCCESS' || currentBuild.result == null) {
                                    def params = readYaml file: './Jenkins/params.yaml'

                                    // Enhanced logic: match release file first, then OS name
                                    def projectName = params.PROJECT_NAME.find { entry ->
                                        def parts = entry.split(':')
                                        def releaseFileMatch = parts.size() > 0 && parts[0] == configval.RELEASE_FILE
                                        def osNameMatch = parts.size() > 1 && parts[1] == configval.selectedOsName
                                        return releaseFileMatch && osNameMatch
                                    }

                                    def harnessUrl = params.HarnessCdPipelineTriggerUrl
                                    echo "Project Name: ${projectName}"
                                    echo "Harness URL: ${harnessUrl}"

                                    if (projectName) {
                                        def parts = projectName.split(':')
                                        def Agent_Name = parts.size() > 3 ? parts[3] : null
                                        def User_Account = parts.size() > 4 ? parts[4] : null
                                        echo "Agent Name: ${Agent_Name}"
                                        echo "User Account: ${User_Account}"

                                        if (Agent_Name && User_Account) {
                                            def payload = """
                                            {
                                                "ARTIFACT_NAME": "${env.ZIP_NAME}",
                                                "TARGET_SERVER": "${Agent_Name}",
                                                "USER_ACCOUNT": "${User_Account}"
                                            }
                                            """
                                            sh """
                                            echo 'Sending payload to Harness:'
                                            echo 'Harness trigger Url ----> ${harnessUrl}'
                                            curl -X POST -H 'content-type: application/json' --url '${harnessUrl}' -d '${payload}'
                                            """
                                        } else {
                                            echo 'Skipping CD pipeline as AGENT_NAME and USER_ACCOUNT are not provided in params.yaml'
                                        }
                                    } else {
                                        echo "No matching project found for releaseFile: ${configval.RELEASE_FILE} and OS: ${configval.selectedOsName}"
                                    }
                                } else {
                                    echo 'Skipping payload send as the build is not successful.'
                                }
                            }
                        } else {
                            echo 'Skipping the triggering CD pipeline this is Not Nighty Build'
                        }
                    }
                }
            }
            stage('Checkmarx') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                    PATH = "$PATH:/data/jenkins/workspace/gitroot/ist-build-tools/autobase/scripts:/Osrc8/tools/bin:$ORACLE_HOME:$JAVA_HOME:$GITROOT:/usr/share/bcc/tools:/root/testing:/Osrc8/local/bin/_LINUX2.6_i386_13/bin:/usr/lib64:/usr/lib"
                }
                steps {
                    script {
                        try {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxProjectNameParams = config.cxscan.isCxProjectName
                            def cxProjectName = "IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev"
                            env.isCheckmarxScan = config.cxscan.isCheckmarxScan.toString()
                            env.isOpaEnable = config.opaScan.isOpaEnable.toString()

                            if (configval.buildcomponent == 'nighty_build' &&
                                env.SKIP_STAGE_NOCOMMIT != 'true' &&
                                env.isCheckmarxScan == 'true' &&
                                configval.selectedOsName == 'RHEL8') {

                                def dayOfWeek = new Date().format('u').toInteger()
                                def isIncrementalScan = !(dayOfWeek == 5)

                                withCredentials([
                                    usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
                                ]) {
                                    sh """
                                        printf "$JENKINS_USER\n$JENKINS_PASSWORD\n" > export:BLD_CREDENTIALS
                                        export USERID=$JENKINS_USER
                                        export USERACCESS=$JENKINS_PASSWORD

                                        if grep -q '^sw_base:' ${env.WORKSPACE}/${configval.RELEASE_FILE}.release; then
                                            sw_base_branch=\$(grep '^sw_base:' ${env.WORKSPACE}/${configval.RELEASE_FILE}.release | cut -d':' -f2)
                                            sed -i "s|^sw_segment:master|sw_segment:\${sw_base_branch}|" ${env.WORKSPACE}/${configval.RELEASE_FILE}.release
                                        fi

                                        grep -E '(:|_OS_)' ${env.WORKSPACE}/${configval.RELEASE_FILE}.release | grep -Ev 'OS_DB|OS_ZCLOPTMZD' > ${env.WORKSPACE}/${configval.RELEASE_FILE}.rel
                                        echo "Filtered Release File:"
                                        cat ${env.WORKSPACE}/${configval.RELEASE_FILE}.rel

                                        ${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts/build_checkmarx_jk.ksh -bt=develop ${env.WORKSPACE}/${configval.RELEASE_FILE}.rel
                                    """
                                }

                                def scanner = new fi.scan.CheckmarxScan()
                                scanner.call([
                                    script: this,
                                    cxProjectName: cxProjectName,
                                    configval: configval,
                                    isIncrementalScan: isIncrementalScan
                                ])

                                archiveArtifacts artifacts: 'Checkmarx/Reports/*.html', allowEmptyArchive: true
                                archiveArtifacts artifacts: 'Checkmarx/Reports/*.pdf', allowEmptyArchive: true

                                def checkmarx_scanOutput = currentBuild.rawBuild.getLog(10000).join("\n")
                                def checkmarx_scanId = extractCxScanId(checkmarx_scanOutput)

                                if (checkmarx_scanId) {
                                    echo "Extracted CxOne Scan ID: ${checkmarx_scanId}"
                                } else {
                                    echo "No Scan ID found in Checkmarx logs"
                                }

                                env.CHECKMARX_SCAN_ID = checkmarx_scanId
                              	env.CX_PROJECT_NAME = "${cxProjectName}"
                            } else {
                                echo 'Skipping Checkmarx stage due to unmet conditions'
                            }
                        } catch (Exception e) {
                            echo "Error occurred in Checkmarx stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            // Optionally: throw e to fail the build immediately
                        }
                    }
                }
            }
            stage('Checkmarx One') {
                steps {
                    script {
                        try {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxOneProjectNameParams = config.cxonescan.isCxOneProjectName
                            def cxOneProjectName = "IST_NightlyBuilds_${cxOneProjectNameParams}_${configval.RELEASE_FILE}_dev"
                            def cxonetagId = config.cxonescan.tagId
                            def cxOneProjectGroup = config.cxonescan.projectGroup
                            env.isCheckmarxOneScan = config.cxonescan.isCheckmarxOneScan.toString()

                            if (configval.buildcomponent == 'nighty_build' &&
                                env.SKIP_STAGE_NOCOMMIT != 'true' &&
                                env.isCheckmarxOneScan == 'true' &&
                                configval.selectedOsName == 'RHEL8') {

                                def scanner = new fi.scan.CheckmarxOneScan()
                                scanner.call([
                                    script: this,
                                    configval: configval,
                                    cxOneProjectName: cxOneProjectName,
                                    cxonetagId: cxonetagId,
                                    cxOneProjectGroup: cxOneProjectGroup
                                ])
                            } else {
                                echo 'Skipping Checkmarx One stage due to unmet conditions'
                            }
                        } catch (Exception e) {
                            echo "Error occurred in Checkmarx One stage: ${e.getMessage()}"
                          	currentBuild.result = 'FAILURE'
                        }
                    }
                }
            }
            stage('Policy-As-Code') {
                when {
                    allOf {
                        expression { configval.buildcomponent == 'nighty_build' }
                        expression { env.SKIP_STAGE_NOCOMMIT != 'true' }
                        expression { env.isOpaEnable == 'true' }
                        expression { configval.selectedOsName == 'RHEL8' }
                    }
                }
                agent {
                    kubernetes {
                        cloud 'devsecops-enablement'
                        yaml opaPodTemplate
                    }
                }
                steps {
                    container('jnlp') {
                        script {
                            sh "mkdir pac"
                            def eopaPath = "./eopa"
                            dir('pac') {
                                checkout([$class: 'GitSCM',
                                    branches: [[name: 'master']],
                                    extensions: [],
                                    userRemoteConfigs: [[
                                        credentialsId: 'cm-credentials-id',
                                        url: 'https://bitbucket.fi.dev/scm/tdodso/tdo_devsecops.git'
                                    ]]
                                ])
                                sh """
                                    git checkout master
                                    curl -fsSL -o ${eopaPath} https://github.com/StyraInc/enterprise-opa/releases/latest/download/eopa_Linux_x86_64
                                    chmod +x ${eopaPath}
                                """
                            }
                        }
                    }
                    container('python') {
                        script {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxOneProjectNameParams = config.cxonescan.isCxOneProjectName
                            def cxProjectNameParams = config.cxscan.isCxProjectName
                            def cxonetagId = config.cxonescan.tagId

                            withCredentials([
                                usernamePassword(credentialsId: 'IST-CheckMarx', passwordVariable: 'CX_PWD', usernameVariable: 'CX_USER'),
                                usernamePassword(credentialsId: 'OPA_CXONE_SWITCH', passwordVariable: 'CXONE_PWD', usernameVariable: 'CXONE_USER'),
                            ]) {
                                dir('pac') {
                                    sh """
                                        pip install -r requirements.txt
                                        sleep 5
                                        python secOps.py \\
                                            --cxone_client_id="${CXONE_USER}" \\
                                            --cxone_client_secret="${CXONE_PWD}" \\
                                            --cxOneProjectName="IST_NightlyBuilds_${cxOneProjectNameParams}_${configval.RELEASE_FILE}_dev" \\
                                            --cxOneBranchName="${env.BRANCH_NAME}" \\
                                            --scInternetFacing=false \\
                                            --vulnCategory=open \\
                                            --scAssetId=${cxonetagId} \\
                                            --cxTeamId="653" \\
                                            --cxProjectName="IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev" \\
                                            --cxsast_username=${CX_USER} \\
                                            --cxsast_password=${CX_PWD} \\
                                            --output=json \\
                                            --debug
                                    """
                                }
                            }
                        }
                    }
                    container('opa-cli') {
                        script {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxOneProjectNameParams = config.cxonescan.isCxOneProjectName
                            def cxProjectNameParams = config.cxscan.isCxProjectName
                            try {
                                runOPAAndHandleResults(
                                    credentialsId: "cm-credentials-id",
                                    CheckmarxoneProjectname: "IST_NightlyBuilds_${cxOneProjectNameParams}_${configval.RELEASE_FILE}_dev",
                                    cxProjectName: "IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev"
                                )
                            } catch (Exception e) {
                                echo "${e.message}"
                              	currentBuild.result = 'FAILURE'
                            }
                        }
                    }
                }
            }
            stage('CxFlow Jira Integration') {
                steps {
                    script {
                        try {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxProjectNameParams = config.cxscan.isCxProjectName
                            def cxProjectName = "IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev"
                            env.isCxFlowEnable = config.cxFlowScan.isCxFlowEnable.toString()
                            def jiraTicket = config.cxFlowScan.jiraAssigneePerson

                            if (configval.buildcomponent == 'nighty_build' && configval.selectedOsName == 'RHEL8') {
                                if (env.SKIP_STAGE_NOCOMMIT == 'true') {
                                    echo 'Skipping CxFlow Jira Integration stage due to no commit found'
                                } else if (env.isCxFlowEnable == 'true') {
                                    println "CXFLOW_PHASE_START: " + new Date().format("EEE MMM d yyyy HH:mm:ss z", TimeZone.getTimeZone('UTC'))
                                    println "Preparing to call CxFlow..."
                                    withCredentials([
                                        usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD'),
                                        usernamePassword(credentialsId: 'IST-CheckMarx', usernameVariable: 'Checkmarx_User', passwordVariable: 'Checkmarx_Passwd')
                                    ]) {
                                        def scanner = new fi.scan.CxFlowIntegration()
                                        scanner.call([
                                            script: this,
                                            configval: configval,
                                            cxProjectName: cxProjectName,
                                            jiraTicket: jiraTicket,
                                            vaultUser: env.JENKINS_USER,
                                            vaultPassword: env.JENKINS_PASSWORD,
                                            checkmarxUser: env.Checkmarx_User,
                                            checkmarxPasswd: env.Checkmarx_Passwd
                                        ])
                                    }
                                } else {
                                    echo 'Skipping CxFlow Jira Integration stage because CxFlow is not enabled'
                                }
                            } else {
                                echo "Skipping CxFlow Jira Integration stage because branch is not Nighty build or agent is not Rhel"
                            }
                        } catch (Exception e) {
                            echo "Error occurred in CxFlow Jira Integration stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                        }
                    }
                }
            }
		}
        post {
            always {
                script {
                    echo "Current build result: ${currentBuild.result}"
                    def yaml = readYaml file: "./Jenkins/params.yaml"
                    def defaultEmail = yaml.NotifyEmail
                    def isPRBuild = env.CHANGE_ID != null
                    def email = isPRBuild && env.PR_AUTHOR_EMAIL ? env.PR_AUTHOR_EMAIL : defaultEmail
                    def selectedOsName = "${configval.selectedOsName}"
                  	def releaseFileName = "${configval.RELEASE_FILE}"
                  	def emailcxProjectName = env.CX_PROJECT_NAME
                    def emailcxOneProjectName = env.CXONE_PROJECT_NAME
                    def emailcxScanId = env.CHECKMARX_SCAN_ID
                    def emailcxOneScanId = env.CHECKMARXONE_SCAN_ID
                    if (env.BRANCH_NAME.startsWith('PR') || env.BRANCH_NAME.startsWith('feature-PR')) {
                        echo "Current build result: ${currentBuild.result}"
                        if (currentBuild.result == 'SUCCESS') {
                            ocpEmailConfig.sendBuildNotificationForPrBuilds('SUCCESS', email)
                        } else if (currentBuild.result == 'FAILURE') {
                            ocpEmailConfig.sendBuildNotificationForPrBuilds('FAILURE', email)
                        } else if (currentBuild.result == 'UNSTABLE') {
                            ocpEmailConfig.sendBuildNotificationForPrBuilds('UNSTABLE', email)
                        }
                    } else if (configval.buildcomponent == 'nighty_build' && env.SKIP_STAGE_NOCOMMIT == 'true') {
                        echo "Skipping stage due to SKIP_STAGE_NOCOMMIT being true"
                    } else if (configval.buildcomponent == 'nighty_build') {
                        echo "Current build result: ${currentBuild.result}"
                        if (currentBuild.result == 'SUCCESS') {
                            ocpEmailConfig.sendPipelineStatus('SUCCESS', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        } else if (currentBuild.result == 'FAILURE') {
                            ocpEmailConfig.sendSimplePipelineStatus('FAILURE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName)
                        } else if (currentBuild.result == 'UNSTABLE') {
                            ocpEmailConfig.sendPipelineStatus('UNSTABLE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        }
                    }
                }
            }
        }
    }
}

---------------------------------------------------------release-build groovy-------------------------------------------------
import fi.ist.*
import groovy.json.JsonOutput
import java.util.TimeZone
import java.util.Date
import java.text.SimpleDateFormat
import org.jenkinsci.plugins.workflow.steps.FlowInterruptedException
def extractCxScanId(String logText) {
    def matcher = logText =~ /Scan ID is \s*(\d+)/
    return matcher ? matcher[0][1] : null
}
def extractCxOneScanId(String logText) {
    def matcher = logText =~ /Wait for scan to complete (\S+)/
    return matcher ? matcher[0][1] : null
}
def extractJiraTickets(consoleOutput) {
    def updatedJiraTickets = []
    def newJiraTickets = []
    def updateMatcher = consoleOutput =~ /Updating JIRA issue #(ISTDEV-\d+)/
    while (updateMatcher.find()) {
        updatedJiraTickets << updateMatcher.group(1)
    }
    def newIssueMatcher = consoleOutput =~ /New issue created. #(ISTDEV-\d+)/
    while (newIssueMatcher.find()) {
        newJiraTickets << newIssueMatcher.group(1)
    }
    return [updatedJiraTickets, newJiraTickets]
}
def extractOsInfo(consoleOutput) {
    def matcher = consoleOutput =~ /INFO: OS \[([^\]]*)\]/
    def osInfo = matcher ? matcher[0][1] : null
    if (osInfo == null) {
        error("OS information not found. Failing the pipeline.")
    }
    return osInfo
}
def call(Map configval = [:]){
    echo "Inside agentRccBuildPipeline.groovy ...."
  	def jobNameParts = JOB_NAME.tokenize('/') as String[]
    def jobNamePart = "${jobNameParts[2]}/${jobNameParts[3]}"
    def datas
    def emailRecipients
    def allowedUsers  
    def failedStage = ''
    def errorMessage = ''
    String PathVar, os_dir, myArtifact
  	def opaPodTemplate = fetchResources.getpodAgents()
  	def foCommitFound
  	def CmpCommitFound
    def triggerTimeEDT = new Date()
    def triggerTimeISTStr
  	def triggerTimeEDTStr
   	def releaseFile = params.RELEASE_FILE
	
    pipeline {
        agent { 
            node {
              		label configval.selectedOsValue
                    customWorkspace "workspace/" + WsSetup( jobNamePart: "${jobNamePart}" ) 
            }
        }
        environment {
          SOURCE_BRANCH = "${env.CHANGE_BRANCH ?: env.BRANCH_NAME}"
        }
        options {
            timestamps()
            buildDiscarder(logRotator(numToKeepStr: '10', artifactNumToKeepStr: '10'))
            copyArtifactPermission('*')
        }
        stages {
            stage('Check Release file') {
                steps {
                    script {
                        releaseApprovalStage(configval)
                    }
                }
            }

            stage('Set Java and Oracle Home') {
                steps {
                    script {
                        SimpleDateFormat edtFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
                        edtFormat.setTimeZone(TimeZone.getTimeZone("America/New_York"))
                        triggerTimeEDTStr = edtFormat.format(new Date())
                        env.TRIGGER_TIME_EDT = triggerTimeEDTStr
                        triggerTimeISTStr = ocpEmailConfig.convertEDTtoIST(triggerTimeEDTStr)
                        env.TRIGGER_TIME_IST = triggerTimeISTStr
                        echo "triggerTimeISTStr: ${triggerTimeISTStr}"
                        echo "triggerTimeEDTStr: ${triggerTimeEDTStr}"

                        def params = readYaml file: './Jenkins/params.yaml'
                        def javaVersion
                        def oracleVersion
                        switch (configval.selectedOsName) {
                            case 'RHEL8':
                                javaVersion = params.RHEL8[0].java_version
                                oracleVersion = params.RHEL8[1].oracle_version
                                break
                            case 'RHEL9':
                                javaVersion = params.RHEL9[0].java_version
                                oracleVersion = params.RHEL9[1].oracle_version
                                break
                            case 'AIX7.3':
                                javaVersion = params.'AIX7.3'[0].java_version
                                oracleVersion = params.'AIX7.3'[1].oracle_version
                                break
                            case 'AIX7.2':
                                javaVersion = params.'AIX7.2'[0].java_version
                                oracleVersion = params.'AIX7.2'[1].oracle_version.toUpperCase()
                                break
                            case 'SOLARIS':
                                javaVersion = params.'SOLARIS'[0].java_version
                                oracleVersion = params.'SOLARIS'[1].oracle_version.toUpperCase()
                                break
                            default:
                                error "Unsupported OS: ${configval.selectedOsName}"
                        }

                        echo "Parsed java_version: ${javaVersion}"
                        echo "Parsed oracle_version: ${oracleVersion}"

                        def javaEnvVar = "JAVA_${javaVersion}_HOME"
                        def oracleEnvVar = "ORACLE_HOME_${oracleVersion}"

                        echo "Looking for Java env var: ${javaEnvVar}"
                        echo "Looking for Oracle env var: ${oracleEnvVar}"

                        sh 'env | grep JAVA || true'
                        sh 'env | grep ORACLE || true'

                        def javaPath = sh(script: "echo \${${javaEnvVar}}", returnStdout: true).trim()
                        def oraclePath = sh(script: "echo \${${oracleEnvVar}}", returnStdout: true).trim()

                        if (!javaPath || javaPath == "\${${javaEnvVar}}") {
                            error "Environment variable '${javaEnvVar}' is not set or not visible to the pipeline shell."
                        }
                        if (!oraclePath || oraclePath == "\${${oracleEnvVar}}") {
                            error "Environment variable '${oracleEnvVar}' is not set or not visible to the pipeline shell."
                        }

                        env.java_home = javaPath
                        env.oracle_home = oraclePath

                        echo "Resolved JAVA_HOME: ${env.java_home}"
                        echo "Resolved ORACLE_HOME: ${env.oracle_home}"
                    }
                }
            }
            stage('Setup') {
                steps {
                    script {
                        println "Setting Parameters"
                        try {
                            
                            String MyOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
                            String kernelVersion = sh(script: "uname -r", returnStdout: true).trim()
                            String ORACLE_HOME = params.oracle_home ?: "/usr/lib/oracle/19.28/client64"
                            echo "OS : ${MyOS}"
                            os_dir = ""
                            PathVar = ""

                            if (MyOS == "linux") {
                               if (kernelVersion.startsWith("5.14")) {
                                    echo "Inside ${kernelVersion} ..."
                                    new CppBuild().env_linux()
                                    os_dir = "lin"

                                    def cleanOracleHome = env.oracle_home?.split("\\\\n")?.find { it.contains("/usr/lib/oracle/") }?.trim()
                                    echo "cleanOracleHome ${cleanOracleHome} ..."

                                    if (!cleanOracleHome) {
                                        error("No valid Oracle Home path found in env.oracle_home")
                                    }

                                    def selectedOracleHome = "/Osrc8/oracle/lin64_ora_199"

                                    PathVar = "/share/istprod_india/e1014306/bin/RHEL9:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:.:/Osrc8/tools/bin:${selectedOracleHome}:/Osrc8/local/bin/_LINUX2.6_i386/bin:/usr/bin/git:/usr/bin/curl:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home3/istrcc/snmp_bin"
									/* PathVar = "/share/istprod_india/e1014306/bin/RHEL9:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:.:/Osrc8/tools/bin:/Osrc8/oracle/lin64_ora_199:/Osrc8/local/bin/_LINUX2.6_i386/bin:/usr/bin/git:/usr/bin/curl:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home3/istrcc/snmp_bin"*/
                                    println "Linux Build with Kernel 5.14 detected (RHEL 9)..."
                                }
                                 else {
                                    new CppBuild().env_linux()
                                    os_dir = "lin"
                                    PathVar = "/Osrc8/local/bin/_LINUX2.6_i386_13/bin:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/Osrc/tools/bin:/Osrc/oracle/lin64_ora_199:$JAVA_HOME:$CLASSPATH:/usr/share/bcc/tools:/usr/local/lib64:/usr/lib64:/usr/lib:$PATH"
                                    println "This is a Linux Build for RHEL 8 ..."
                                }
                            } else if (MyOS == "aix") {
                                new CppBuild().env_aix()
                                os_dir = "aix"
                                String AIXVersion = sh(script: "oslevel", returnStdout: true).trim()
                                echo "Detected AIX version: ${AIXVersion}"
                                if (AIXVersion.startsWith("7.3")) {
                                    PathVar = "/opt/freeware/lib64:/home3/istrcc/BUILD/AIX-730/build/pdir/lib:/home3/istrcc/BUILD/AIX-730/build/pdir/bin:/share/istprod_india/e1014306/bin/AIX/:/share/istprod_india/e1014306/bin/AIX//curl:/home3/istrcc/BUILD/AIX-730/workspace/gitroot/ist-build-tools/autobase/scripts:/home3/Osrc/local/bin/_AIX4.2_risc6000/bin:/home3/Osrc/tools/bin:/usr/java8_64/bin:/opt/IBM/openxlC/17.1.1/bin/:/opt/freeware/bin:/usr/bin:/etc/:/usr/sbin:/usr/ucb:/usr/bin/X11:/sbin:/usr/java7_64/jre/bin:/usr/java7_64/bin:/usr/boksm/bin:/opt/freeware/bin:/opt/IBM/openxlC/17.1.1/bin:/opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10"
                                    echo "This is an AIX 7.3 Build ..."
                                } else if (AIXVersion.startsWith("7.2")) {
                                    PathVar = "/Osrc/local/bin/_AIX5.3_risc6000/bin:/opt/IBM/xlc/13.1.3/bin:/build/ist-build-tools/autobase/scripts:/Osrc/tools/bin:/Osrc/oracle/aix64_ora_1911:/usr/share/bcc/tools:/usr/lib64:/usr/lib:/opt/freeware/lib:${env.PATH}"
                                    echo "This is an AIX 7.2 Build ..."
                                } else {
                                    echo "Unknown AIX version: ${AIXVersion}"
                                }
                                echo "Final PathVar: ${PathVar}"
                            } else if (MyOS == "sunos") {
                                os_dir = "sol"
                                PathVar = "/opt/developerstudio12.6/bin:/home3/istrcc/BUILD/SOL-2114-M7/bin:/home3/Osrc/local/bin/_SOLARIS2.7_sun4x/bin:/usr/bin:/home3/istrcc/BUILD/SOL-2114-M7/workspace/gitroot/ist-build-tools/autobase/scripts:.:/home3/Osrc/tools/bin:/usr/bin/git:/usr/bin/curl:/usr/bin::/home3/istrcc/snmp_bin:/home3/istrcc/snmp_bin:/usr/bin/git:/home3/istrcc/BUILD/SOL-2114-M7/bin"
                                println "This is a Solaris Build ..."
                            } else if (MyOS == "hp-ux") {
                                os_dir = "hpux"
                                PathVar = ""
                                println "This is a HP-UX Build ..."
                            } else {
                                error "Unknown Operating System. Will not build."
                            }
                          
                             datas = readYaml file: "./Jenkins/params.yaml"
                             //datares = readYaml(text: libraryResource('fi/IST/Parameters.yaml'))
                            def component = configval.swComponent?.toLowerCase()
                            def buildType = configval.buildType?.toLowerCase()
                            def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')
                            def useBranchBuildList = false
                            switch (component) {
                                case "rcc_build":
                                    echo "Collected release file name from ${env.release_file} for rcc build."
                                    break
                                default:
                                    echo "Unknown or unsupported swComponent: ${component}. Defaulting to release file."
                                    break
                            }
                        }
                        catch (Exception e) {
                            println e
                            currentBuild.result = 'FAILURE'
                        }
                    }
                }
            }
            stage('Download dependency') {
                steps {
                    script {
                        try {
                            println "Stage: Download dependency repos."
                            dir('gitroot') {
                                BUILD_TYPE = params.BUILD_TYPE
                                new CppBuild().downloaddependency(
                                    project_repo: "${datas.Project_repo}",
                                    gitCreds: "cm-credentials-id"
                                )
                            }
                        } catch (Exception e) {
                            println "Error occurred during dependency download: ${e.getMessage()}"
                            // Optionally, you can fail the build or take other actions
                            currentBuild.result = 'FAILURE'
                            error("Download dependency stage failed.")
                        }
                    }
                }
            }
          
			stage('Build') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                    IST_TOOLS = "${env.WORKSPACE}/gitroot/ist-build-tools"
                    PATH = "${PathVar}"
                }
                steps {
					script {
						try {
							def component = configval.swComponent?.toLowerCase()
							def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')
							def repoName = jobNameParts[3]?.toLowerCase()
                          	configval.RELEASE_FILE = "${env.release_file_name}"
                          	env.trigger = "FullTrigger"
                          	echo "Build Release File: ${configval.RELEASE_FILE}"

							if (params.productname == 'ist-release-info') {
								myArtifact = new CppBuild().build(
									artFile: "${jobNameParts[2]}/${env.BRANCH_NAME.replaceAll('/', '_')}/${BUILD_NUMBER}",
									build_Flags: "${datas.build.Flags}",
									os: "${os_dir}",
									releasefile: sh(script: "cat ${GITROOT}/ist-release-info/rel_info/build.release", returnStdout: true).trim(),
									ArtCred: "svcacct_istartifact"
								)
							} else {
								myArtifact = new RccCppBuild().build(
									artFile: "${jobNameParts[2]}/${env.BRANCH_NAME.replaceAll('/', '_')}/${BUILD_NUMBER}",
									build_Flags: "${datas.build.Flags}",
									os: "${os_dir}",
									java_home: "${env.java_home}",
									oracle_home: "${env.oracle_home}",
									releasefile: "${env.release_file}",
									ArtCred: "svcacct_istartifact"
								)
							}
							if (myArtifact != "NoArtifact") {
                                  def artifactFiles = myArtifact.split(',').findAll { it?.trim() }.collect { "\"${it}\"" }.join(' ')
                                  if (artifactFiles) {
                                      sh "cp ${artifactFiles} ${env.WORKSPACE}"
                                  } else {
                                      println "No valid artifact files to copy."
                                  }
                                println "Component value: ${component}"
                                println "isPRBuild value: ${isPRBuild}"
                                println "repoName value: ${repoName}"

								def filesToZip = []

								// Load artifactBuildTgz.groovy
								//def artifactBuildTgz = load "${env.WORKSPACE}/path/to/artifactBuildTgz.groovy"

								if (artifactBuildTgz.shouldRenameArtifacts(component, isPRBuild, repoName)) {
									println "Inside the rename artifacts if condition"
									def (version, buildTag) = artifactBuildTgz.extractVersionAndBuildTag(env)
									filesToZip = artifactBuildTgz.renameArtifacts(myArtifact, version, buildTag, env)
								} else {
									filesToZip = artifactBuildTgz.collectTgzFiles(env, component)
								}

								if (filesToZip) {
									artifactBuildTgz.zipArtifacts(filesToZip, configval, env)
								} else {
									error("No artifact generated.")
								}
							}
						} catch (e) {
							echo "Build stage failed:"
							e.printStackTrace()
							throw e
						}
					}
				}
			}                        

            stage('Create PRs') {
              when {
                environment name: 'Approved_RunCreatePR', value: 'true'
              }
              steps {
                script {
                  try {
                    wrap([$class: 'BuildUser']) {

                      echo "Confirmed release file: ${env.release_file}"
                      echo "Approved SourceBranches: ${env.Approved_SourceBranches}"
                      echo "Approved DestinationBranches: ${env.Approved_DestinationBranches}"
                      echo "Approved RunCreatePR: ${env.Approved_RunCreatePR}"

                      String srcRaw = (env.Approved_SourceBranches ?: '').trim()
                      String dstRaw = (env.Approved_DestinationBranches ?: '').trim()

                      if (!srcRaw || !dstRaw) {
                        error "Provide both Approved_SourceBranches and Approved_DestinationBranches as comma-separated 'repo:branch' pairs."
                      }

                      def splitCsv = { String s -> s.split(',').collect { it.trim() }.findAll { it } }
                      def parsePairs = { String s ->
                        splitCsv(s).collect { item ->
                          def parts = item.split(':', 2)  // "repo:branch"
                          if (parts.size() != 2 || !parts[0].trim() || !parts[1].trim()) {
                            error "Invalid pair '${item}'. Expected 'repoName:branchName'."
                          }
                          [repo: parts[0].trim(), branch: parts[1].trim()]
                        }
                      }

                      def srcPairs   = parsePairs(srcRaw)
                      def destPairs  = parsePairs(dstRaw)

                      def destByRepo = destPairs.collectEntries { p -> [(p.repo.toLowerCase()): p.branch] }

                      def projectKeyFor = { String repoName, String srcBranch, String destBranch ->
                        def token = (repoName =~ /^([A-Za-z]+)_/).with { m -> m.find() ? m.group(1).toLowerCase() : null }
                        if (!token) {
                          def m1 = (srcBranch ?: '') =~ /(?i)\b(fo|cl|sw|ma)_/
                          if (m1.find()) token = m1.group(1).toLowerCase()
                          else {
                            def m2 = (destBranch ?: '') =~ /(?i)\b(fo|cl|sw|ma)_/
                            if (m2.find()) token = m2.group(1).toLowerCase()
                          }
                        }
                        switch (token) {
                          case 'fo': return 'istfo'
                          case 'cl': return 'istclr'
                          case 'sw': return 'istsw'
                          case 'ma': return 'istmas'
                          default: error "Cannot determine project family from repo='${repoName}'. Expected FO/CL/SW/MA in repo or branch name."
                        }
                      }

                      def workItems = []
                      srcPairs.each { s ->
                        def destBranch = destByRepo[s.repo.toLowerCase()]
                        if (!destBranch) {
                          error "Destination branch missing for repo '${s.repo}'. Make sure repo names match in both lists."
                        }
                        echo "PAIR: repo='${s.repo}' src='${s.branch}' ‚Üí dest='${destBranch}'"
                        def prKey = projectKeyFor(s.repo, s.branch, destBranch)
                        workItems << [repo: s.repo, srcBranch: s.branch, destBranch: destBranch, projectKey: prKey]
                      }

                      if (workItems.isEmpty()) {
                        error "No PR work items could be built from the provided pairs."
                      }

                      workItems.each { item ->
                        stage("Create PR: ${item.repo}  ${item.srcBranch} ‚Üí ${item.destBranch}") {
                          echo """
                          PR Input
                          --------
                          Repository   : ${item.repo}
                          Project Key  : ${item.projectKey}
                          Source Branch: ${item.srcBranch}
                          Dest Branch  : ${item.destBranch}
                          """.stripIndent()

                          // IMPORTANT:
                          // This calls YOUR EXISTING shared library (unchanged).
                          // If an existing open PR already uses the same src‚Üídest,
                          // your library will SKIP by design.
                          // To create "another PR", the dev team must provide a DIFFERENT source branch name.
                          createBitbucketPRs(
                            sourceBranches : [item.srcBranch],   
                            destBranch     : item.destBranch,
                            repoName       : item.repo,
                            projectKey     : item.projectKey,
                            bitbucketCreds : 'cm-credentials-id'
                          )
                        }
                      }
                    }
                  } catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException fie) {
                    echo "Pipeline was manually aborted."
                    currentBuild.result = 'ABORTED'
                    throw fie
                  }
                }
              }
            }

            stage('Checkmarx') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                    PATH = "$PATH:/data/jenkins/workspace/gitroot/ist-build-tools/autobase/scripts:/Osrc8/tools/bin:$ORACLE_HOME:$JAVA_HOME:$GITROOT:/usr/share/bcc/tools:/root/testing:/Osrc8/local/bin/_LINUX2.6_i386_13/bin:/usr/lib64:/usr/lib"
                }
                when {
                    expression { return configval.selectedOsName == 'RHEL8' || configval.selectedOsName == 'RHEL9' }
                }
                steps {
                    script {
                        try {
                            def cxProjectName = "${env.Cx_CxOne_Project_Name}"
                            def branchName = env.BRANCH_NAME ?: ""
							def isIncrementalScan = !branchName.startsWith("release/")
                            env.release_file_name_transformed = env.release_file.replace(".release", "")

                            withCredentials([
                                usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
                            ]) {
                                sh """
                                    printf "$JENKINS_USER\n$JENKINS_PASSWORD\n" > export:BLD_CREDENTIALS
                                    export USERID=$JENKINS_USER
                                    export USERACCESS=$JENKINS_PASSWORD

                                    if grep -q '^sw_base:' ${env.WORKSPACE}/${env.release_file}; then
                                        sw_base_branch=\$(grep '^sw_base:' ${env.WORKSPACE}/${env.release_file} | cut -d':' -f2)
                                        sed -i "s|^sw_segment:master|sw_segment:\${sw_base_branch}|" ${env.WORKSPACE}/${env.release_file}
                                    fi

                                    grep -E '(:|_OS_)' ${env.WORKSPACE}/${env.release_file} | grep -Ev 'OS_DB|OS_ZCLOPTMZD' > ${env.WORKSPACE}/${env.release_file_name_transformed}.rel
                                    echo "Filtered Release File:"
                                    cat ${env.WORKSPACE}/${env.release_file_name_transformed}.rel

                                    ${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts/build_checkmarx_jk.ksh ${env.WORKSPACE}/${env.release_file_name_transformed}.rel
                                """
                            }

                            def scanner = new fi.scan.CheckmarxScan()
                            scanner.call([
                                script: this,
                                cxProjectName: cxProjectName,
                                configval: configval,
                                isIncrementalScan: isIncrementalScan
                            ])

                            archiveArtifacts artifacts: 'Checkmarx/Reports/*.html', allowEmptyArchive: true
                            archiveArtifacts artifacts: 'Checkmarx/Reports/*.pdf', allowEmptyArchive: true

                            def checkmarx_scanOutput = currentBuild.rawBuild.getLog(10000).join("\n")
                            def checkmarx_scanId = extractCxScanId(checkmarx_scanOutput)

                            if (checkmarx_scanId) {
                                echo "Extracted CxOne Scan ID: ${checkmarx_scanId}"
                            } else {
                                echo "No Scan ID found in Checkmarx logs"
                            }

                            env.CHECKMARX_SCAN_ID = checkmarx_scanId
                            env.CX_PROJECT_NAME = "${cxProjectName}"
                        } catch (Exception e) {
                            echo "Error occurred during Checkmarx stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Checkmarx stage failed.")
                        }
                    }
                }
            }
            stage('Checkmarx One') {
                when {
                    expression { return configval.selectedOsName == 'RHEL8' || configval.selectedOsName == 'RHEL9' }
                }
                steps {
                    script {
                        try {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxOneProjectName = "${env.Cx_CxOne_Project_Name}"
                            def cxonetagId = config.cxonescan.tagId
                            def cxOneProjectGroup = config.cxonescan.projectGroup

                            // Run Checkmarx One scan
                            def scanner = new fi.scan.CheckmarxOneScan()
                            scanner.call([
                                script: this,
                                configval: configval,
                                cxOneProjectName: cxOneProjectName,
                                cxonetagId: cxonetagId,
                                cxOneProjectGroup: cxOneProjectGroup
                            ])
                        } catch (Exception e) {
                            echo "Error occurred during Checkmarx One stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Checkmarx One stage failed.")
                        }
                    }
                }
            }
            stage('Policy-As-Code') {
              	when {
                    expression { return configval.selectedOsName == 'RHEL8' || configval.selectedOsName == 'RHEL9' }
                }
                agent {
                    kubernetes {
                        cloud 'devsecops-enablement'
                        yaml opaPodTemplate
                    }
                }
                steps {
                    container('jnlp') {
                        script {
                            sh "mkdir pac"
                            def eopaPath = "./eopa"
                            dir('pac') {
                                checkout([$class: 'GitSCM',
                                    branches: [[name: 'master']],
                                    extensions: [],
                                    userRemoteConfigs: [[
                                        credentialsId: 'cm-credentials-id',
                                        url: 'https://bitbucket.fi.dev/scm/tdodso/tdo_devsecops.git'
                                    ]]
                                ])
                                sh """
                                    git checkout master
                                    curl -fsSL -o ${eopaPath} https://github.com/StyraInc/enterprise-opa/releases/latest/download/eopa_Linux_x86_64
                                    chmod +x ${eopaPath}
                                """
                            }
                        }
                    }
                    container('python') {
                        script {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxOneProjectName = "${env.Cx_CxOne_Project_Name}"
                            def cxProjectName = "${env.Cx_CxOne_Project_Name}"
                            def cxonetagId = config.cxonescan.tagId

                            withCredentials([
                                usernamePassword(credentialsId: 'IST-CheckMarx', passwordVariable: 'CX_PWD', usernameVariable: 'CX_USER'),
                                usernamePassword(credentialsId: 'OPA_CXONE_SWITCH', passwordVariable: 'CXONE_PWD', usernameVariable: 'CXONE_USER'),
                            ]) {
                                dir('pac') {
                                    sh """
                                        pip install -r requirements.txt
                                        sleep 5
                                        python secOps.py \\
                                            --cxone_client_id="${CXONE_USER}" \\
                                            --cxone_client_secret="${CXONE_PWD}" \\
                                            --cxOneProjectName="${cxOneProjectName}" \\
                                            --cxOneBranchName="${env.BRANCH_NAME}" \\
                                            --scInternetFacing=false \\
                                            --vulnCategory=open \\
                                            --scAssetId=${cxonetagId} \\
                                            --cxTeamId="653" \\
                                            --cxProjectName="${cxProjectName}" \\
                                            --cxsast_username=${CX_USER} \\
                                            --cxsast_password=${CX_PWD} \\
                                            --output=json \\
                                            --debug
                                    """
                                }
                            }
                        }
                    }
                    container('opa-cli') {
                        script {
                            def cxOneProjectName = "${env.Cx_CxOne_Project_Name}"
                            def cxProjectName = "${env.Cx_CxOne_Project_Name}"
                            try {
                                runOPAAndHandleResults(
                                    credentialsId: "cm-credentials-id",
                                  	CheckmarxoneProjectname: "${cxProjectName}",
                                  	cxProjectName: "${cxOneProjectName}"
                                )
                            } catch (Exception e) {
                                echo "Error occurred during Policy as Code stage: ${e.getMessage()}"
                            	currentBuild.result = 'FAILURE'
                            	error("Policy as Code stage failed.")
                            }
                        }
                    }
                }
            }
            stage('Upload Release Logs and Scan Report') {
                steps {
                    wrap([$class: 'BuildUser']) {
                        script {
                            // Detect OS and version
                            def detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
                            def AIXVersion = detectedOS == "aix" ? sh(script: "oslevel", returnStdout: true).trim() : ""
                            def isAIX73 = (detectedOS == "aix" && AIXVersion.startsWith("7.3"))

                            try {
                                echo "Upload Stage Start: " + new Date().format("EEE MMM d yyyy HH:mm:ss z", TimeZone.getTimeZone('UTC'))

                                def userFullName = env.BUILD_USER
                                def userEmail = env.BUILD_USER_EMAIL ?: "${userFullName}@figlobal.com"

                                def scmUrl = env.GIT_URL ?: scm?.getUserRemoteConfigs()?.getAt(0)?.getUrl()
                                def repoUrl = scmUrl?.replaceAll(/\.git$/, '') ?: "https://bitbucket.fi.dev/scm/istsw/sw_devops"

                                def releaseFileName = env.release_file_name ?: "unknown_release_file"
                                def branchName = env.BRANCH_NAME ?: "main"
                                def jenkinsJobUrl = env.BUILD_URL ?: "N/A"

                                def releaseFilePath = "${env.WORKSPACE}/release_info_${env.BUILD_NUMBER}.txt"
                                configval = configval ?: [selectedOsName: "unknown"]

                                def releaseInfoContent = """\
                                    Triggered By: ${userFullName}
                                    Email: ${userEmail}
                                    Release File: "${releaseFileName}"
                                    Branch: "${branchName}"
                                    Timestamp: ${new Date().format("yyyy-MM-dd HH:mm:ss", TimeZone.getTimeZone("UTC"))}
                                    Jenkins Job URL: ${jenkinsJobUrl}
                                    Repo URL: ${repoUrl}
                                    Agent Name: ${configval.selectedOsName}
                                """
                                writeFile file: releaseFilePath, text: releaseInfoContent
                                sh "cat ${releaseFilePath}"

                                def scanFilePath = ""
                                if (configval?.selectedOsName == "RHEL8") {
                                    echo "Detected RHEL8 - generating scan_results file"
                                    scanFilePath = "${env.WORKSPACE}/scans_results_${env.BUILD_NUMBER}.txt"
                                    def scanContent = """\
                                        CXProjectName="${env.CX_PROJECT_NAME}" 
                                        CXScanId=${env.CHECKMARX_SCAN_ID} 
                                        CxOneProject="${env.CXONE_PROJECT_NAME}" 
                                        CxSCAScanId=${env.CHECKMARXONE_SCAN_ID}
                                        """
                                    writeFile file: scanFilePath, text: scanContent
                                    sh "cat ${scanFilePath}"
                                } else {
                                    echo "Skipping scan_results file generation - OS is not RHEL8"
                                }

                                def datas2 = readYaml file: "./Jenkins/params.yaml"
                                def repoUrlArtifactory = datas2.artifactory.Path
                                def buildType = "development"
                                def txtSubPath = "release_logs/${releaseFileName}"

                                withCredentials([
                                    usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'ART_USER', passwordVariable: 'ART_PASS')
                                ]) {
                                    echo "Uploading release info to Artifactory"
                                    new RccCppBuild().artifactUploadTgz([
                                        artifactPath: releaseFilePath,
                                        repoUrl: repoUrlArtifactory,
                                        buildType: buildType,
                                        subPath: txtSubPath,
                                        artifactory: datas2.artifactory
                                    ])

                                    if (scanFilePath && fileExists(scanFilePath)) {
                                        echo "Uploading scan results to Artifactory"
                                        new RccCppBuild().artifactUploadTgz([
                                            artifactPath: scanFilePath,
                                            repoUrl: repoUrlArtifactory,
                                            buildType: buildType,
                                            subPath: txtSubPath,
                                            artifactory: datas2.artifactory
                                        ])
                                    }
                                }

                                echo "Upload Stage End: " + new Date().format("EEE MMM d yyyy HH:mm:ss z", TimeZone.getTimeZone('UTC'))
                            } catch (Exception e) {
                                echo "Error occurred during Upload Logs stage: ${e.getMessage()}"
                            	currentBuild.result = 'FAILURE'
                            	error("Upload Logs stage failed.")
                            }
                        }
                    }
                }
            }
          	stage('Upload to Artifactory') {
                steps {
					script {
						try {
							def datas2 = readYaml file: "./Jenkins/params.yaml"
							def tgzFilesPath = sh(script: "ls ${env.WORKSPACE}/*.tgz | awk -F'/' '{print \$NF}'", returnStdout: true).trim().toString()
							def tgzFiles = tgzFilesPath ? tgzFilesPath.split('\n') : []
							def buildType = "development"
							def repoUrl = datas2.artifactory.Path
                          	def tgzSubPath = "rel_tgz/Oja_release/${os_dir}"
                          	env.tgzSubPathSei = "${tgzSubPath}"
							if (tgzFiles.size() == 0) {
								echo "No tgz files found!"
							} else {
								tgzFiles.each { tgzFile ->
									echo "Uploading tgz artifact: ${tgzFile}"
									new RccCppBuild().artifactUploadTgz([
										artifactPath: tgzFile,
										repoUrl: repoUrl,
										buildType: buildType,
										subPath: tgzSubPath,
										artifactory: datas2.artifactory
									])
								}
							}
						} catch (Exception e) {
							echo "Error occurred during Upload Artifactory stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Upload Artifactory stage failed.")
						}
					}
				}
			}
          	stage('Submit Execution to Harness SEI') {
                steps {
                    script {
                        harnessSeiCode(configval, env)
                    }
                }
            }
        }
        
		post {
            always {
                script {
                    echo "Current build result: ${currentBuild.result}"
                  	def yaml = readYaml file: "./Jenkins/params.yaml"
                    def defaultEmail = yaml.NotifyEmail
                    def isPRBuild = env.CHANGE_ID != null
                    def email = isPRBuild && env.PR_AUTHOR_EMAIL ? env.PR_AUTHOR_EMAIL : defaultEmail
                    def selectedOsName = "${configval.selectedOsName}"
                  	def releaseFileName = "${env.release_file_name}"
                  	def emailcxProjectName = env.CX_PROJECT_NAME
                    def emailcxOneProjectName = env.CXONE_PROJECT_NAME
                    def emailcxScanId = env.CHECKMARX_SCAN_ID
                    def emailcxOneScanId = env.CHECKMARXONE_SCAN_ID
                    if (configval.buildcomponent == 'rcc_build') {
                        echo "Current build result: ${currentBuild.result}"
                        if (currentBuild.result == 'SUCCESS') {
                           ocpEmailConfig.releaseSendPipelineStatus('SUCCESS', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        } else if (currentBuild.result == 'FAILURE') {
                            ocpEmailConfig.releaseSendSimplePipelineStatus('FAILURE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName)
                        } else if (currentBuild.result == 'UNSTABLE') {
                            ocpEmailConfig.releaseSendPipelineStatus('UNSTABLE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        }
                    }
                }
            }
        }
    }
}

---------------------------------------------------------pipeline-router groovy-------------------------------------------------
#!/usr/bin/groovy

import fi.ist.*

def agentList = SelectAgent()

def call(Map configval = [:]) {

    echo "Inside BuildPipelineRouter ...."

    def osList = SelectOS()
    def oslabels = osList.keySet() as List<String>

    configval.branch = env.BRANCH_NAME ?: ""
    def branch = "${configval.branch}"
    def isPRBuild = branch ==~ /^(develop|feature|feature-PR|PR-|Feature)\/?[A-Za-z0-9._-]*$/
    def isReleaseBuild = branch ==~ /^(release|master)\/?[A-Za-z0-9._-]*$/
    def isNightyBuild = branch ==~ /^(master|stable)\/?[A-Za-z0-9._-]*$/

    def selectedOsName = ""

    if (branch.contains("Nighty")) {
        properties([
            parameters([
                choice(name: 'OS_TYPE_VERSION', choices: oslabels, description: 'Select OS'),
                string(name: 'RELEASE_FILE', defaultValue: '', description: 'Provide the release file name'),
                booleanParam(
                    name: 'FULL_BUILD_CHECKBOX',
                    defaultValue: false,
                    description: 'Check this box to perform a full build for a project'
                )
            ])
        ])

        configval.RELEASE_FILE = params.RELEASE_FILE ?: ''
        configval.FULL_BUILD_CHECKBOX = params.FULL_BUILD_CHECKBOX ?: false
        selectedOsName = params.OS_TYPE_VERSION

    } else if (branch.contains("release/")) {
      	selectedOsName = "${configval.agentLable}"
        echo "OS_TYPE_VERSION from params.yaml: ${selectedOsName}"

    } else {
        properties([
            parameters([
                choice(name: 'OS_TYPE_VERSION', choices: oslabels, description: 'Select OS')
            ])
        ])
        selectedOsName = params.OS_TYPE_VERSION
    }

    echo "selectedOsName: ${selectedOsName}"
    def selectedOsValue = osList[selectedOsName]
    echo "Selected OS Value: ${selectedOsValue}"

    if (isPRBuild || isNightyBuild) {
        configval.put("buildType", "development")
    } else if (isReleaseBuild) {
        configval.put("buildType", "release")
    } else {
        println "${branch} is not a valid branch. Will not proceed ahead."
        return
    }
  	
  	if (branch.contains("PR") || branch.contains("feature-PR")) {
        configval.put("swComponent", "PR")
    } else if (branch.contains("SW_")) {
        configval.put("swComponent", "switch")
    } else if (branch.contains("CL_")) {
        configval.put("swComponent", "clearing")
    } else if (branch.contains("MA_")) {
        configval.put("swComponent", "mas")
	} else if (branch.contains("Nighty")) {
        configval.put("swComponent", "nighty_build")
    } else if (branch.contains("release/")) {
        configval.put("swComponent", "rcc_build")
    } else {
        echo "Branch name is not having value to match in pipeline router"
    }
  	
  	    // üîÑ NEW LOGIC: Split buildcomponent into swComponentType and buildcomponent for checkmarx run to use it for different project
    if (configval.containsKey("buildcomponent") && configval.buildcomponent.contains("_")) {
        def parts = configval.buildcomponent.split("_", 2)
        configval.put("swComponentType", parts[0])
        configval.put("buildcomponent", parts[1])
    }

    configval.put("selectedOsName", selectedOsName)
    configval.put("selectedOsValue", selectedOsValue)

    echo "Branch: ${configval.branch}"
    echo "Build Type: ${configval.buildType}"
    echo "swComponent: ${configval.swComponent}"
    echo "selectedOsName: ${configval.selectedOsName}"
    echo "selectedOsValue: ${configval.selectedOsValue}"
  	echo "swComponentType: ${configval.swComponentType}" // ‚úÖ New variable
    echo "Build Component: ${configval.buildcomponent}"
    echo "Build Release File: ${configval.RELEASE_FILE}"
    echo "Enable Full Build: ${configval.FULL_BUILD_CHECKBOX}"

    if (branch.contains("Nighty")) {
        if (selectedOsName.contains("OCP")) {
            echo "Nighty OCP build detected. Calling ocpBuildPipeline..."
            ocpBuildPipeline(configval)
        } else {
            echo "Nighty agent build detected. Calling agentBuildPipeline..."
            agentBuildPipeline(configval)
        }
    } else if (branch.contains("PR") || branch.contains("feature-PR") || branch.contains("develop/SW_") || branch.contains("develop/CL_") || branch.contains("develop/MA_")) {
        if (selectedOsName.contains("OCP")) {
            echo "PR OCP build detected. Calling ocpBuildPipeline..."
            ocpBuildPipeline(configval)
        } else {
            echo "PR agent build detected. Calling agentBuildPipeline..."
            agentBuildPipeline(configval)
        }
    } else if (branch.contains("release/")) {
        if (selectedOsName.contains("OCP")) {
            echo "Release OCP build detected. Calling ocpRccBuildPipeline..."
            ocpRccBuildPipeline(configval)
        } else {
            echo "Release agent build detected. Calling agentRccBuildPipeline..."
            agentRccBuildPipeline(configval)
        }
    } else {
        echo "Non-OCP build detected. Calling agentBuildPipeline..."
        agentBuildPipeline(configval)
    }
}




notes -- whether its ocp build nightly build or release build


@Library(['common-lib@3-stable', 'incubator-lib', 'cm-cicd-pipeline-library', 'ist-switch-jenkins-pipeline-library@stable-2']) _


PipelineRouter(
    buildParamsYAML: 'params.yaml',
  	cxParamsYAML: './Jenkins/cxflow_params.yml',
    buildcomponent: 'switch_nighty_build'
	
	
	
	
@Library(['common-lib@3-stable', 'incubator-lib', 'cm-cicd-pipeline-library', 'ist-switch-jenkins-pipeline-library@stable-2']) _

PipelineRouter(
  buildcomponent: 'switch_rcc_build',
  agentLable: 'RHEL8', // AIX7.3, RHEL8, AIX7.2, RHEL9, RHEL9OCP, RHEL8OCP
  isPR: true     
)




----------------------------sei----------------------------

def call(configval, env) {
    try {
        wrap([$class: 'BuildUser']) {
            echo "DEBUG: Inside the Harness SEI pipeline method...."

            def bitbucketRepoUrl = env.GIT_URL ?: scm?.getUserRemoteConfigs()?.getAt(0)?.getUrl()
            echo "DEBUG: Repository URL from Jenkins = ${bitbucketRepoUrl}"

            withCredentials([usernamePassword(credentialsId: 'cm-credentials-id', usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')]) {
                def authenticatedRepoUrl = bitbucketRepoUrl.replace("https://", "https://${USERNAME}:${PASSWORD}@")

                echo "DEBUG: Executing the git ls-remote command...."
                def releaseBranchesRaw = sh(
                    script: "git ls-remote --heads ${authenticatedRepoUrl} | grep 'refs/heads/release/' | awk '{print \$2}' | sort | tail -n 2 || echo ''",
                    returnStdout: true
                ).trim()

                echo "DEBUG: Executed the git ls-remote command...."
                def branches = releaseBranchesRaw.split('\n').findAll { it }

                echo "DEBUG: Branch list = ${branches}"

                if (branches.size() < 2) {
                    error "Not enough release branches found to compare commits."
                }

                def previousReleaseBranch = branches[0].replace('refs/heads/', '').trim()
                def currentReleaseBranch = branches[1].replace('refs/heads/', '').trim()

                echo "Previous Release Branch: ${previousReleaseBranch}"
                echo "Current Release Branch: ${currentReleaseBranch}"

                echo "DEBUG: Fetching branches..."
                sh "git fetch ${authenticatedRepoUrl} ${previousReleaseBranch}:${previousReleaseBranch}"
                sh "git fetch ${authenticatedRepoUrl} ${currentReleaseBranch}:${currentReleaseBranch}"
                echo "DEBUG: Fetch complete for both branches"

                echo "DEBUG: Executing the git log command...."
                def diffCommits = sh(
                    script: "git log --pretty=format:'%H' ${previousReleaseBranch}..${currentReleaseBranch} || echo ''",
                    returnStdout: true
                ).trim().split('\n').findAll { it }

                echo "DEBUG: Executed the git log command...."
                echo "Commits between ${previousReleaseBranch} and ${currentReleaseBranch}:"
                diffCommits.each { echo it }

                def scm_commit_ids = diffCommits.collect { "\"${it}\"" }.join(',')

                def repoUrl = bitbucketRepoUrl
              	def agentLable = "${configval.selectedOsName}"
                def instanceUrl = env.BUILD_URL
                def instanceId = 'd6961b19-fcbb-4f16-8c55-c4b33a010260'
                def apiKey = 'Apikey eyJrZXkiOiJveDdoYkJ1cElvTCsmV0pFbmhDaVNhYWV6JkR0WldJcG51MnFoYzlBbTBzMzI4TUtNUCIsImlkIjoiMzU1NDE0MzgtODZjZi00NDliLThjNDUtYzg1NTllZDI1ZmNkIiwiY29tcGFueSI6ImZpc2dsb2JhbCJ9'
                def buildNumber = env.BUILD_NUMBER?.toLong() ?: 0
                def startTime = new Date(currentBuild.getStartTimeInMillis()).format("yyyy-MM-dd HH:mm:ss", TimeZone.getTimeZone("UTC"))
                def durationMillis = currentBuild.getDuration()
                def buildUserId = "${env.BUILD_USER} (${env.BUILD_USER_ID})"
                def jobName = env.JOB_NAME
                def buildStatus = currentBuild.currentResult
                def branchName = env.GIT_BRANCH ?: "stable/"
                def renameModule = "IST${configval.swComponentType.toUpperCase()}"
                def tgzSubPath = env.tgzSubPathSei ?: ""

                def tgzFiles = sh(script: "find . -type f -name '*.tgz' -exec basename {} \\; || echo ''", returnStdout: true).trim().split('\n').findAll { it }
                def artifactsJson = tgzFiles.collect { tgzName ->
                    return """{
                        "input": false,
                        "output": true,
                        "type": "non_container",
                        "location": "emeaistgui-generic-snapshot-local",
                        "name": "${tgzSubPath}/${tgzName}",
                        "qualifier": "${tgzSubPath}/${tgzName}"
                    }"""
                }.join(',')

                def payload = """{
                    "pipeline": "${jobName}",
                    "user_id": "${buildUserId}",
                    "agentName": "${agentLable}"
                    "repo_url": "${repoUrl}",
                    "start_time": "${startTime}",
                    "result": "${buildStatus}",
                    "duration": ${durationMillis},
                    "build_number": ${buildNumber},
                    "instance_guid": "${instanceId}",
                    "instance_name": "ci-cd-instance",
                    "instance_url": "https://jenkins.fi.dev/",
                    "job_run": "${instanceUrl}",
                    "job_full_name": "${jobName}",
                    "qualified_name": "${jobName}",
                    "branch_name": "${branchName}",
                    "module_name": "${renameModule}",
                    "scm_commit_ids": [${scm_commit_ids}],
                    "ci": true,
                    "cd": false,
                    "artifacts": [${artifactsJson}]
                }"""

                echo "Payload to be sent: ${payload}"

                // Uncomment to send to SEI
                // writeFile file: 'sei_payload.json', text: payload
                // sh """
                //     curl -X POST https://app.harness.io/gratis/sei/api/v1/custom-cicd \\
                //     --header 'Accept: application/json, text/plain, */*' \\
                //     --header 'Referer: https://app.harness.io/gratis/sei/api' \\
                //     --header 'sec-ch-ua-mobile: ?0' \\
                //     --header 'authorization: ${apiKey}' \\
                //     --header 'Content-Type: application/json' \\
                //     --data @sei_payload.json
                // """

                echo 'Pushed execution detail to SEI...'
            }
        }
    } catch (Exception e) {
        echo "ERROR in Harness SEI pipeline: ${e.getMessage()}"
        throw e
    }
}


-----------------------------------artifactbuild tgz.grrovy-----------------------------------------------------

def zipArtifacts(filesToZip, configval, env) {
    def zipInputFiles = filesToZip.collect { it.tokenize('/').last() }.join(' ')
    def consoleOutput = currentBuild.rawBuild.getLog(1000000).join("\n")
    def modifiedOsInfo = extractOsInfo(consoleOutput, configval)
    def osBitMode = extractBitMode(consoleOutput)

    def zipFileName = "IST_${configval.RELEASE_FILE}_${modifiedOsInfo}${osBitMode}_${env.trigger}.zip"
    echo "Zip file name: ${zipFileName}"
    echo "Files to zip: ${zipInputFiles}"

    env.ZIP_NAME = "${zipFileName}"

    sh """
        cd ${env.WORKSPACE}
        echo 'Zipping files into ${zipFileName}'
        zip ${zipFileName} ${zipInputFiles}
        mkdir -p "${env.WORKSPACE}/nighty_checkmarxone_tgz"
        cp ${zipFileName} ${env.WORKSPACE}/nighty_checkmarxone_tgz/
    """

    dir("${env.WORKSPACE}/nighty_checkmarxone_tgz") {
        sh '''
            echo "Unzipping artifacts for Checkmarx Scan..."
            unzip -o *.zip || echo "No zip files found or unzip failed"
            rm -f *.zip
            ls -lart

            echo "Extracting all .tgz files"
            for file in *.tgz; do
                if [ -s "$file" ]; then
                    echo "Extracting $file"
                    tar -xzf "$file" || echo "Failed to extract $file"
                else
                    echo "Skipping empty or non-existent file: $file"
                fi
            done
            rm -f *.tgz
            ls -lart
        '''
    }
}

def renameArtifacts(myArtifact, version, buildTag, env, configval) {
    def consoleOutput = currentBuild.rawBuild.getLog(1000000).join("\n")
    def modifiedOsInfo = extractOsInfo(consoleOutput, configval)
    def filesToZip = []

    def osVersionOnly = modifiedOsInfo.tokenize('-')[0..1].join('-')  // e.g., "LIN-4180" or "AIX-730"

    myArtifact.split(',').each { fullPath ->
        def fileName = fullPath.tokenize('/').last()
        def localPath = "${env.WORKSPACE}/${fileName}"
        def newName = fileName

        if (fileName.startsWith("SW_MASTER") && fileName.endsWith("_SEGMENT.tgz")) {
            def archFull = fileName.replace("SW_MASTER_", "").replace("_SEGMENT.tgz", "")
            def arch = archFull.replaceFirst(/LIN-\d+-/, "")  // Remove embedded LIN-* if present

            def finalArch = arch.contains(osVersionOnly) ? arch : "${osVersionOnly}-${arch}"

            newName = buildTag ?
                "SW_${version}_${finalArch}_SEGMENT_${buildTag}.tgz" :
                "SW_${version}_${finalArch}_SEGMENT.tgz"
        } else if (fileName.endsWith(".tgz") && configval.selectedOsName?.contains("RHEL8OCP")) {
            newName = fileName.replaceAll(/LIN-\d+/, osVersionOnly)
        }

        def newPath = "${env.WORKSPACE}/${newName}"
        if (newName != fileName) {
            echo "Renaming ${fileName} ‚Üí ${newName}"
            sh "mv ${localPath} ${newPath}"
        } else {
            echo "Keeping ${fileName} unchanged"
        }

        filesToZip << newPath
    }

    return filesToZip
}


/*def renameArtifacts(myArtifact, version, buildTag, env, configval) {
    def consoleOutput = currentBuild.rawBuild.getLog(1000000).join("\n")
    def modifiedOsInfo = extractOsInfo(consoleOutput, configval)
    def filesToZip = []

    def osVersionOnly = modifiedOsInfo.tokenize('-')[0..1].join('-')  // e.g., "LIN-4180"

    myArtifact.split(',').each { fullPath ->
        def fileName = fullPath.tokenize('/').last()
        def localPath = "${env.WORKSPACE}/${fileName}"
        def newName = fileName

        if (fileName.startsWith("SW_MASTER") && fileName.endsWith("_SEGMENT.tgz")) {
            def archFull = fileName.replace("SW_MASTER_", "").replace("_SEGMENT.tgz", "")
            def arch = archFull.replaceFirst(/LIN-\d+-/, "")  // Remove embedded LIN-* if present

            newName = buildTag ?
                "SW_${version}_${osVersionOnly}-${arch}_SEGMENT_${buildTag}.tgz" :
                "SW_${version}_${osVersionOnly}-${arch}_SEGMENT.tgz"
        } else if (fileName.endsWith(".tgz") && configval.selectedOsName?.contains("RHEL8OCP")) {
            newName = fileName.replaceAll(/LIN-\d+/, osVersionOnly)
        }

        def newPath = "${env.WORKSPACE}/${newName}"
        if (newName != fileName) {
            echo "Renaming ${fileName} ‚Üí ${newName}"
            sh "mv ${localPath} ${newPath}"
        } else {
            echo "Keeping ${fileName} unchanged"
        }

        filesToZip << newPath
    }

    return filesToZip
} */


def extractBitMode(consoleOutput) {
    def matcher = consoleOutput =~ /BIT_MODE=([^\s]*)/
    def bitMode = matcher ? matcher[0][1] : null
    if (bitMode == null) {
        error("BIT_MODE information not found. Failing the pipeline.")
    }
    return bitMode
}

def extractOsInfo(consoleOutput, configval) {
    def matcher = consoleOutput =~ /INFO: OS \[([^\]]*)\]/
    def osInfo = matcher ? matcher[0][1] : null
    if (osInfo == null) {
        error("OS information not found. Failing the pipeline.")
    }

    def modifiedOsInfo = osInfo

    if (configval.selectedOsName?.contains("RHEL8OCP")) {
        def osMatcher = osInfo =~ /^LIN-(\d+)-(.+)$/
        if (osMatcher.matches()) {
            def version = osMatcher[0][1]
            def arch = osMatcher[0][2]
            if (version == "5140") {
                modifiedOsInfo = "LIN-4180-${arch}"
            }
        }
    }

    return modifiedOsInfo
}

def shouldRenameArtifacts(component, isPRBuild, repoName) {
    return (component in ["switch", "nighty_build", "pr"]) &&
           (!isPRBuild || (isPRBuild && repoName?.startsWith("sw")))
}

def extractVersionAndBuildTag(env) {
    def version = "unknown"
    def buildTag = ""

    if (env.CHANGE_ID) {
        def versionFile = "${env.WORKSPACE}/VERSION"
        if (fileExists(versionFile)) {
            def content = readFile(versionFile).trim()
            def parts = content.split("_")
            version = parts[0]
            if (parts.size() > 1) {
                buildTag = parts[1]
            }
        }
    } else {
        def releaseContent = readFile(env.release_file_name).trim()
        def swBaseLine = releaseContent.split('\n').find { it.toLowerCase().startsWith("sw_base:") }

        if (swBaseLine) {
            def swBase = swBaseLine.split(":")[1].trim()
            def swName = swBase.tokenize('/').last()
            def parts = swName.replace("SW_", "").split("_")
            version = parts[0]
            if (parts.size() >= 2) {
                buildTag = parts[1]
            }
        }
    }

    return [version, buildTag]
}

def collectTgzFiles(env, component) {
    return findFiles(glob: '*.tgz').collect { it.path }
}

---------------------------------------------------check recent commits------------------------------------

def call(params = [:]) {
    println "Inside the Check Recent Commits"
    println "[DEBUG] Params received: ${params}"
    println "[DEBUG] releaseFileName: ${params.releaseFileName}"

    if (!params.project_repo) {
        error "[ERROR] Missing 'project_repo' parameter"
    }

    def foundationBitbucketBaseUrl = params.FOUNDATION_BITBUCKET_BASE_URL
    def BitbucketBaseUrl = params.BITBUCKET_BASE_URL
    def bitbucketCredentialsId = params.BITBUCKET_CREDENTIALS_ID
    def result = [foCommitFound: false, CmpCommitStatus: [:]]

    if (fileExists(params.releaseFileName)) {
        println "Inside the Check Recent Commits if condition"
        def releaseFileContent = readFile(file: params.releaseFileName)
        println "[DEBUG] Original release file content:\n${releaseFileContent}"
        def releaseComponents = releaseFileContent.split('\n')

        def updatedReleaseComponents = []
        def forceAdded = false

        releaseComponents.each { line ->
            echo "[DEBUG] Processing line: ${line}"
            def parts = line.split(':')
            if (parts.size() < 2) {
                updatedReleaseComponents << line
                return
            }
            def component = parts[0].trim()
            def branch = parts[1].trim()

            def repoUrl = component.startsWith('fo_') ? "${foundationBitbucketBaseUrl}/${component}.git" : "${BitbucketBaseUrl}/${component}.git"

            def recentCommit = checkRecentCommit(component, repoUrl, branch, bitbucketCredentialsId)
            echo "[DEBUG] Recent Commit for ${component}: ${recentCommit}"

            if (component.startsWith('fo_')) {
                if (recentCommit) {
                    updatedReleaseComponents << "FORCE=1\n${line}"
                    result.foCommitFound = true
                    forceAdded = true
                } else {
                    updatedReleaseComponents << line
                }
            } else if ((component.startsWith('sw_') || component.startsWith('cl_') || component.startsWith('cli_') || component.startsWith('clq_') || component.startsWith('ma_')) && !result.foCommitFound) {
                if (recentCommit && !forceAdded) {
                    updatedReleaseComponents << "FORCE=1\n${line}"
                    result.CmpCommitStatus[component] = recentCommit
                    forceAdded = true
                } else {
                    updatedReleaseComponents << line
                }
            } else {
                updatedReleaseComponents << line
            }

            if (forceAdded) {
                echo "[DEBUG] Force added, exiting loop."
                return
            }
        }

        println "[DEBUG] Updated release file content:\n${updatedReleaseComponents.join('\n')}"
        writeFile file: "./${params.releaseFileName}", text: updatedReleaseComponents.join('\n')
    }

    return result
}

def checkRecentCommit(String component, String repoUrl, String branchName, String bitbucketCredentialsId) {
    script {
        def baseDir = "${env.WORKSPACE}/checkcommit"
        def safeBranch = branchName.replaceAll('/', '_')
        def tmpDir = "${baseDir}/${component}/${safeBranch}"
        echo "[DEBUG] Checking recent commit for ${component} in ${tmpDir}"

        withCredentials([usernamePassword(credentialsId: bitbucketCredentialsId, usernameVariable: 'BITBUCKET_USER', passwordVariable: 'BITBUCKET_PASS')]) {
            sh """
                mkdir -p ${tmpDir}
                cd ${tmpDir}
                if [ ! -d ".git" ]; then
                    git clone --branch ${branchName} --single-branch https://\$BITBUCKET_USER:\$BITBUCKET_PASS@${repoUrl} .
                else
                    git remote set-url origin https://\$BITBUCKET_USER:\$BITBUCKET_PASS@${repoUrl}
                    git fetch origin ${branchName}:${branchName}
                    git checkout ${branchName}
                    git reset --hard origin/${branchName} || true
                fi
            """
        }

        def lastCommitCount = sh(
            script: """cd ${tmpDir} && git log origin/${branchName} --since="24 hours ago" --pretty=oneline | wc -l""",
            returnStdout: true
        ).trim().toInteger()

        echo "[DEBUG] Last Commit Count for ${component}: ${lastCommitCount}"

        if (lastCommitCount > 0) {
            echo "Recent commit found in branch ${branchName} for component ${component} within the last 24 hours."
            return true
        } else {
            echo "No recent commit found in branch ${branchName} for component ${component} within the last 24 hours. Skipping."
            return false
        }
    }
}


def checkRecentCommitForManualTrigger(String releaseFileName) {
    script {
        def params = readYaml file: './Jenkins/params.yaml'
        def foundationBitbucketBaseUrl = params.FOUNDATION_BITBUCKET_BASE_URL
        def BitbucketBaseUrl = params.BITBUCKET_BASE_URL
        def bitbucketCredentialsId = params.BITBUCKET_CREDENTIALS_ID

        def releaseFileContent = readFile(file: "${releaseFileName}")
        println "[DEBUG] Original release file content:\n${releaseFileContent}"

        def releaseComponents = releaseFileContent.split('\n')
        releaseComponents.each { line ->
            echo "[DEBUG] Processing line: ${line}"
            if (!line.contains(':')) {
                return // Skip lines without component:branch format
            }

            def parts = line.split(':')
            if (parts.size() < 2) {
                return // Skip malformed lines
            }

            def component = parts[0].trim()
            def branchName = parts[1].trim()

            def repoUrl = component.startsWith('fo_') ?
                "${foundationBitbucketBaseUrl}/${component}.git" :
                "${BitbucketBaseUrl}/${component}.git"

            def baseDir = "${env.WORKSPACE}/checkcommit"
            def safeBranch = branchName.replaceAll('/', '_')
            def tmpDir = "${baseDir}/${component}/${safeBranch}"

            echo "[DEBUG] Checking recent commit for ${component} in ${tmpDir}"

            withCredentials([usernamePassword(credentialsId: bitbucketCredentialsId, usernameVariable: 'BITBUCKET_USER', passwordVariable: 'BITBUCKET_PASS')]) {
                sh """
                    mkdir -p ${tmpDir}
                    cd ${tmpDir}
                    if [ ! -d ".git" ]; then
                        git clone --branch ${branchName} --single-branch https://\$BITBUCKET_USER:\$BITBUCKET_PASS@${repoUrl} .
                    else
                        git remote set-url origin https://\$BITBUCKET_USER:\$BITBUCKET_PASS@${repoUrl}
                        git fetch origin ${branchName}:${branchName}
                        git checkout ${branchName}
                        git reset --hard origin/${branchName} || true
                    fi
                """
            }
        }
    }
}

--------------------------------------------------create bitbucketrepos.groovy-------------------------------------------------
def call(Map params = [:]) {
    def sourceBranches = params.sourceBranches
    def destBranch = params.destBranch
    def repoName = params.repoName
    def projectKey = params.projectKey
    def bitbucketCreds = params.bitbucketCreds

    def repoSlug = repoName.toLowerCase()

    def validateBranch = { projKey, repo, branchName ->
        def encodedBranch = java.net.URLEncoder.encode(branchName, 'UTF-8')
        def branchUrl = "https://bitbucket.fi.dev/rest/api/1.0/projects/${projKey}/repos/${repo}/branches?filterText=${encodedBranch}"
        def response = httpRequest(url: branchUrl, httpMode: 'GET', authentication: bitbucketCreds, validResponseCodes: '200')
        def json = readJSON text: response.content
        return json.values.any { it.displayId.equalsIgnoreCase(branchName.trim()) }
    }

    def prExists = { projKey, repo, srcBranch, targetBranch ->
        def encodedDest = java.net.URLEncoder.encode("refs/heads/${targetBranch}", 'UTF-8')
        def url = "https://bitbucket.fi.dev/rest/api/1.0/projects/${projKey}/repos/${repo}/pull-requests?at=${encodedDest}&state=OPEN"
        def response = httpRequest(url: url, httpMode: 'GET', authentication: bitbucketCreds, validResponseCodes: '200')
        def json = readJSON text: response.content
        return json.values.any { it.fromRef.id == "refs/heads/${srcBranch}" && it.toRef.id == "refs/heads/${targetBranch}" }
    }

    if (!validateBranch(projectKey, repoSlug, destBranch)) {
        error "Destination branch '${destBranch}' does NOT exist in ${repoSlug}. Aborting."
    }

    def invalidSources = []
    sourceBranches.each { srcBranch ->
        if (!validateBranch(projectKey, repoSlug, srcBranch)) {
            invalidSources << srcBranch
        }
    }
    if (invalidSources) {
        error "Source branches not found: ${invalidSources.join(', ')}"
    }

    def summary = []
    sourceBranches.each { srcBranch ->
        echo "Creating PR: ${srcBranch} ‚Üí ${destBranch} in repo ${repoName}..."

        if (prExists(projectKey, repoSlug, srcBranch, destBranch)) {
            echo "PR already exists for ${srcBranch} to ${destBranch}. Skipping."
            summary << "SKIPPED: ${srcBranch} to ${destBranch}"
            return
        }

        def apiUrl = "https://bitbucket.fi.dev/rest/api/1.0/projects/${projectKey}/repos/${repoSlug}/pull-requests"
        def payload = [
            title      : "Merge ${srcBranch} to ${destBranch}",
            description: "Automated PR created by Jenkins pipeline for merging ${srcBranch} into ${destBranch}",
            fromRef    : [id: "refs/heads/${srcBranch}", repository: [slug: repoSlug, project: [key: projectKey]]],
            toRef      : [id: "refs/heads/${destBranch}", repository: [slug: repoSlug, project: [key: projectKey]]]
        ]

        echo "Payload: ${groovy.json.JsonOutput.prettyPrint(groovy.json.JsonOutput.toJson(payload))}"

        try {
            def response = httpRequest(
                url: apiUrl,
                httpMode: 'POST',
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload),
                authentication: bitbucketCreds,
                validResponseCodes: '200:299'
            )
            echo "PR created successfully for ${srcBranch}: Status ${response.status}"
            summary << "SUCCESS: ${srcBranch} ‚Üí ${destBranch}"
        } catch (err) {
            if (err.toString().contains("409")) {
                echo "Bitbucket returned 409 (Conflict) for ${srcBranch} to ${destBranch}. Likely same commit. Skipping."
                summary << "SKIPPED (Same Commit): ${srcBranch} to ${destBranch}"
            } else {
                echo "Failed to create PR for ${srcBranch}: ${err}"
                summary << "FAILED: ${srcBranch} to ${destBranch}"
            }
        }
    }

    echo "=== PR Creation Summary ==="
    summary.each { echo it }
}

--------------------------------------fetch resources.groovy-------------------------------------------------
def getpodAgents() {
    def yaml = libraryResource('fi/IST/ocPodAgents.yml')
    return yaml
}

def getIstPodAgents() {
    def yaml = libraryResource('fi/IST/istPodAgents.yaml')
    return yaml
}

def getistPodAgentsRhel9() {
    def yaml = libraryResource('fi/IST/istPodAgentsRhel9.yaml')
    return yaml
}

def buildAgents() {
    def yamlFileContent = libraryResource('fi/IST/Agents.yaml')
    def yamlFile = readYaml text: yamlFileContent
    return yamlFile.agent_labels
}


def getCheckmarxBranchType(){
    if(env.BRANCH_NAME.startsWith('feature/') || env.BRANCH_NAME.startsWith('PR')){
        cxBranch = 'feature'
    }else if(env.BRANCH_NAME.startsWith('develop')){
        cxBranch = 'dev'
    }else if(env.BRANCH_NAME.startsWith('release/')){
        cxBranch = 'prod'
    }else{

        error('Invalid Branch Type')
    }
    return cxBranch
}

// Send approval/reject email
def emailApprovalReject(Map params = [:]) {
    def userInput
    def buildUrl = env.BUILD_URL
    def emailList = params.emailRecipients.split(',')
    def allowedUsers = params.allowedUsers.split(',')
    def json = readJSON text: params.output


    // Helper function to determine the subject
    def getSubject = { SASTStatus, SCAStatus, cxProjectName, CheckmarxoneProjectname ->
        if (SASTStatus == 'FAIL' && SCAStatus == 'FAIL') {
            return "!!! ACTION REQUIRED: Policy-As-Code Check FAILED for ${cxProjectName} and ${CheckmarxoneProjectname} !!!"
        } else if (SASTStatus == 'FAIL') {
            return "!!! ACTION REQUIRED: Policy-As-Code Check FAILED for ${cxProjectName} !!!"
        } else if (SCAStatus == 'FAIL') {
            return "!!! ACTION REQUIRED: Policy-As-Code Check FAILED for ${CheckmarxoneProjectname} !!!"
        } else {
            return ">>> Policy-As-Code Check PASSED for ${cxProjectName} and ${CheckmarxoneProjectname} <<<"
        }
    }

    // Helper function to determine the attachments and unstash
    def getAttachmentsAndUnstash = { SASTStatus, SCAStatus ->
        def attachments = []
        if (SASTStatus == 'FAIL') {
            unstash 'checkmarx_reports'
            attachments << "Checkmarx/Reports/**"
        }
        if (SCAStatus == 'FAIL') {
            unstash 'cxone-ast-results'
            attachments << "cx_result.pdf"
        }
        return attachments
    }

    def SASTStatus = json.evaluationDetails.SASTStatus
    def SCAStatus = json.evaluationDetails.SCAStatus
    def subject = getSubject(SASTStatus, SCAStatus, params.cxProjectName, params.CheckmarxoneProjectname)
    def attachments = getAttachmentsAndUnstash(SASTStatus, SCAStatus)

    def attachmentsPattern = attachments.join(',')
    if (attachmentsPattern) {
        attachmentsPattern += ",${params.resultsFile}"
    }

    emailext(
            subject: "${subject}",
            body: """
            <p>The Policy-As-Code check resulted in the following:</p>
            <ul>
                <li><strong>SASTStatus:</strong> <span style="color:${SASTStatus == 'Pass' ? 'green' : 'red'};">${SASTStatus == 'Pass' ? SASTStatus + ' &#x1F389;' : SASTStatus + ' &#x274C;'}</span></li>
                <li><strong>SCAStatus:</strong> <span style="color:${SCAStatus == 'Pass' ? 'green' : 'red'};">${SCAStatus == 'Pass' ? SCAStatus + ' &#x1F389;' : SCAStatus + ' &#x274C;'}</span></li>
            </ul>
            <p>Please review the issue and approve or reject the pipeline to proceed to the next stage.</p>
            <p>
                <a href="${buildUrl}input">Approve or Reject</a>
            </p>
        """,
            mimeType: 'text/html',
            attachmentsPattern: attachmentsPattern,
            to: emailList.join(',')
    )
    try {
        userInput = timeout(time: 48, unit: 'HOURS') {
            input message: 'Policy-As-Code Failed. Approve or Reject the pipeline?',
                    parameters: [choice(name: 'Action', choices: 'Approve\nReject', description: 'Choose an action')],
                    submitter: allowedUsers.join(','),
                    ok: 'Submit'
        }

        if (userInput == 'Reject') {
            error("Build rejected by user due to Policy-As-Code failure")
        } else {
            echo "Build approved by user despite Policy-As-Code failure"
        }
    } catch (Exception e) {
        if (userInput == 'Abort') {
            echo("Build Aborted by user")
            currentBuild.result='ABORTED'
        } else {
            echo "Timeout reached without user input. Automatically rejecting the build."
            error("Build automatically rejected due to timeout")
        }
    }
}




--------------------------------------------------ocpbuildpipeline.groovy-------------------------------------------------
import fi.ist.*
import groovy.json.JsonOutput
import java.util.TimeZone
import java.util.Date
import java.text.SimpleDateFormat

def extractCxScanId(String logText) {
    def matcher = logText =~ /Scan ID is \s*(\d+)/
    return matcher ? matcher[0][1] : null
}

def extractCxOneScanId(String logText) {
    def matcher = logText =~ /Wait for scan to complete (\S+)/
    return matcher ? matcher[0][1] : null
}

def extractJiraTickets(consoleOutput) {
    def updatedJiraTickets = []
    def newJiraTickets = []
    
    // Collect Updating JIRA issue tickets
    def updateMatcher = consoleOutput =~ /Updating JIRA issue #(ISTDEV-\d+)/
    while (updateMatcher.find()) {
        updatedJiraTickets << updateMatcher.group(1)
    }
    
    // Collect New issue created tickets
    def newIssueMatcher = consoleOutput =~ /New issue created. #(ISTDEV-\d+)/
    while (newIssueMatcher.find()) {
        newJiraTickets << newIssueMatcher.group(1)
    }
    
    return [updatedJiraTickets, newJiraTickets]
}

def extractOsInfo(consoleOutput) {
    def matcher = consoleOutput =~ /INFO: OS \[([^\]]*)\]/
    def osInfo = matcher ? matcher[0][1] : null
    if (osInfo == null) {
        error("OS information not found. Failing the pipeline.")
    }
    return osInfo
}

def call(Map configval = [:]){
     
    echo "Inside OCPBuildPipeline.groovy ...."
  	
    echo "Branch: ${configval.branch}"
    echo "Build Type: ${configval.buildType}"
    echo "swComponent: ${configval.swComponent}"
    echo "swComponentType: ${configval.swComponentType}"
    echo "selectedOsName: ${configval.selectedOsName}"
    echo "selectedOsValue: ${configval.selectedOsValue}"
    echo "Build Component: ${configval.buildcomponent}"
    echo "Build Release File: ${configval.RELEASE_FILE}"
    echo "Enable Full Build: ${configval.FULL_BUILD_CHECKBOX}"
  	
  	def jobNameParts = JOB_NAME.tokenize('/') as String[]
    def jobNamePart = "${jobNameParts[2]}/${jobNameParts[3]}"
     def datas = ""
   // def datas, datares

   //def releaseInfoContent = ""

    String PathVar, os_dir, myArtifact
    def podTemplate = fetchResources.getIstPodAgents()
  	def opaPodTemplate = fetchResources.getpodAgents()
  	//def oracleHomePath
  	def foCommitFound
  	def CmpCommitFound
    def triggerTimeEDT = new Date()
    def triggerTimeISTStr
  	def triggerTimeEDTStr
    
  	String selectedYaml
    switch(configval.selectedOsName) {
        case 'RHEL8OCP':
            selectedYaml = fetchResources.getIstPodAgents()
            break
        case 'RHEL9OCP':
            selectedYaml = fetchResources.getistPodAgentsRhel9()
            break
        default:
            error("Unsupported OS: ${configval.selectedOsName}")
    }
  
	pipeline {
        agent {
            kubernetes {
                cloud 'ist-build-jenkins'
                yaml selectedYaml
            }
        }
        environment {
          	SOURCE_BRANCH = "${env.CHANGE_BRANCH ?: env.BRANCH_NAME}"
          	CREDENTIALS_ID ="cm-credentials-id"
            OS_NAME = "${configval.selectedOsName}"
        }
      
        options {
            timestamps()
            buildDiscarder(logRotator(numToKeepStr: '10', artifactNumToKeepStr: '10'))
          	copyArtifactPermission('*')
        }
		stages {
            stage('Set Java and Oracle Home') {
                steps {
                    container('ist-build-agent') {
                        script {
                            if (configval.buildcomponent == 'nighty_build') {
                                // Adding current build description
                                currentBuild.description = "${configval.RELEASE_FILE}:${configval.selectedOsName}"
                            } else {
                                // Adding current build description
                                currentBuild.description = "${configval.selectedOsName}"
                            }
                          	
                            SimpleDateFormat edtFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
                            edtFormat.setTimeZone(TimeZone.getTimeZone("America/New_York"))
                            triggerTimeEDTStr = edtFormat.format(new Date()) // Assign value
                            env.TRIGGER_TIME_EDT = triggerTimeEDTStr

                            triggerTimeISTStr = ocpEmailConfig.convertEDTtoIST(triggerTimeEDTStr)
                            env.TRIGGER_TIME_IST = triggerTimeISTStr

                            echo "triggerTimeISTStr: ${triggerTimeISTStr}"
                            echo "triggerTimeEDTStr: ${triggerTimeEDTStr}"

                            def javaPath = sh(
                                script: '''
                                    JAVAC_PATH=$(which javac)
                                    JAVA_HOME=$(readlink -f "$JAVAC_PATH" | sed 's:/bin/javac::')
                                    echo "$JAVA_HOME"
                                ''',
                                returnStdout: true
                            ).trim()

                            def oracleHomePath = sh(script: 'echo $ORACLE_HOME', returnStdout: true).trim()
                            def oracleVersion = oracleHomePath.tokenize('/')[-2] 

                            def javaExists = sh(script: "[ -d '${javaPath}' ] && echo exists || echo missing", returnStdout: true).trim()
                            def oracleExists = sh(script: "[ -d '${oracleHomePath}' ] && echo exists || echo missing", returnStdout: true).trim()

                            if (javaExists != "exists") {
                                error "Java path '${javaPath}' does not exist."
                            }
                            if (oracleExists != "exists") {
                                error "Oracle path '${oracleHomePath}' does not exist."
                            }

                            def updatedOracleVersion =  "ORA-${oracleVersion}"

                            env.java_home = javaPath
                            env.oracle_home = "${oracleHomePath}\n${updatedOracleVersion}"

                            echo "JAVA_HOME set to: ${env.java_home}"
                            echo "ORACLE_HOME set to: ${env.oracle_home}"
                        }
                    }
                }
            }
            stage('Get PR Author email') {
                when {
                    expression { return env.CHANGE_ID != null }
                }
                steps {
                    script {
                        ocpEmailConfig.getPRAuthorEmail()
                    }
                }
            }  

          	stage('Setup') {
                steps {
                    container('ist-build-agent') {
                        script {
                            println "Setting Parameters"
                            try {
                                datas = readYaml file: "./Jenkins/params.yaml"
                                //def datares = readYaml(text: libraryResource('fi/IST/Parameters.yaml'))

                                def component = configval.swComponent
                                def buildType = configval.buildType?.toLowerCase()
                                def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')

                                def useBranchBuildList = false

                                switch (component) {
                                    case "PR":
                                    case "switch":
                                    case "fo":
                                        if (buildType == "development") {
                                            def readContent = readFile './Jenkins/branch-build.list'
                                            writeFile file: './Jenkins/branch-build.list',
                                                text: readContent + "\n${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                            echo "Updated branch-build.list for ${component} with ${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                            useBranchBuildList = true
                                            env.release_file_name = './Jenkins/branch-build.list'
                                        } else {
                                            echo "Release file will be passed as an input to build script for ${component}."
                                        }
                                        break

                                    case "mas":
                                    case "clearing":
                                        if (buildType == "development") {
                                            def readContent = readFile './Jenkins/branch-build.list'
                                            writeFile file: './Jenkins/branch-build.list',
                                                text: readContent + "\n${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                            echo "Updated branch-build.list for ${component} with ${jobNameParts[3].toLowerCase()}:${env.SOURCE_BRANCH}"
                                            useBranchBuildList = true
                                            env.release_file_name = './Jenkins/branch-build.list'
                                        } else if (buildType == "release") {
                                            echo "Release file will be passed as an input to build script for ${component}."
                                        } else {
                                            echo "Unknown build type for ${component}. Defaulting to release file."
                                        }
                                        break

                                    case "nighty_build":
                                        env.release_file_name = "${configval.RELEASE_FILE}.release"
                                  		echo "Collected release file name from ${configval.RELEASE_FILE} for nightly build."
                                        break

                                    default:
                                        echo "Unknown or unsupported swComponent: ${component}. Defaulting to release file."
                                        break
                                }

                            } catch (Exception e) {
                                echo "Error occurred during Setup stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Setup stage failed.")
                            }
                        }
                    }
                }
            }
            stage('Check commit and Update Release File') {
                when {
                    expression { configval.buildcomponent == 'nighty_build' }
                }
                steps {
                    script {
                        try {
                            container('ist-build-agent') {
                                def isManualTrigger = currentBuild.rawBuild.getCause(hudson.model.Cause$UserIdCause) != null
                                def isTimerTrigger = !isManualTrigger
                                echo "isManualTrigger: ${isManualTrigger}"
                                echo "isTimerTrigger: ${isTimerTrigger}"

                                def releaseFileName = "${env.release_file_name}"

                                if (isManualTrigger) {
                                    echo "Manual trigger detected..."
                                    foCommitFound = true
                                    CmpCommitFound = false
                                    env.foCommitFound = foCommitFound
                                    env.CmpCommitFound = CmpCommitFound

                                    def fullBuildCheckboxSelected = "${configval.FULL_BUILD_CHECKBOX}"
                                    if (!fullBuildCheckboxSelected) {
                                        error("Full build checkbox not selected. Failing the pipeline.")
                                    } else {
                                        echo "Full build checkbox selected. Updating release file..."
                                        def releaseFileContent = readFile(releaseFileName)
                                        releaseFileContent = releaseFileContent.replaceFirst(/(?m)^BUILDOPT=/, 'FORCE=1\nBUILDOPT=')
                                        writeFile file: releaseFileName, text: releaseFileContent
                                        echo "Updated release file content:\n${releaseFileContent}"
                                        checkRecentCommits.checkRecentCommitForManualTrigger(releaseFileName)
                                    }
                                } else if (isTimerTrigger) {
                                    echo "Timer trigger detected..."
                                    echo "Performing recent commits and updating release file content..."
                                    datas1 = readYaml file: "./Jenkins/params.yaml"
                                    echo "releaseFileName: ${releaseFileName}"
                                    def result = checkRecentCommits([
                                        project_repo: datas1.Project_repo,
                                        releaseFileName: releaseFileName,
                                        BITBUCKET_BASE_URL: datas1.BITBUCKET_BASE_URL,
                                        FOUNDATION_BITBUCKET_BASE_URL: datas1.FOUNDATION_BITBUCKET_BASE_URL,
                                        REL_BITBUCKET_BASE_URL: datas1.REL_BITBUCKET_BASE_URL,
                                        BITBUCKET_CREDENTIALS_ID: datas1.BITBUCKET_CREDENTIALS_ID
                                    ])
                                    foCommitFound = result.foCommitFound
                                    CmpCommitFound = result.CmpCommitStatus
                                    echo "foCommitFound: ${foCommitFound}"
                                    echo "CmpCommitFound: ${CmpCommitFound}"
                                    env.foCommitFound = foCommitFound
                                    env.CmpCommitFound = CmpCommitFound

                                    if (!foCommitFound && CmpCommitFound.isEmpty()) {
                                        echo "No commit found in the last 24 hours for the release file: ${env.release_file_name}"
                                        currentBuild.result = 'SUCCESS'
                                        env.SKIP_STAGE_NOCOMMIT = 'true'
                                        return
                                    }
                                } else {
                                    error("Unknown trigger type. Failing the pipeline.")
                                }

                                echo "foCommitFound: ${env.foCommitFound}"
                                echo "CmpCommitFound: ${env.CmpCommitFound}"

                                if (foCommitFound && !CmpCommitFound) {
                                    env.trigger = "FullTrigger"
                                } else if (!foCommitFound && CmpCommitFound) {
                                    env.trigger = "PartialTrigger"
                                } else {
                                    env.trigger = "NoTrigger"
                                }

                                echo "env.trigger: ${env.trigger}"
                            }
                        } catch (Exception e) {
                            echo "Error occurred during 'Check commit and Update Release File' stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Check commit and Update Release File stage failed.")
                        }
                    }
                }
            }
            stage('Download dependency') {
                when { expression { return env.SKIP_STAGE_NOCOMMIT != 'true' } }
                steps {
                    container('ist-build-agent') {
                        script {
                            try {
                                println "Stage: Download dependency repos."
                                dir('gitroot') {
                                    BUILD_TYPE = configval.BUILD_TYPE
                                    new CppBuild().downloaddependency(
                                        project_repo: "${datas.Project_repo}",
                                        gitCreds: "cm-credentials-id"
                                    )
                                }
                            } catch (Exception e) {
                                echo "Error occurred during 'Download dependency' stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Download dependency stage failed.")
                            }
                        }
                    }
                }
            }
          
            /* stage('Patch Checkmarx Script') {
                steps {
                  script {
                    new CppBuild().patchCheckmarxBranchLogic()
                  }
                }
              } */
          
          
            stage('Build') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                    IST_TOOLS = "${env.WORKSPACE}/gitroot/ist-build-tools"
                }
                when { expression { return env.SKIP_STAGE_NOCOMMIT != 'true' } }
                steps {
                    container('ist-build-agent') {
                        script {
                            try {
                                def component = configval.swComponent?.toLowerCase()
                                def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')
                                def repoName = jobNameParts[3]?.toLowerCase()
                                def skipZipPrefixes = ['develop/SW', 'develop/CL', 'develop/MA', 'develop/']
                                def shouldSkipZip = skipZipPrefixes.any { env.BRANCH_NAME?.startsWith(it) }
                              	//env.trigger = "PartialTrigger" this should be enable when you are disabling check commit stage.########

                                if (params.productname == 'ist-release-info') {
                                    myArtifact = new CppBuild().build(
                                        artFile: "${jobNameParts[2]}/${env.BRANCH_NAME.replaceAll('/', '_')}/${BUILD_NUMBER}",
                                        build_Flags: "${datas.build.Flags}",
                                        os: "${os_dir}",
                                        releasefile: sh(script: "cat ${GITROOT}/ist-release-info/rel_info/build.release", returnStdout: true).trim(),
                                        ArtCred: "svcacct_istartifact"
                                    )
                                } else {
                                    myArtifact = new OcpCppBuild().build(
                                        artFile: "${jobNameParts[2]}/${env.BRANCH_NAME.replaceAll('/', '_')}/${BUILD_NUMBER}",
                                        build_Flags: "${datas.build.Flags}",
                                        os: "${os_dir}",
                                        java_home: "${env.java_home}",
                                        oracle_home: "${env.oracle_home}",
                                        releasefile: "${env.release_file_name}",
                                        Build_Component: "${configval.buildcomponent}",
										selectedOsName: "${configval.selectedOsName}",
                                        ArtCred: "svcacct_istartifact"
                                    )
                                }

                                 if (myArtifact != "NoArtifact") {
                                    def artifactFiles = myArtifact.split(',').findAll { it?.trim() }.collect { "\"${it}\"" }.join(' ')
                                    if (artifactFiles) {
                                        sh "cp ${artifactFiles} ${env.WORKSPACE}"
                                    } else {
                                        println "No valid artifact files to copy."
                                    }

                                    println "Component value: ${component}"
                                    println "isPRBuild value: ${isPRBuild}"
                                    println "repoName value: ${repoName}"
                                    def filesToZip = []
                                    if (artifactBuildTgz.shouldRenameArtifacts(component, isPRBuild, repoName)) {
                                        println "Inside the rename artifacts if condition"
                                        def (version, buildTag) = artifactBuildTgz.extractVersionAndBuildTag(env)
                                        filesToZip = artifactBuildTgz.renameArtifacts(myArtifact, version, buildTag, env, configval)
                                    } else {
                                        filesToZip = artifactBuildTgz.collectTgzFiles(env, component)
                                    }

                                    if (!isPRBuild && !shouldSkipZip) {
                                        if (filesToZip) {
                                            artifactBuildTgz.zipArtifacts(filesToZip, configval, env)
                                        } else {
                                            error("No artifact generated.")
                                        }
                                    } else {
                                        println "Skipping zipping artifacts for PR build or specific develop branches."
                                    }
                                }
                            } catch (Exception e) {
                                echo "Error occurred during Build stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Build stage failed.")
                            }
                        }
                    }
                }
            }
            stage('Upload to Artifactory') {
				when {
					expression {
						if (configval.buildcomponent == 'nighty_build' && env.SKIP_STAGE_NOCOMMIT != 'true') {
							echo 'Detected Nighty Build and SKIP_STAGE_NOCOMMIT is not true'
							return true
						} else if (env.BRANCH_NAME.startsWith('PR') || env.BRANCH_NAME.startsWith('feature-PR')) {
							echo 'Stage skipped because branch is PR or feature'
							return false
						} else if (configval.buildcomponent == 'nighty_build' && env.SKIP_STAGE_NOCOMMIT == 'true') {
							echo 'Stage skipped because no commit found'
							return false
						} else if (env.BRANCH_NAME.startsWith('develop/SW_') || 
								   env.BRANCH_NAME.startsWith('develop/CL_') || 
								   env.BRANCH_NAME.startsWith('develop/MA_')) {
							echo 'Running the stage because branch is develop/SW_, develop/CL_, or develop/MA_'
							return true
						} else {
							echo 'Stage skipped because none of the conditions were met'
							return false
						}
					}
				}
                steps {
					script {
						try {
							def datas2 = readYaml file: "./Jenkins/params.yaml"
							def zipFilesPath = sh(script: "ls ${env.WORKSPACE}/*.zip | awk -F'/' '{print \$NF}'", returnStdout: true).trim().toString()
							def tgzFilesPath = sh(script: "ls ${env.WORKSPACE}/*.tgz | awk -F'/' '{print \$NF}'", returnStdout: true).trim().toString()
							def zipFiles = zipFilesPath ? zipFilesPath.split('\n') : []
							def tgzFiles = tgzFilesPath ? tgzFilesPath.split('\n') : []
							def buildType = "development"
							def repoUrl = datas2.artifactory.Path
							def zipSubPath = "rel_zip/release"
							def tgzSubPath = "rel_tgz/release/lin"

							if (zipFiles.size() == 0 && tgzFiles.size() == 0) {
								echo "No zip or tgz files found!"
							} else {
								zipFiles.each { zipFile ->
									echo "Uploading zip artifact: ${zipFile}"
									new OcpCppBuild().artifactUploadZip([
										artifactPath: zipFile,
										repoUrl: repoUrl,
										buildType: buildType,
										subPath: zipSubPath,
										artifactory: datas2.artifactory
									])
								}
								tgzFiles.each { tgzFile ->
									echo "Uploading tgz artifact: ${tgzFile}"
									new OcpCppBuild().artifactUploadTgz([
										artifactPath: tgzFile,
										repoUrl: repoUrl,
										buildType: buildType,
										subPath: tgzSubPath,
										artifactory: datas2.artifactory
									])
								}
							}
						} catch (Exception e) {
							echo "Error occurred during Upload Artifactory stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Upload Artifactory stage failed.")
						}
					}
				}
			}
            stage('Triggering Harness CD Pipeline') {
              	when { expression { return configval.buildcomponent == 'nighty_build' } }
                steps {
                    script {
                        if (configval.buildcomponent == 'nighty_build') {
                            if (env.SKIP_STAGE_NOCOMMIT == 'true') {
                                echo 'Skipping the triggering CD pipeline due to no commit found'
                            } else {
                                if (currentBuild.result == 'SUCCESS' || currentBuild.result == null) {
                                    def params = readYaml file: './Jenkins/params.yaml'

                                    // Enhanced logic: match release file first, then OS name
                                    def projectName = params.PROJECT_NAME.find { entry ->
                                        def parts = entry.split(':')
                                        def releaseFileMatch = parts.size() > 0 && parts[0] == configval.RELEASE_FILE
                                        def osNameMatch = parts.size() > 1 && parts[1] == configval.selectedOsName
                                        return releaseFileMatch && osNameMatch
                                    }

                                    def harnessUrl = params.HarnessCdPipelineTriggerUrl
                                    echo "Project Name: ${projectName}"
                                    echo "Harness URL: ${harnessUrl}"

                                    if (projectName) {
                                        def parts = projectName.split(':')
                                        def Agent_Name = parts.size() > 3 ? parts[3] : null
                                        def User_Account = parts.size() > 4 ? parts[4] : null
                                        echo "Agent Name: ${Agent_Name}"
                                        echo "User Account: ${User_Account}"

                                        if (Agent_Name && User_Account) {
                                            def payload = """
                                            {
                                                "ARTIFACT_NAME": "${env.ZIP_NAME}",
                                                "TARGET_SERVER": "${Agent_Name}",
                                                "USER_ACCOUNT": "${User_Account}"
                                            }
                                            """
                                            sh """
                                            echo 'Sending payload to Harness:'
                                            echo 'Harness trigger Url ----> ${harnessUrl}'
                                            curl -X POST -H 'content-type: application/json' --url '${harnessUrl}' -d '${payload}'
                                            """
                                        } else {
                                            echo 'Skipping CD pipeline as AGENT_NAME and USER_ACCOUNT are not provided in params.yaml'
                                        }
                                    } else {
                                        echo "No matching project found for releaseFile: ${configval.RELEASE_FILE}"
                                    }
                                } else {
                                    echo 'Skipping payload send as the build is not successful.'
                                }
                            }
                        } else {
                            echo 'Skipping the triggering CD pipeline this is Not Nighty Build'
                        }
                    }
                }
            }
          
            stage('Checkmarx') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                }
                when { expression { return configval.buildcomponent == 'nighty_build' } }
                steps {
                    container('ist-build-agent') {
                        script {
                            try {
                                def config = readYaml file: "./Jenkins/params.yaml"
                                def cxProjectNameParams = config.cxscan.isCxProjectName
                                def cxProjectName = "IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev"
                                env.isCheckmarxScan = config.cxscan.isCheckmarxScan.toString()
                                env.isOpaEnable = config.opaScan.isOpaEnable.toString()

                                if (configval.buildcomponent == 'nighty_build' &&
                                    env.SKIP_STAGE_NOCOMMIT != 'true' &&
                                    env.isCheckmarxScan == 'true') {

                                    def dayOfWeek = new Date().format('u').toInteger()
                                    def isIncrementalScan = !(dayOfWeek == 5)

                                    withCredentials([
                                        usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
                                    ]) {
                                        sh """
                                            printf "$JENKINS_USER\n$JENKINS_PASSWORD\n" > export:BLD_CREDENTIALS
                                            export USERID=$JENKINS_USER
                                            export USERACCESS=$JENKINS_PASSWORD
                                            if grep -q '^sw_base:' ${env.WORKSPACE}/${configval.RELEASE_FILE}.release; then
                                                sw_base_branch=\$(grep '^sw_base:' ${env.WORKSPACE}/${configval.RELEASE_FILE}.release | cut -d':' -f2)
                                                sed -i "s|^sw_segment:master|sw_segment:\${sw_base_branch}|" ${env.WORKSPACE}/${configval.RELEASE_FILE}.release
                                            fi
                                            grep -E '(:|_OS_)' ${env.WORKSPACE}/${configval.RELEASE_FILE}.release | grep -Ev 'OS_DB|OS_ZCLOPTMZD' > ${env.WORKSPACE}/${configval.RELEASE_FILE}.rel

                                            echo "Filtered Release File:"
                                            cat ${env.WORKSPACE}/${configval.RELEASE_FILE}.rel

                                            ${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts/build_checkmarx_jk.ksh -bt=develop ${env.WORKSPACE}/${configval.RELEASE_FILE}.rel
                                        """
                                    }

                                    def scanner = new fi.scan.CheckmarxScan()
                                    scanner.call([
                                        script: this,
                                        cxProjectName: cxProjectName,
                                        configval: configval,
                                        isIncrementalScan: isIncrementalScan
                                    ])

                                    archiveArtifacts artifacts: 'Checkmarx/Reports/*.html', allowEmptyArchive: true
                                    archiveArtifacts artifacts: 'Checkmarx/Reports/*.pdf', allowEmptyArchive: true

                                    def checkmarx_scanOutput = currentBuild.rawBuild.getLog(10000).join("\n")
                                    def checkmarx_scanId = extractCxScanId(checkmarx_scanOutput)

                                    if (checkmarx_scanId) {
                                        echo "Extracted CxOne Scan ID: ${checkmarx_scanId}"
                                    } else {
                                        echo "No Scan ID found in Checkmarx logs"
                                    }

                                    env.CHECKMARX_SCAN_ID = checkmarx_scanId
                                  	env.CX_PROJECT_NAME = "${cxProjectName}"
                                } else {
                                    echo 'Skipping Checkmarx stage due to unmet conditions'
                                }
                            } catch (Exception e) {
                                echo "Checkmarx stage failed: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                              	error("Checkmarx stage failed.")
                            }
                        }
                    }
                }
            }
            stage('Checkmarx One') {
                when { expression { return configval.buildcomponent == 'nighty_build' } }
                steps {
                    script {
                        try {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxOneProjectNameParams = config.cxonescan.isCxOneProjectName
                            def cxOneProjectName = "IST_NightlyBuilds_${cxOneProjectNameParams}_${configval.RELEASE_FILE}_dev"
                            def cxonetagId = config.cxonescan.tagId
                            def cxOneProjectGroup = config.cxonescan.projectGroup
                            env.isCheckmarxOneScan = config.cxonescan.isCheckmarxOneScan.toString()

                            if (configval.buildcomponent == 'nighty_build' &&
                                env.SKIP_STAGE_NOCOMMIT != 'true' &&
                                env.isCheckmarxOneScan == 'true') {

                                // Run Checkmarx One scan
                                def scanner = new fi.scan.CheckmarxOneScan()
                                scanner.call([
                                    script: this,
                                    configval: configval,
                                    cxOneProjectName: cxOneProjectName,
                                    cxonetagId: cxonetagId,
                                    cxOneProjectGroup: cxOneProjectGroup
                                ])
                            } else {
                                echo 'Skipping Checkmarx One stage due to unmet conditions'
                            }
                        } catch (Exception e) {
                            echo "Error occurred during 'Checkmarx One' stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Checkmarx One stage failed.")
                        }
                    }
                }
            }
            stage('Policy-As-Code') {
              	when {
                    allOf {
                      	expression { configval.buildcomponent == 'nighty_build' }
                        expression { env.SKIP_STAGE_NOCOMMIT != 'true' }
                        expression { env.isOpaEnable == 'true' }
                    }
                }
                steps {
                    container('python') {
                        script {
                            sh """
                            mkdir pac
                            """
                          	def eopaPath = "./eopa"
                            dir('pac') {
                                checkout([$class: 'GitSCM', branches: [[name: 'master']], extensions: [], userRemoteConfigs: [[credentialsId: 'cm-credentials-id', url: 'https://bitbucket.fi.dev/scm/tdodso/tdo_devsecops.git']]])
                                sh """
                                    git checkout master
                                    curl -fsSL -o ${eopaPath} https://github.com/StyraInc/enterprise-opa/releases/latest/download/eopa_Linux_x86_64
                                    chmod +x ${eopaPath}
                                """
                            }

                            // Read config and run Python script
                            def config = readYaml file: "${env.WORKSPACE}/Jenkins/params.yaml"
                            def cxOneProjectNameParams = config.cxonescan.isCxOneProjectName
                            def cxProjectNameParams = config.cxscan.isCxProjectName
                            def cxonetagId = config.cxonescan.tagId

							withCredentials([
								usernamePassword(credentialsId: 'IST-CheckMarx', passwordVariable: 'CX_PWD', usernameVariable: 'CX_USER'),
								usernamePassword(credentialsId: 'OPA_CXONE_SWITCH', passwordVariable: 'CXONE_PWD', usernameVariable: 'CXONE_USER'),
							]) {
								dir('pac') {
									sh """
										export https_proxy=http://mazproxy.fidev.local:8080
										export http_proxy=http://mazproxy.fidev.local:8080
										pip3 install -r requirements.txt
										sleep 5

										python3 secOps.py \\
											--cxone_client_id="${CXONE_USER}" \\
											--cxone_client_secret="${CXONE_PWD}" \\
											--cxOneProjectName="IST_NightlyBuilds_${cxOneProjectNameParams}_${configval.RELEASE_FILE}_dev" \\
											--cxOneBranchName="${env.BRANCH_NAME}" \\
											--scInternetFacing=false \\
											--vulnCategory=open \\
											--scAssetId="${cxonetagId}" \\
											--cxTeamId=653 \\
											--cxProjectName="IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev" \\
											--cxsast_username="${CX_USER}" \\
											--cxsast_password="${CX_PWD}" \\
											--output=json \\
											--debug
									"""
								}

                                // Run OPA logic
                                try {
                                    runOPAAndHandleResults(
                                        credentialsId: "cm-credentials-id",
                                        CheckmarxoneProjectname: "IST_NightlyBuilds_${cxOneProjectNameParams}_${configval.RELEASE_FILE}_dev",
                                        cxProjectName: "IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev"
                                    )
                                } catch (Exception e) {
                                    echo "Error occurred during Policy-As-Code stage: ${e.getMessage()}"
                            		currentBuild.result = 'FAILURE'
                            		error("Policy-As-Code stage failed.")
                                }
                            }
                        }
                    }
                }
            }
            stage('CxFlow Jira Integration') {
                when { expression { return configval.buildcomponent == 'nighty_build' } }
                steps {
                    script {
                        try {
                            def config = readYaml file: "./Jenkins/params.yaml"
                            def cxProjectNameParams = config.cxscan.isCxProjectName
                            def cxProjectName = "IST_NightlyBuilds_${cxProjectNameParams}_${configval.RELEASE_FILE}_dev"
                            env.isCxFlowEnable = config.cxFlowScan.isCxFlowEnable.toString()
                            def jiraTicket = config.cxFlowScan.jiraAssigneePerson

                            if (configval.buildcomponent == 'nighty_build') {
                                if (env.SKIP_STAGE_NOCOMMIT == 'true') {
                                    echo 'Skipping CxFlow Jira Integration stage due to no commit found'
                                } else if (env.isCxFlowEnable == 'true') {
                                    println "CXFLOW_PHASE_START: " + new Date().format("EEE MMM d yyyy HH:mm:ss z", TimeZone.getTimeZone('UTC'))
                                    println "Preparing to call CxFlow..."

                                    withCredentials([
                                        usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD'),
                                        usernamePassword(credentialsId: 'IST-CheckMarx', usernameVariable: 'Checkmarx_User', passwordVariable: 'Checkmarx_Passwd')
                                    ]) {
                                        def scanner = new fi.scan.CxFlowIntegration()
                                        scanner.call([
                                            script: this,
                                            configval: configval,
                                            cxProjectName: cxProjectName,
                                            jiraTicket: jiraTicket,
                                            vaultUser: env.JENKINS_USER,
                                            vaultPassword: env.JENKINS_PASSWORD,
                                            checkmarxUser: env.Checkmarx_User,
                                            checkmarxPasswd: env.Checkmarx_Passwd
                                        ])
                                    }
                                } else {
                                    echo 'Skipping CxFlow Jira Integration stage because CxFlow is not enabled'
                                }
                            } else {
                                echo "Skipping CxFlow Jira Integration stage because branch is not Nighty build or agent is not Rhel"
                            }
                        } catch (Exception e) {
                            echo "Error occurred during 'CxFlow Jira Integration' stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("CxFlow Jira Integration stage failed.")
                        }
                    }
                }
            }
        }
        post {
            always {
                script {
                    echo "Current build result: ${currentBuild.result}"
                    def yaml = readYaml file: "./Jenkins/params.yaml"
                    def defaultEmail = yaml.NotifyEmail
                    def isPRBuild = env.CHANGE_ID != null
                    def email = isPRBuild && env.PR_AUTHOR_EMAIL ? env.PR_AUTHOR_EMAIL : defaultEmail
                    def selectedOsName = "${configval.selectedOsName}"
                  	def releaseFileName = "${configval.RELEASE_FILE}"
                  	def emailcxProjectName = env.CX_PROJECT_NAME
                    def emailcxOneProjectName = env.CXONE_PROJECT_NAME
                    def emailcxScanId = env.CHECKMARX_SCAN_ID
                    def emailcxOneScanId = env.CHECKMARXONE_SCAN_ID
                    if (env.BRANCH_NAME.startsWith('PR') || env.BRANCH_NAME.startsWith('feature-PR')) {
                        echo "Current build result: ${currentBuild.result}"
                        if (currentBuild.result == 'SUCCESS') {
                            ocpEmailConfig.sendBuildNotificationForPrBuilds('SUCCESS', email)
                        } else if (currentBuild.result == 'FAILURE') {
                            ocpEmailConfig.sendBuildNotificationForPrBuilds('FAILURE', email)
                        } else if (currentBuild.result == 'UNSTABLE') {
                            ocpEmailConfig.sendBuildNotificationForPrBuilds('UNSTABLE', email)
                        }
                    } else if (configval.buildcomponent == 'nighty_build' && env.SKIP_STAGE_NOCOMMIT == 'true') {
                        echo "Skipping stage due to SKIP_STAGE_NOCOMMIT being true"
                    } else if (configval.buildcomponent == 'nighty_build') {
                        echo "Current build result: ${currentBuild.result}"
                        if (currentBuild.result == 'SUCCESS') {
                            ocpEmailConfig.sendPipelineStatus('SUCCESS', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        } else if (currentBuild.result == 'FAILURE') {
                            ocpEmailConfig.sendSimplePipelineStatus('FAILURE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName)
                        } else if (currentBuild.result == 'UNSTABLE') {
                            ocpEmailConfig.sendPipelineStatus('UNSTABLE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        }
                    }
                }
            }
        }
    }
}

--------------------------------------------------------ocp email confg.groovy-------------------------------------------------
// Function to evaluate policy compliance
import groovy.json.JsonOutput
import java.util.TimeZone
import java.util.Date
import java.text.SimpleDateFormat

def evaluatePolicyCompliance() {
    def consoleOutput = currentBuild.rawBuild.getLog(1000000).join("\n")

    // Updated regex to match unquoted keys and values
    def policyMatcher = consoleOutput =~ /evaluation_status:\s*(\w+)/
    def policyMatcherCx = consoleOutput =~ /sast_status:\s*(\w+)/
    def policyMatcherCxOne = consoleOutput =~ /sca_status:\s*(\w+)/

    def policyEvaluation = policyMatcher.find() ? policyMatcher.group(1) : null
    def sastStatus = policyMatcherCx.find() ? policyMatcherCx.group(1) : null
    def scaStatus = policyMatcherCxOne.find() ? policyMatcherCxOne.group(1) : null

    // Debug logs
    echo "DEBUG: Extracted evaluation_status = '${policyEvaluation}'"
    echo "DEBUG: Extracted sast_status = '${sastStatus}'"
    echo "DEBUG: Extracted sca_status = '${scaStatus}'"

    return [
        policyEvaluation: policyEvaluation,
        sastStatus: sastStatus,
        scaStatus: scaStatus
    ]
}

// Function to convert EDT to IST
def convertEDTtoIST(triggerTimeEDTStr) {
    SimpleDateFormat edtFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
    edtFormat.setTimeZone(TimeZone.getTimeZone("America/New_York"))

    SimpleDateFormat istFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
    istFormat.setTimeZone(TimeZone.getTimeZone("Asia/Kolkata"))

    Date edtDate = edtFormat.parse(triggerTimeEDTStr)
    String istDateStr = istFormat.format(edtDate)
    return istDateStr
}

def sendPipelineStatus(buildStatus, selectedOsName, triggerTimeEDTStr, triggerTimeIST, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId) {
    try {
        def complianceResults = evaluatePolicyCompliance()
        def policyEvaluation = complianceResults.policyEvaluation
        def sastStatus = complianceResults.sastStatus
        def scaStatus = complianceResults.scaStatus
        def policyCompliance = policyEvaluation?.toUpperCase() == 'PASS' ? 'compliant' : 'non-compliant'
        def sastCompliance = sastStatus?.toUpperCase() == 'PASS' ? 'compliant' : 'non-compliant'
        def scaCompliance = scaStatus?.toUpperCase() == 'PASS' ? 'compliant' : 'non-compliant'
        def policyColor = policyCompliance == 'compliant' ? 'green' : 'red'
        def sastColor = sastCompliance == 'compliant' ? 'green' : 'red'
        def scaColor = scaCompliance == 'compliant' ? 'green' : 'red'
        def yamlContent = readFile file: './Jenkins/params.yaml'
        def yaml = readYaml text: yamlContent
        def email = yaml.NotifyEmail
        def teamsWebhookUrl = yaml.TeamsWebhookUrl
        def branchName = env.BRANCH_NAME
        def currentDate = new Date().format('ddMMyyyy')
        def subjectBranch = branchName.contains('Switch') ? 'Switch' : branchName.contains('Clearing') ? 'Clearing' : branchName.contains('Mas') ? 'Mas' : branchName

        def statusColor, statusText, errorLogSnippet = "", failedStage = "Unknown"
        def attachments = []

        switch (buildStatus) {
            case 'SUCCESS':
                statusColor = 'green'
                statusText = 'BUILD SUCCESSFUL'
                break
            case 'UNSTABLE':
                statusColor = 'orange'
                statusText = 'BUILD UNSTABLE'
                break
            case 'FAILURE':
                statusColor = 'red'
                statusText = 'BUILD FAILED'
                def buildLog = currentBuild.rawBuild.getLog(200)
                errorLogSnippet = buildLog.join('\n') ?: "No logs found."

                def currentStage = ""
                buildLog.each { line ->
                    if (line.contains('[Pipeline] { (')) {
                        def matcher = line =~ /\[Pipeline\] \{ \((.+)\)/
                        if (matcher.find()) {
                            currentStage = matcher[0][1]
                        }
                    }

                    if (line.toLowerCase().contains("error during build") || line.toLowerCase().contains("script returned exit code")) {
                        failedStage = currentStage ?: "Unknown"
                    }
                }

                def buildLogFile = findFiles(glob: '*.buildlog')
                if (buildLogFile.length > 0) {
                    attachments << buildLogFile[0].path
                }
                break
        }

        archiveArtifacts artifacts: 'Checkmarx/Reports/CxSASTReport_*.pdf', allowEmptyArchive: true
        archiveArtifacts artifacts: 'cx_result.json', allowEmptyArchive: true
        archiveArtifacts artifacts: 'pac/*.json', allowEmptyArchive: true
        archiveArtifacts artifacts: '*_results.json', allowEmptyArchive: true
        archiveArtifacts artifacts: 'jira_tickets_*.txt', allowEmptyArchive: true

        def addIfExists = { pattern ->
            def files = findFiles(glob: pattern)
            if (files.length > 0) {
                attachments.addAll(files.collect { it.path })
            }
        }

        addIfExists('Checkmarx/Reports/CxSASTReport_*.pdf')
        addIfExists('checkmarx_One/cx_result.json')
        addIfExists('pac/*.json')
        addIfExists('jira_tickets_*.txt')

        def emailBody = """
            <html>
                <body>
                    <div style='border: 2px solid ${statusColor}; padding: 10px;'>
                        <h2 style='color:${statusColor}'>${statusText}</h2>
                        <p><b>URL:</b> ${env.BUILD_URL}</p>
                        <p><b>Nighty Branch Name:</b> ${env.BRANCH_NAME}</p>
                        <p><b>Project Name:</b> ${releaseFileName}</p>
                        <p><b>Agent Name:</b> ${selectedOsName}</p>
                        <p><b>Trigger Time (EDT):</b> ${triggerTimeEDTStr} EDT</p>
                        <p><b>Trigger Time (IST):</b> ${triggerTimeIST} IST</p>
                        <p><b>Duration:</b> ${currentBuild.durationString}</p>
                        <p><b>Started by:</b> ${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}</p>
                        ${buildStatus == 'FAILURE' ? "<p><b>Failed Stage:</b> ${failedStage}</p><p><b>Last 200 Console Lines:</b><br><pre>${errorLogSnippet}</pre></p>" : ""}
                    </div>
                    <h2>Scan Reports</h2>
                    <table border='1'>
                        <tr>
                            <th>Scan</th>
                            <th>Result</th>
                            <th>Project Name</th>
                            <th>Scan ID</th>
                        </tr>
                        ${findFiles(glob: 'Checkmarx/Reports/CxSASTReport_*.pdf').length > 0 ? 
                            "<tr><td>Checkmarx</td><td style='color:${sastColor}'>${sastCompliance}</td><td>${emailcxProjectName}</td><td>${emailcxScanId}</td></tr>" : ""}
                        ${findFiles(glob: 'checkmarx_One/cx_result.json').length > 0 ? 
                            "<tr><td>CheckmarxOne</td><td style='color:${scaColor}'>${scaCompliance}</td><td>${emailcxOneProjectName}</td><td>${emailcxOneScanId}</td></tr>" : ""}
                        ${findFiles(glob: 'pac/*.json').length > 0 ? 
                            "<tr><td>OPA</td><td style='color:${policyColor}'>${policyCompliance}</td><td>N/A</td><td>N/A</td></tr>" : ""}
                        ${findFiles(glob: 'jira_tickets_*.txt').length > 0 ? 
                            "<tr><td>CxFlow</td><td style='color:grey'>Not Applicable</td><td>N/A</td><td>N/A</td></tr>" : ""}
                    </table>
                </body>
            </html>
        """

        emailext(
            to: "${email}",
            subject: "Nighty Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            body: emailBody,
            mimeType: 'text/html',
            attachmentsPattern: attachments.join(',')
        )

        def message = [
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "summary": "Nighty Build || Pipeline Status Notification",
            "themeColor": statusColor,
            "title": "Nighty Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            "sections": [
                [
                    "activityTitle": statusText,
                    "activitySubtitle": "URL: ${env.BUILD_URL}",
                    "facts": [
                        ["name": "Nighty Branch Name", "value": "${env.BRANCH_NAME}"],
                        ["name": "Project Name", "value": "${releaseFileName}"],
                        ["name": "Agent Name", "value": "${selectedOsName}"],
                        ["name": "Trigger Time (EDT)", "value": "${triggerTimeEDTStr} EDT"],
                        ["name": "Trigger Time (IST)", "value": "${triggerTimeIST} IST"],
                        ["name": "Duration", "value": "${currentBuild.durationString}"],
                        ["name": "Started by", "value": "${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}"]
                    ],
                    "markdown": true
                ],
                [
                    "activityTitle": "Scan Reports",
                    "facts":[
                        ["name": "Checkmarx", "value": "[Valuation Report - ${sastCompliance}]"],
                        ["name": "CheckmarxOne", "value": "[Valuation Report - ${scaCompliance}]"],
                        ["name": "OPA", "value":"[Valuation Report - ${policyCompliance}]"]
                    ],
                    "markdown": true
                ]
            ]
        ]

        if (buildStatus == 'FAILURE') {
            message.sections << [
                "activityTitle": "Failure Details",
                "facts": [
                    ["name": "Failed Stage", "value": "${failedStage}"]
                ],
                "text": "```${errorLogSnippet}```",
                "markdown": true
            ]
        }

        def jsonMessage = JsonOutput.toJson(message)
        httpRequest(
            httpMode: 'POST',
            url: teamsWebhookUrl,
            contentType: 'APPLICATION_JSON',
            requestBody: jsonMessage
        )
    } catch (Exception e) {
        echo "Error sending pipeline status: ${e.message}"
        e.printStackTrace()
    }

    cleanWs deleteDirs: buildStatus != 'FAILURE', notFailBuild: buildStatus != 'FAILURE'
}


def sendSimplePipelineStatus(buildStatus, selectedOsName, triggerTimeEDTStr, triggerTimeIST, releaseFileName) {
    try {
        def yamlContent = readFile file: './Jenkins/params.yaml'
        def yaml = readYaml text: yamlContent
        def email = yaml.NotifyEmail
        def teamsWebhookUrl = yaml.TeamsWebhookUrl

        def statusColor
        def statusText
        def branchName = env.BRANCH_NAME
        def currentDate = new Date().format('ddMMyyyy')
        def subjectBranch = branchName.contains('Switch') ? 'Switch' : branchName.contains('Clearing') ? 'Clearing' : branchName.contains('Mas') ? 'Mas' : branchName

        def attachments = []
        def errorLogSnippet = ""
        def failedStage = "Unknown"

        switch (buildStatus) {
            case 'SUCCESS':
                statusColor = 'green'
                statusText = 'BUILD SUCCESSFUL'
                break
            case 'FAILURE':
                statusColor = 'red'
                statusText = 'BUILD FAILED'
                def buildLog = currentBuild.rawBuild.getLog(200)
                errorLogSnippet = buildLog.join('\n') ?: "No logs found."

                def currentStage = ""
                buildLog.each { line ->
                    if (line.contains('[Pipeline] { (')) {
                        def matcher = line =~ /\[Pipeline\] \{ \((.+)\)/
                        if (matcher.find()) {
                            currentStage = matcher[0][1]
                        }
                    }

                    if (line.toLowerCase().contains("error during build") || line.toLowerCase().contains("script returned exit code")) {
                        failedStage = currentStage ?: "Unknown"
                    }
                }

                def buildLogFile = findFiles(glob: '*.buildlog')
                if (buildLogFile.length > 0) {
                    attachments << buildLogFile[0].path
                }
                break
            case 'UNSTABLE':
                statusColor = 'orange'
                statusText = 'BUILD UNSTABLE'
                break
        }

        // Email body
        def emailBody = """
            <html>
                <body>
                    <div style='border: 2px solid ${statusColor}; padding: 10px;'>
                        <h2 style='color:${statusColor}'>${statusText}</h2>
                        <p><b>URL:</b> ${env.BUILD_URL}</p>
                        <p><b>Nighty Branch Name:</b> ${env.BRANCH_NAME}</p>
                        <p><b>Project Name:</b> ${releaseFileName}</p>
                        <p><b>Agent Name:</b> ${selectedOsName}</p>
                        <p><b>Trigger Time (EDT):</b> ${triggerTimeEDTStr} EDT</p>
                        <p><b>Trigger Time (IST):</b> ${triggerTimeIST} IST</p>
                        <p><b>Duration:</b> ${currentBuild.durationString}</p>
                        <p><b>Started by:</b> ${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}</p>
                        ${buildStatus == 'FAILURE' ? "<p><b>Failed Stage:</b> ${failedStage}</p><p><b>Last 200 Console Lines:</b><br><pre>${errorLogSnippet}</pre></p>" : ""}
                    </div>
                </body>
            </html>
        """

        emailext(
            to: "${email}",
            subject: "Nighty Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            body: emailBody,
            mimeType: 'text/html',
            attachmentsPattern: attachments.join(',')
        )

        // Teams message
        def message = [
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "summary": "Nighty Build || Pipeline Status Notification",
            "themeColor": statusColor,
            "title": "Nighty Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            "sections": [
                [
                    "activityTitle": statusText,
                    "activitySubtitle": "URL: ${env.BUILD_URL}",
                    "facts": [
                        ["name": "Nighty Branch Name", "value": "${env.BRANCH_NAME}"],
                        ["name": "Project Name", "value": "${releaseFileName}"],
                        ["name": "Agent Name", "value": "${selectedOsName}"],
                        ["name": "Trigger Time (EDT)", "value": "${triggerTimeEDTStr} EDT"],
                        ["name": "Trigger Time (IST)", "value": "${triggerTimeIST} IST"],
                        ["name": "Duration", "value": "${currentBuild.durationString}"],
                        ["name": "Started by", "value": "${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}"]
                    ],
                    "markdown": true
                ]
            ]
        ]

        if (buildStatus == 'FAILURE') {
            message.sections << [
                "activityTitle": "Failure Details",
                "facts": [
                    ["name": "Failed Stage", "value": "${failedStage}"]
                ],
                "text": "```${errorLogSnippet}```",
                "markdown": true
            ]
        }

        def jsonMessage = JsonOutput.toJson(message)
        httpRequest(
            httpMode: 'POST',
            url: teamsWebhookUrl,
            contentType: 'APPLICATION_JSON',
            requestBody: jsonMessage
        )
    } catch (Exception e) {
        echo "Error sending pipeline status: ${e.message}"
        e.printStackTrace()
    }

    // ‚úÖ Workspace cleanup only if build did NOT fail
    if (buildStatus != 'FAILURE') {
        cleanWs deleteDirs: true, notFailBuild: true
    }
}


def sendBuildNotificationForPrBuilds(buildStatus, email) {
    script {
        echo "NotifyEmail: ${email}"

        def borderColor, subject, message, buildLog = ""
        def attachments = []

        switch (buildStatus) {
            case 'SUCCESS':
                borderColor = 'green'
                subject = "PR || Pipeline Success Notification"
                message = "The pipeline completed successfully."
                break
            case 'FAILURE':
                borderColor = 'red'
                subject = "PR || Pipeline Failure Notification"
                message = "Something went wrong with the pipeline. Please check the logs for more details."
                buildLog = currentBuild.rawBuild.getLog(200).join('\n')
                def buildLogFile = findFiles(glob: '*.buildlog')
                if (buildLogFile.length > 0) {
                    attachments << buildLogFile[0].path
                }
                break
            case 'UNSTABLE':
                borderColor = 'orange'
                subject = "PR || Pipeline Unstable Notification"
                message = "The pipeline is unstable. Please check the logs for more details."
                break
        }

        emailext(
            to: "${email},Rajesh.Dhandapani@figlobal.com,Gaurav.Gupta3@figlobal.com,Girija.Manoharan@figlobal.com,Jeyanthi.Ramanujam@figlobal.com,Ramesh.S.Velayutham@figlobal.com",
            subject: subject,
            body: """\
                <html>
                <body>
                <div style='border: 2px solid ${borderColor}; padding: 10px;'>
                <h2 style='color:${borderColor}'>BUILD ${buildStatus}</h2>
                <p><b>URL:</b> ${env.BUILD_URL}</p>
                <p><b>Branch Name:</b> ${env.BRANCH_NAME}</p>
                <p><b>Date:</b> ${new Date()}</p>
                <p><b>Duration:</b> ${currentBuild.durationString}</p>
                <p><b>Started by:</b> ${currentBuild.getBuildCauses()?.first()?.userName ?: 'Unknown'}</p>
                <p><b>Message:</b> ${message}</p>
                ${buildStatus == 'FAILURE' ? "<pre>${buildLog}</pre>" : ""}
                </div>
                </body>
                </html>
            """,
            mimeType: 'text/html',
            attachmentsPattern: attachments.join(',')
        )
    }
    cleanWs deleteDirs: buildStatus != 'FAILURE', notFailBuild: buildStatus != 'FAILURE'
}

def releaseSendPipelineStatus(buildStatus, selectedOsName, triggerTimeEDTStr, triggerTimeIST, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId) {
    try {
        def complianceResults = evaluatePolicyCompliance()
        def policyEvaluation = complianceResults.policyEvaluation
        def sastStatus = complianceResults.sastStatus
        def scaStatus = complianceResults.scaStatus
        def policyCompliance = policyEvaluation?.toUpperCase() == 'PASS' ? 'compliant' : 'non-compliant'
        def sastCompliance = sastStatus?.toUpperCase() == 'PASS' ? 'compliant' : 'non-compliant'
        def scaCompliance = scaStatus?.toUpperCase() == 'PASS' ? 'compliant' : 'non-compliant'
        def policyColor = policyCompliance == 'compliant' ? 'green' : 'red'
        def sastColor = sastCompliance == 'compliant' ? 'green' : 'red'
        def scaColor = scaCompliance == 'compliant' ? 'green' : 'red'
        def yamlContent = readFile file: './Jenkins/params.yaml'
        def yaml = readYaml text: yamlContent
        def email = yaml.NotifyEmail
        def teamsWebhookUrl = yaml.TeamsWebhookUrl
        def branchName = env.BRANCH_NAME
        def currentDate = new Date().format('ddMMyyyy')
        def subjectBranch = branchName.contains('Switch') ? 'Switch' : branchName.contains('Clearing') ? 'Clearing' : branchName.contains('Mas') ? 'Mas' : branchName

        def statusColor, statusText, errorLogSnippet = "", failedStage = "Unknown"
        def attachments = []

        switch (buildStatus) {
            case 'SUCCESS':
                statusColor = 'green'
                statusText = 'BUILD SUCCESSFUL'
                break
            case 'UNSTABLE':
                statusColor = 'orange'
                statusText = 'BUILD UNSTABLE'
                break
            case 'FAILURE':
                statusColor = 'red'
                statusText = 'BUILD FAILED'
                def buildLog = currentBuild.rawBuild.getLog(200)
                errorLogSnippet = buildLog.join('\n') ?: "No logs found."

                def currentStage = ""
                buildLog.each { line ->
                    if (line.contains('[Pipeline] { (')) {
                        def matcher = line =~ /\[Pipeline\] \{ \((.+)\)/
                        if (matcher.find()) {
                            currentStage = matcher[0][1]
                        }
                    }

                    if (line.toLowerCase().contains("error during build") || line.toLowerCase().contains("script returned exit code")) {
                        failedStage = currentStage ?: "Unknown"
                    }
                }

                def buildLogFile = findFiles(glob: '*.buildlog')
                if (buildLogFile.length > 0) {
                    attachments << buildLogFile[0].path
                }
                break
        }

        archiveArtifacts artifacts: 'Checkmarx/Reports/CxSASTReport_*.pdf', allowEmptyArchive: true
        archiveArtifacts artifacts: 'cx_result.json', allowEmptyArchive: true
        archiveArtifacts artifacts: 'pac/*.json', allowEmptyArchive: true
        archiveArtifacts artifacts: '*_results.json', allowEmptyArchive: true
        archiveArtifacts artifacts: 'jira_tickets_*.txt', allowEmptyArchive: true

        def addIfExists = { pattern ->
            def files = findFiles(glob: pattern)
            if (files.length > 0) {
                attachments.addAll(files.collect { it.path })
            }
        }

        addIfExists('Checkmarx/Reports/CxSASTReport_*.pdf')
        addIfExists('checkmarx_One/cx_result.json')
        addIfExists('pac/*.json')
        addIfExists('jira_tickets_*.txt')

        def emailBody = """
            <html>
                <body>
                    <div style='border: 2px solid ${statusColor}; padding: 10px;'>
                        <h2 style='color:${statusColor}'>${statusText}</h2>
                        <p><b>URL:</b> ${env.BUILD_URL}</p>
                        <p><b>Release Branch Name:</b> ${env.BRANCH_NAME}</p>
                        <p><b>Project Name:</b> ${releaseFileName}</p>
                        <p><b>Agent Name:</b> ${selectedOsName}</p>
                        <p><b>Trigger Time (EDT):</b> ${triggerTimeEDTStr} EDT</p>
                        <p><b>Trigger Time (IST):</b> ${triggerTimeIST} IST</p>
                        <p><b>Duration:</b> ${currentBuild.durationString}</p>
                        <p><b>Started by:</b> ${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}</p>
                        ${buildStatus == 'FAILURE' ? "<p><b>Failed Stage:</b> ${failedStage}</p><p><b>Last 200 Console Lines:</b><br><pre>${errorLogSnippet}</pre></p>" : ""}
                    </div>
                    <h2>Scan Reports</h2>
                    <table border='1'>
                        <tr>
                            <th>Scan</th>
                            <th>Result</th>
                            <th>Project Name</th>
                            <th>Scan ID</th>
                        </tr>
                        ${findFiles(glob: 'Checkmarx/Reports/CxSASTReport_*.pdf').length > 0 ? 
                            "<tr><td>Checkmarx</td><td style='color:${sastColor}'>${sastCompliance}</td><td>${emailcxProjectName}</td><td>${emailcxScanId}</td></tr>" : ""}
                        ${findFiles(glob: 'checkmarx_One/cx_result.json').length > 0 ? 
                            "<tr><td>CheckmarxOne</td><td style='color:${scaColor}'>${scaCompliance}</td><td>${emailcxOneProjectName}</td><td>${emailcxOneScanId}</td></tr>" : ""}
                        ${findFiles(glob: 'pac/*.json').length > 0 ? 
                            "<tr><td>OPA</td><td style='color:${policyColor}'>${policyCompliance}</td><td>N/A</td><td>N/A</td></tr>" : ""}
                        ${findFiles(glob: 'jira_tickets_*.txt').length > 0 ? 
                            "<tr><td>CxFlow</td><td style='color:grey'>Not Applicable</td><td>N/A</td><td>N/A</td></tr>" : ""}
                    </table>
                </body>
            </html>
        """

        emailext(
            to: "${email}",
            subject: "RCC Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            body: emailBody,
            mimeType: 'text/html',
            attachmentsPattern: attachments.join(',')
        )

        def message = [
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "summary": "RCC Build || Pipeline Status Notification",
            "themeColor": statusColor,
            "title": "Release Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            "sections": [
                [
                    "activityTitle": statusText,
                    "activitySubtitle": "URL: ${env.BUILD_URL}",
                    "facts": [
                        ["name": "Release Branch Name", "value": "${env.BRANCH_NAME}"],
                        ["name": "Project Name", "value": "${releaseFileName}"],
                        ["name": "Agent Name", "value": "${selectedOsName}"],
                        ["name": "Trigger Time (EDT)", "value": "${triggerTimeEDTStr} EDT"],
                        ["name": "Trigger Time (IST)", "value": "${triggerTimeIST} IST"],
                        ["name": "Duration", "value": "${currentBuild.durationString}"],
                        ["name": "Started by", "value": "${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}"]
                    ],
                    "markdown": true
                ],
                [
                    "activityTitle": "Scan Reports",
                    "facts":[
                        ["name": "Checkmarx", "value": "[Valuation Report - ${sastCompliance}]"],
                        ["name": "CheckmarxOne", "value": "[Valuation Report - ${scaCompliance}]"],
                        ["name": "OPA", "value":"[Valuation Report - ${policyCompliance}]"]
                    ],
                    "markdown": true
                ]
            ]
        ]

        if (buildStatus == 'FAILURE') {
            message.sections << [
                "activityTitle": "Failure Details",
                "facts": [
                    ["name": "Failed Stage", "value": "${failedStage}"]
                ],
                "text": "```${errorLogSnippet}```",
                "markdown": true
            ]
        }

        def jsonMessage = JsonOutput.toJson(message)
        httpRequest(
            httpMode: 'POST',
            url: teamsWebhookUrl,
            contentType: 'APPLICATION_JSON',
            requestBody: jsonMessage
        )
    } catch (Exception e) {
        echo "Error sending pipeline status: ${e.message}"
        e.printStackTrace()
    }

    cleanWs deleteDirs: buildStatus != 'FAILURE', notFailBuild: buildStatus != 'FAILURE'
}

def releaseSendSimplePipelineStatus(buildStatus, selectedOsName, triggerTimeEDTStr, triggerTimeIST, releaseFileName) {
    try {
        def yamlContent = readFile file: './Jenkins/params.yaml'
        def yaml = readYaml text: yamlContent
        def email = yaml.NotifyEmail
        def teamsWebhookUrl = yaml.TeamsWebhookUrl

        def statusColor
        def statusText
        def branchName = env.BRANCH_NAME
        def currentDate = new Date().format('ddMMyyyy')
        def subjectBranch = branchName.contains('Switch') ? 'Switch' : branchName.contains('Clearing') ? 'Clearing' : branchName.contains('Mas') ? 'Mas' : branchName

        def attachments = []
        def errorLogSnippet = ""
        def failedStage = "Unknown"

        switch (buildStatus) {
            case 'SUCCESS':
                statusColor = 'green'
                statusText = 'BUILD SUCCESSFUL'
                break
            case 'FAILURE':
                statusColor = 'red'
                statusText = 'BUILD FAILED'
                def buildLog = currentBuild.rawBuild.getLog(200)
                errorLogSnippet = buildLog.join('\n') ?: "No logs found."

                def currentStage = ""
                buildLog.each { line ->
                    if (line.contains('[Pipeline] { (')) {
                        def matcher = line =~ /\[Pipeline\] \{ \((.+)\)/
                        if (matcher.find()) {
                            currentStage = matcher[0][1]
                        }
                    }

                    if (line.toLowerCase().contains("error during build") || line.toLowerCase().contains("script returned exit code")) {
                        failedStage = currentStage ?: "Unknown"
                    }
                }

                def buildLogFile = findFiles(glob: '*.buildlog')
                if (buildLogFile.length > 0) {
                    attachments << buildLogFile[0].path
                }
                break
            case 'UNSTABLE':
                statusColor = 'orange'
                statusText = 'BUILD UNSTABLE'
                break
        }

        // Email body
        def emailBody = """
            <html>
                <body>
                    <div style='border: 2px solid ${statusColor}; padding: 10px;'>
                        <h2 style='color:${statusColor}'>${statusText}</h2>
                        <p><b>URL:</b> ${env.BUILD_URL}</p>
                        <p><b>RCC Branch Name:</b> ${env.BRANCH_NAME}</p>
                        <p><b>Project Name:</b> ${releaseFileName}</p>
                        <p><b>Agent Name:</b> ${selectedOsName}</p>
                        <p><b>Trigger Time (EDT):</b> ${triggerTimeEDTStr} EDT</p>
                        <p><b>Trigger Time (IST):</b> ${triggerTimeIST} IST</p>
                        <p><b>Duration:</b> ${currentBuild.durationString}</p>
                        <p><b>Started by:</b> ${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}</p>
                        ${buildStatus == 'FAILURE' ? "<p><b>Failed Stage:</b> ${failedStage}</p><p><b>Last 200 Console Lines:</b><br><pre>${errorLogSnippet}</pre></p>" : ""}
                    </div>
                </body>
            </html>
        """

        emailext(
            to: "${email}",
            subject: "RCC Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            body: emailBody,
            mimeType: 'text/html',
            attachmentsPattern: attachments.join(',')
        )

        // Teams message
        def message = [
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "summary": "RCC Build || Pipeline Status Notification",
            "themeColor": statusColor,
            "title": "RCC Build || Pipeline Status Notification || ${subjectBranch} || ${currentDate}",
            "sections": [
                [
                    "activityTitle": statusText,
                    "activitySubtitle": "URL: ${env.BUILD_URL}",
                    "facts": [
                        ["name": "Nighty Branch Name", "value": "${env.BRANCH_NAME}"],
                        ["name": "Project Name", "value": "${releaseFileName}"],
                        ["name": "Agent Name", "value": "${selectedOsName}"],
                        ["name": "Trigger Time (EDT)", "value": "${triggerTimeEDTStr} EDT"],
                        ["name": "Trigger Time (IST)", "value": "${triggerTimeIST} IST"],
                        ["name": "Duration", "value": "${currentBuild.durationString}"],
                        ["name": "Started by", "value": "${currentBuild.getBuildCauses()?.first()?.userName ?: 'Timer Trigger'}"]
                    ],
                    "markdown": true
                ]
            ]
        ]

        if (buildStatus == 'FAILURE') {
            message.sections << [
                "activityTitle": "Failure Details",
                "facts": [
                    ["name": "Failed Stage", "value": "${failedStage}"]
                ],
                "text": "```${errorLogSnippet}```",
                "markdown": true
            ]
        }

        def jsonMessage = JsonOutput.toJson(message)
        httpRequest(
            httpMode: 'POST',
            url: teamsWebhookUrl,
            contentType: 'APPLICATION_JSON',
            requestBody: jsonMessage
        )
    } catch (Exception e) {
        echo "Error sending pipeline status: ${e.message}"
        e.printStackTrace()
    }

    cleanWs deleteDirs: buildStatus != 'FAILURE', notFailBuild: buildStatus != 'FAILURE'
}

def getPRAuthorEmail() {
    if (env.CHANGE_ID != null) {
        try {
            def prId = env.CHANGE_ID
            def gitUrl = env.GIT_URL
            def urlParts = gitUrl.tokenize('/')
            def projectname = urlParts[-2]
            def reponame = urlParts[-1].replace('.git', '')
            echo "projectname: ${projectname}"
            echo "reponame: ${reponame}"
            def apiUrl = "https://bitbucket.fi.dev/rest/api/1.0/projects/${projectname}/repos/${reponame}/pull-requests/${prId}"
            echo "apiUrl : ${apiUrl}"
            withCredentials([usernamePassword(credentialsId: env.CREDENTIALS_ID, usernameVariable: 'GIT_USERNAME', passwordVariable: 'GIT_PASSWORD')]) {
                def response = sh(
                    script: """curl -s -w "\\n%{http_code}" -u $GIT_USERNAME:$GIT_PASSWORD "${apiUrl}" """,
                    returnStdout: true
                ).trim()
                def lines = response.readLines()
                def body = lines[0..-2].join('\n')
                def statusCode = lines[-1]
                echo "HTTP Status Code: ${statusCode}"
                echo "Raw API response (first 1000 chars): ${body.take(1000)}"
                if (statusCode != "200") {
                    error "Bitbucket API call failed with status code ${statusCode}"
                }
                def json
                try {
                    json = readJSON text: body
                } catch (parseErr) {
                    error "Failed to parse JSON: ${parseErr}"
                }
                echo "Parsed JSON keys: ${json.keySet()}"
                echo "Author object: ${json?.author}"
                echo "Author user object: ${json?.author?.user}"
                def authorEmail = json?.author?.user?.emailAddress
                if (!authorEmail) {
                    error "Could not retrieve PR author email from Bitbucket API."
                }
                env.PR_AUTHOR_EMAIL = authorEmail
                echo "PR Author Email: ${env.PR_AUTHOR_EMAIL}"
            }
        } catch (err) {
            echo "Failed to get PR author email: ${err}"
        }
    }
}

---------------------------------------------ocpRccBuildPipeline.groovy-------------------------------------

import fi.ist.*
import groovy.json.JsonOutput
import java.util.TimeZone
import java.util.Date
import java.text.SimpleDateFormat
import hudson.model.User
import org.jenkinsci.plugins.workflow.steps.FlowInterruptedException

def extractCxScanId(String logText) {
    def matcher = logText =~ /Scan ID is \s*(\d+)/
    return matcher ? matcher[0][1] : null
}

def extractCxOneScanId(String logText) {
    def matcher = logText =~ /Wait for scan to complete (\S+)/
    return matcher ? matcher[0][1] : null
}

def getBuildTriggerUser() {
    def user = 'unknown'
    def cause = currentBuild.rawBuild.getCause(hudson.model.Cause$UserIdCause)
    if (cause != null) {
        user = cause.getUserId()
    }
    return user
}

def call(Map configval = [:]){
     
    echo "Inside OCPBuildPipeline.groovy ...."
  	
  
  	echo "Branch: ${configval.branch}"
    echo "Build Type: ${configval.buildType}"
    echo "swComponent: ${configval.swComponent}"
    echo "selectedOsName: ${configval.selectedOsName}"
    echo "selectedOsValue: ${configval.selectedOsValue}"
    echo "Build Component: ${configval.buildcomponent}"
  	
  	def jobNameParts = JOB_NAME.tokenize('/') as String[]
    def jobNamePart = "${jobNameParts[2]}/${jobNameParts[3]}"
    def datas = ""
    String PathVar, os_dir, myArtifact
    def podTemplate = fetchResources.getIstPodAgents()
  	def opaPodTemplate = fetchResources.getpodAgents()
  	def foCommitFound
  	def CmpCommitFound
    def triggerTimeEDT = new Date()
    def triggerTimeISTStr
  	def triggerTimeEDTStr
    
	pipeline {
        agent {
            kubernetes {
                cloud 'ist-build-jenkins'
                yaml podTemplate
            }
        }
        environment {
          	SOURCE_BRANCH = "${env.CHANGE_BRANCH ?: env.BRANCH_NAME}"
          	CREDENTIALS_ID ="cm-credentials-id"
        }
      
        options {
            timestamps()
            buildDiscarder(logRotator(numToKeepStr: '10', artifactNumToKeepStr: '10'))
        }
		stages {
            stage('Check Release file') {
                steps {
                    script {
                        releaseApprovalStage(configval)
                    }
                }
            }
            stage('Set Java and Oracle Home') {
                steps {
                    container('ist-build-agent') {
                        script {
                            try {
                                SimpleDateFormat edtFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
                                edtFormat.setTimeZone(TimeZone.getTimeZone("America/New_York"))
                                triggerTimeEDTStr = edtFormat.format(new Date())
                                env.TRIGGER_TIME_EDT = triggerTimeEDTStr

                                triggerTimeISTStr = ocpEmailConfig.convertEDTtoIST(triggerTimeEDTStr)
                                env.TRIGGER_TIME_IST = triggerTimeISTStr

                                echo "triggerTimeISTStr: ${triggerTimeISTStr}"
                                echo "triggerTimeEDTStr: ${triggerTimeEDTStr}"

                                def javaPath = sh(
                                    script: '''
                                        JAVAC_PATH=$(which javac)
                                        JAVA_HOME=$(readlink -f "$JAVAC_PATH" | sed 's:/bin/javac::')
                                        echo "$JAVA_HOME"
                                    ''',
                                    returnStdout: true
                                ).trim()

                                def oracleHomePath = sh(script: 'echo $ORACLE_HOME', returnStdout: true).trim()
                                def oracleVersion = oracleHomePath.tokenize('/')[-2]

                                def javaExists = sh(script: "[ -d '${javaPath}' ] && echo exists || echo missing", returnStdout: true).trim()
                                def oracleExists = sh(script: "[ -d '${oracleHomePath}' ] && echo exists || echo missing", returnStdout: true).trim()

                                if (javaExists != "exists") {
                                    error "Java path '${javaPath}' does not exist."
                                }
                                if (oracleExists != "exists") {
                                    error "Oracle path '${oracleHomePath}' does not exist."
                                }

                                def updatedOracleVersion = "ORA-${oracleVersion}"

                                env.java_home = javaPath
                                env.oracle_home = "${oracleHomePath}\n${updatedOracleVersion}"

                                echo "JAVA_HOME set to: ${env.java_home}"
                                echo "ORACLE_HOME set to: ${env.oracle_home}"
                            } catch (Exception e) {
                                echo "Error occurred during 'Set Java and Oracle Home' stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Set Java and Oracle Home stage failed.")
                            }
                        }
                    }
                }
            }
			stage('Setup') {
                steps {
                    container('ist-build-agent') {
                        script {
                            println "Setting Parameters"
                            try {
                                datas = readYaml file: "./Jenkins/params.yaml"
                                //def datares = readYaml(text: libraryResource('fi/IST/Parameters.yaml'))

                              	def component = "${configval.buildcomponent}"
                                def buildType = configval.buildType?.toLowerCase()
                                def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')

                                def useBranchBuildList = false

                                switch (component) {
                                    case "rcc_build":
                                        env.release_file_name = "${env.release_file}"
                                  		echo "Collected release file name from ${env.release_file_name} for rcc build."
                                        break

                                    default:
                                        echo "Unknown or unsupported buildcomponent: ${component}. Defaulting to release file."
                                        break
                                }

                            } catch (Exception e) {
                                echo "Error occurred during 'Setup' stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Setup stage failed.")
                            }
                        }
                    }
                }
            }
            stage('Download dependency') {
                when { expression { return env.SKIP_STAGE_NOCOMMIT != 'true' } }
                steps {
                    container('ist-build-agent') {
                        script {
                            try {
                                println "Stage: Download dependency repos."
                                dir('gitroot') {
                                    BUILD_TYPE = configval.BUILD_TYPE
                                    new CppBuild().downloaddependency(
                                        project_repo: "${datas.Project_repo}",
                                        gitCreds: "cm-credentials-id"
                                    )
                                }
                            } catch (Exception e) {
                                echo "Error occurred during 'Download dependency' stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Download dependency stage failed.")
                            }
                        }
                    }
                }
            }
          
            /*stage('Patch Checkmarx Script') {
                steps {
                  script {
                    new CppBuild().patchCheckmarxBranchLogic()
                  }
                }
              }*/
          
			stage('Build') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                    IST_TOOLS = "${env.WORKSPACE}/gitroot/ist-build-tools"
                }
                steps {
                    container('ist-build-agent') {
                        script {
                            try {
                                def component = configval.swComponent?.toLowerCase()
                                def isPRBuild = env.BRANCH_NAME?.startsWith('PR-')
                                def repoName = jobNameParts[3]?.toLowerCase()
                              	configval.RELEASE_FILE = "${env.release_file_name}"
                          		env.trigger = "FullTrigger"
                          		echo "Build Release File: ${configval.RELEASE_FILE}"

                                if (params.productname == 'ist-release-info') {
                                    myArtifact = new CppBuild().build(
                                        artFile: "${jobNameParts[2]}/${env.BRANCH_NAME.replaceAll('/', '_')}/${BUILD_NUMBER}",
                                        build_Flags: "${datas.build.Flags}",
                                        os: "${os_dir}",
                                        releasefile: sh(script: "cat ${GITROOT}/ist-release-info/rel_info/build.release", returnStdout: true).trim(),
                                        ArtCred: "svcacct_istartifact"
                                    )
                                } else {
                                    myArtifact = new OcpCppBuild().build(
                                        artFile: "${jobNameParts[2]}/${env.BRANCH_NAME.replaceAll('/', '_')}/${BUILD_NUMBER}",
                                        build_Flags: "${datas.build.Flags}",
                                        os: "${os_dir}",
                                        java_home: "${env.java_home}",
                                        oracle_home: "${env.oracle_home}",
                                        releasefile: "${env.release_file_name}",
                                        Build_Component: "${configval.buildcomponent}",
                                        selectedOsName: "${configval.selectedOsName}",
                                        ArtCred: "svcacct_istartifact"
                                    )
                                }
								if ("${myArtifact}" != "NoArtifact") {
									def artifactFiles = myArtifact.split(',').collect { "\"${it}\"" }.join(' ')
									sh "cp ${artifactFiles} ${env.WORKSPACE}"

									println "Component value: ${component}"
									println "isPRBuild value: ${isPRBuild}"
									println "repoName value: ${repoName}"

									def filesToZip = []

									// Load artifactBuildTgz.groovy
									//def artifactBuildTgz = load "${env.WORKSPACE}/path/to/artifactBuildTgz.groovy"

									if (artifactBuildTgz.shouldRenameArtifacts(component, isPRBuild, repoName)) {
										println "Inside the rename artifacts if condition"
										def (version, buildTag) = artifactBuildTgz.extractVersionAndBuildTag(env)
										filesToZip = artifactBuildTgz.renameArtifacts(myArtifact, version, buildTag, env)
									} else {
										filesToZip = artifactBuildTgz.collectTgzFiles(env, component)
									}

									if (filesToZip) {
										artifactBuildTgz.zipArtifacts(filesToZip, configval, env)
									} else {
										error("No artifact generated.")
									}
								}
							} catch (Exception e) {
								echo "Error occurred during 'Build' stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Build stage failed.")
							}
						}
					}
				}
			}  
                 
            stage('Create PRs') {
              when {
                environment name: 'Approved_RunCreatePR', value: 'true'
              }
              steps {
                script {
                  try {
                    wrap([$class: 'BuildUser']) {

                      echo "Confirmed release file: ${env.release_file}"
                      echo "Approved SourceBranches: ${env.Approved_SourceBranches}"
                      echo "Approved DestinationBranches: ${env.Approved_DestinationBranches}"
                      echo "Approved RunCreatePR: ${env.Approved_RunCreatePR}"

                      String srcRaw = (env.Approved_SourceBranches ?: '').trim()
                      String dstRaw = (env.Approved_DestinationBranches ?: '').trim()

                      if (!srcRaw || !dstRaw) {
                        error "Provide both Approved_SourceBranches and Approved_DestinationBranches as comma-separated 'repo:branch' pairs."
                      }

                      def splitCsv = { String s -> s.split(',').collect { it.trim() }.findAll { it } }
                      def parsePairs = { String s ->
                        splitCsv(s).collect { item ->
                          def parts = item.split(':', 2)  // "repo:branch"
                          if (parts.size() != 2 || !parts[0].trim() || !parts[1].trim()) {
                            error "Invalid pair '${item}'. Expected 'repoName:branchName'."
                          }
                          [repo: parts[0].trim(), branch: parts[1].trim()]
                        }
                      }

                      def srcPairs   = parsePairs(srcRaw)
                      def destPairs  = parsePairs(dstRaw)

                      def destByRepo = destPairs.collectEntries { p -> [(p.repo.toLowerCase()): p.branch] }

                      def projectKeyFor = { String repoName, String srcBranch, String destBranch ->
                        def token = (repoName =~ /^([A-Za-z]+)_/).with { m -> m.find() ? m.group(1).toLowerCase() : null }
                        if (!token) {
                          def m1 = (srcBranch ?: '') =~ /(?i)\b(fo|cl|sw|ma)_/
                          if (m1.find()) token = m1.group(1).toLowerCase()
                          else {
                            def m2 = (destBranch ?: '') =~ /(?i)\b(fo|cl|sw|ma)_/
                            if (m2.find()) token = m2.group(1).toLowerCase()
                          }
                        }
                        switch (token) {
                          case 'fo': return 'istfo'
                          case 'cl': return 'istclr'
                          case 'sw': return 'istsw'
                          case 'ma': return 'istmas'
                          default: error "Cannot determine project family from repo='${repoName}'. Expected FO/CL/SW/MA in repo or branch name."
                        }
                      }

                      def workItems = []
                      srcPairs.each { s ->
                        def destBranch = destByRepo[s.repo.toLowerCase()]
                        if (!destBranch) {
                          error "Destination branch missing for repo '${s.repo}'. Make sure repo names match in both lists."
                        }
                        echo "PAIR: repo='${s.repo}' src='${s.branch}' ‚Üí dest='${destBranch}'"
                        def prKey = projectKeyFor(s.repo, s.branch, destBranch)
                        workItems << [repo: s.repo, srcBranch: s.branch, destBranch: destBranch, projectKey: prKey]
                      }

                      if (workItems.isEmpty()) {
                        error "No PR work items could be built from the provided pairs."
                      }

                      workItems.each { item ->
                        stage("Create PR: ${item.repo}  ${item.srcBranch} ‚Üí ${item.destBranch}") {
                          echo """
                          PR Input
                          --------
                          Repository   : ${item.repo}
                          Project Key  : ${item.projectKey}
                          Source Branch: ${item.srcBranch}
                          Dest Branch  : ${item.destBranch}
                          """.stripIndent()

                          // IMPORTANT:
                          // This calls YOUR EXISTING shared library (unchanged).
                          // If an existing open PR already uses the same src‚Üídest,
                          // your library will SKIP by design.
                          // To create "another PR", the dev team must provide a DIFFERENT source branch name.
                          createBitbucketPRs(
                            sourceBranches : [item.srcBranch],   
                            destBranch     : item.destBranch,
                            repoName       : item.repo,
                            projectKey     : item.projectKey,
                            bitbucketCreds : 'cm-credentials-id'
                          )
                        }
                      }
                    }
                  } catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException fie) {
                    echo "Pipeline was manually aborted."
                    currentBuild.result = 'ABORTED'
                    throw fie
                  }
                }
              }
            }
                        
            stage('Checkmarx') {
                environment {
                    GIT_CRED = credentials('cm-credentials-id')
                    GITROOT = "${env.WORKSPACE}/gitroot"
                }
                steps {
                    container('ist-build-agent') {
                        script {
                            try {
                              	def cxProjectName = "${env.Cx_CxOne_Project_Name}"
                                def dayOfWeek = new Date().format('u').toInteger()
                                def branchName = env.BRANCH_NAME ?: ""
								def isIncrementalScan = !branchName.startsWith("release/")
                                env.release_file_name_transformed = env.release_file.replace(".release", "")

                                withCredentials([
                                    usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
                                ]) {
                                    sh """
                                        printf "$JENKINS_USER\n$JENKINS_PASSWORD\n" > export:BLD_CREDENTIALS
                                        export USERID=$JENKINS_USER
                                        export USERACCESS=$JENKINS_PASSWORD

                                        if grep -q '^sw_base:' ${env.WORKSPACE}/${env.release_file_name}; then
                                            sw_base_branch=\$(grep '^sw_base:' ${env.WORKSPACE}/${env.release_file_name} | cut -d':' -f2)
                                            sed -i "s|^sw_segment:master|sw_segment:\${sw_base_branch}|" ${env.WORKSPACE}/${env.release_file_name}
                                        fi

                                        grep -E '(:|_OS_)' ${env.WORKSPACE}/${env.release_file_name} > ${env.WORKSPACE}/${env.release_file_name_transformed}.rel
                                        echo "Filtered Release File:"
                                        cat ${env.WORKSPACE}/${env.release_file_name_transformed}.rel

                                        ${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts/build_checkmarx_jk.ksh -bt=develop ${env.WORKSPACE}/${env.release_file_name_transformed}.rel
                                    """
                                }


                                def scanner = new fi.scan.CheckmarxScan()
                                scanner.call([
                                    script: this,
                                    cxProjectName: cxProjectName,
                                    configval: configval,
                                    isIncrementalScan: isIncrementalScan
                                ])

                                archiveArtifacts artifacts: 'Checkmarx/Reports/*.html', allowEmptyArchive: true
                                archiveArtifacts artifacts: 'Checkmarx/Reports/*.pdf', allowEmptyArchive: true

                                def checkmarx_scanOutput = currentBuild.rawBuild.getLog(10000).join("\n")
                                def checkmarx_scanId = extractCxScanId(checkmarx_scanOutput)

                                if (checkmarx_scanId) {
                                    echo "Extracted CxOne Scan ID: ${checkmarx_scanId}"
                                } else {
                                    echo "No Scan ID found in Checkmarx logs"
                                }

                                env.CHECKMARX_SCAN_ID = checkmarx_scanId
                            } catch (Exception e) {
                                echo "Error occurred during 'Checkmarx' stage: ${e.getMessage()}"
                                currentBuild.result = 'FAILURE'
                                error("Checkmarx stage failed.")
                            }
                        }
                    }
                }
            }
            stage('Checkmarx One') {
                steps {
                    script {
                        try {
                            def cxOneProjectName = "${env.Cx_CxOne_Project_Name}"
                            def cxonetagId = config.cxonescan.tagId
                            def cxOneProjectGroup = config.cxonescan.projectGroup

                            // Run Checkmarx One scan
                            def scanner = new fi.scan.CheckmarxOneScan()
                            scanner.call([
                                script: this,
                                configval: configval,
                                cxOneProjectName: cxOneProjectName,
                                cxonetagId: cxonetagId,
                                cxOneProjectGroup: cxOneProjectGroup
                            ])
                        } catch (Exception e) {
                            echo "Error occurred during 'Checkmarx One' stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Checkmarx One stage failed.")
                        }
                    }
                }
            }
          	stage('Policy-As-Code') {          	
          	    steps {
                    container('python') {
                        script {
                            sh """
                            mkdir pac
                            """
                          	def eopaPath = "./eopa"
                            dir('pac') {
                                checkout([$class: 'GitSCM', branches: [[name: 'master']], extensions: [], userRemoteConfigs: [[credentialsId: 'cm-credentials-id', url: 'https://bitbucket.fi.dev/scm/tdodso/tdo_devsecops.git']]])
                                sh """
                                    git checkout master
                                    curl -fsSL -o ${eopaPath} https://github.com/StyraInc/enterprise-opa/releases/latest/download/eopa_Linux_x86_64
                                    chmod +x ${eopaPath}
                                """
                            }

                            // Read config and run Python script
                            def config = readYaml file: "${env.WORKSPACE}/Jenkins/params.yaml"
                            def cxOneProjectName = "${env.Cx_CxOne_Project_Name}"
                            def cxProjectName = "${env.Cx_CxOne_Project_Name}"
                            def cxonetagId = config.cxonescan.tagId

							withCredentials([
								usernamePassword(credentialsId: 'IST-CheckMarx', passwordVariable: 'CX_PWD', usernameVariable: 'CX_USER'),
								usernamePassword(credentialsId: 'OPA_CXONE_SWITCH', passwordVariable: 'CXONE_PWD', usernameVariable: 'CXONE_USER'),
							]) {
								dir('pac') {
									sh """
										export https_proxy=http://mazproxy.fidev.local:8080
										export http_proxy=http://mazproxy.fidev.local:8080
										pip3 install -r requirements.txt
										sleep 5

										python3 secOps.py \\
											--cxone_client_id="${CXONE_USER}" \\
											--cxone_client_secret="${CXONE_PWD}" \\
											--cxOneProjectName="${cxOneProjectName}" \\
											--cxOneBranchName="${env.BRANCH_NAME}" \\
											--scInternetFacing=false \\
											--vulnCategory=open \\
											--scAssetId="${cxonetagId}" \\
											--cxTeamId=653 \\
											--cxProjectName="${cxProjectName}" \\
											--cxsast_username="${CX_USER}" \\
											--cxsast_password="${CX_PWD}" \\
											--output=json \\
											--debug
									"""
								}

                                // Run OPA logic
                                try {
                                    runOPAAndHandleResults(
                                        credentialsId: "cm-credentials-id",
                                        CheckmarxoneProjectname: "${cxProjectName}",
                                        cxProjectName: "${cxOneProjectName}"
                                    )
                                } catch (Exception e) {
                                    echo "Error occurred during 'Policy-As-Code' stage: ${e.getMessage()}"
                            		currentBuild.result = 'FAILURE'
                            		error("Policy-As-Code stage failed.")
                                }
                            }
                        }
                    }
                }
            }
          	
            stage('Upload Release Logs and Scan Report') {
                steps {
                    wrap([$class: 'BuildUser']) {
                        script {
                            // Detect OS and version
                            def detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
                            def AIXVersion = detectedOS == "aix" ? sh(script: "oslevel", returnStdout: true).trim() : ""
                            def isAIX73 = (detectedOS == "aix" && AIXVersion.startsWith("7.3"))

                            try {
                                echo "Upload Stage Start: " + new Date().format("EEE MMM d yyyy HH:mm:ss z", TimeZone.getTimeZone('UTC'))

                                def userFullName = env.BUILD_USER
                                def userEmail = env.BUILD_USER_EMAIL ?: "${userFullName}@figlobal.com"

                                def scmUrl = env.GIT_URL ?: scm?.getUserRemoteConfigs()?.getAt(0)?.getUrl()
                                def repoUrl = scmUrl?.replaceAll(/\.git$/, '') ?: "https://bitbucket.fi.dev/scm/istsw/sw_devops"

                                def releaseFileName = env.release_file_name ?: "unknown_release_file"
                                def branchName = env.BRANCH_NAME ?: "main"
                                def jenkinsJobUrl = env.BUILD_URL ?: "N/A"

                                def releaseFilePath = "${env.WORKSPACE}/release_info_${env.BUILD_NUMBER}.txt"
                                configval = configval ?: [selectedOsName: "unknown"]

                                def releaseInfoContent = """\
            Triggered By: ${userFullName}
            Email: ${userEmail}
            Release File: "${releaseFileName}"
            Branch: "${branchName}"
            Timestamp: ${new Date().format("yyyy-MM-dd HH:mm:ss", TimeZone.getTimeZone("UTC"))}
            Jenkins Job URL: ${jenkinsJobUrl}
            Repo URL: ${repoUrl}
            Agent Name: ${configval.selectedOsName}
            """
                                writeFile file: releaseFilePath, text: releaseInfoContent
                                sh "cat ${releaseFilePath}"

                                // Generate scan_results file only for RHEL8
                                def scanFilePath = ""
                                if (configval?.selectedOsName == "RHEL8") {
                                    echo "Detected RHEL8 - generating scan_results file"
                                    scanFilePath = "${env.WORKSPACE}/scans_results_${env.BUILD_NUMBER}.txt"
                                    def scanId = env.CHECKMARX_SCAN_ID ?: "N/A"
                                    def cxOneScanId = env.CXONE_SCAN_ID ?: "N/A"
                                    def scanContent = """\
            CXProjectName="${env.Cx_CxOne_Project_Name}" 
            CXScanId=${scanId} 
            CxOneProject="${env.Cx_CxOne_Project_Name}" 
            CxSCAScanId=${cxOneScanId}
            """
                                    writeFile file: scanFilePath, text: scanContent
                                    sh "cat ${scanFilePath}"
                                } else {
                                    echo "Skipping scan_results file generation - OS is not RHEL8"
                                }

                                // Upload to Artifactory
                                def datas2 = readYaml file: "./Jenkins/params.yaml"
                                def repoUrlArtifactory = datas2.artifactory.Path
                                def buildType = "development"
                                def txtSubPath = "release_logs/${releaseFileName}"

                                withCredentials([
                                    usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'ART_USER', passwordVariable: 'ART_PASS')
                                ]) {
                                    echo "Uploading release info to Artifactory"
                                    new RccCppBuild().artifactUploadTgz([
                                        artifactPath: releaseFilePath,
                                        repoUrl: repoUrlArtifactory,
                                        buildType: buildType,
                                        subPath: txtSubPath,
                                        artifactory: datas2.artifactory
                                    ])

                                    if (scanFilePath && fileExists(scanFilePath)) {
                                        echo "Uploading scan results to Artifactory"
                                        new RccCppBuild().artifactUploadTgz([
                                            artifactPath: scanFilePath,
                                            repoUrl: repoUrlArtifactory,
                                            buildType: buildType,
                                            subPath: txtSubPath,
                                            artifactory: datas2.artifactory
                                        ])
                                    }
                                }

                                echo "Upload Stage End: " + new Date().format("EEE MMM d yyyy HH:mm:ss z", TimeZone.getTimeZone('UTC'))
                            } catch (Exception e) {
                                echo "Error occurred during 'Upload Release Logs and Scan Report' stage: ${e.getMessage()}"
                            	currentBuild.result = 'FAILURE'
                            	error("Upload Release Logs and Scan Report stage failed.")
                            }
                        }
                    }
                }
            }
          	stage('Upload to Artifactory') {
                steps {
					script {
						try {
							def datas2 = readYaml file: "./Jenkins/params.yaml"
							def tgzFilesPath = sh(script: "ls ${env.WORKSPACE}/*.tgz | awk -F'/' '{print \$NF}'", returnStdout: true).trim().toString()
							def tgzFiles = tgzFilesPath ? tgzFilesPath.split('\n') : []
							def buildType = "development"
							def repoUrl = datas2.artifactory.Path
                          	def tgzSubPath = "rel_tgz/Oja_release/lin"
							if (tgzFiles.size() == 0) {
								echo "No tgz files found!"
							} else {
								tgzFiles.each { tgzFile ->
									echo "Uploading tgz artifact: ${tgzFile}"
									new RccCppBuild().artifactUploadTgz([
										artifactPath: tgzFile,
										repoUrl: repoUrl,
										buildType: buildType,
										subPath: tgzSubPath,
										artifactory: datas2.artifactory
									])
								}
							}
						} catch (Exception e) {
							echo "Error occurred during 'Upload to Artifactory' stage: ${e.getMessage()}"
                            currentBuild.result = 'FAILURE'
                            error("Upload to Artifactory stage failed.")
						}
					}
				}
			}
          	stage('Submit Execution to Harness SEI') {
                steps {
                    script {
                        harnessSeiCode(configval, env)
                    }
                }
            }
        }
		post {
            always {
                script {
                    echo "Current build result: ${currentBuild.result}"
                  	def yaml = readYaml file: "./Jenkins/params.yaml"
                    def defaultEmail = yaml.NotifyEmail
                    def isPRBuild = env.CHANGE_ID != null
                    def email = isPRBuild && env.PR_AUTHOR_EMAIL ? env.PR_AUTHOR_EMAIL : defaultEmail
                    def selectedOsName = "${configval.selectedOsName}"
                  	def releaseFileName = "${env.release_file_name}"
                  	def emailcxProjectName = env.CX_PROJECT_NAME
                    def emailcxOneProjectName = env.CXONE_PROJECT_NAME
                    def emailcxScanId = env.CHECKMARX_SCAN_ID
                    def emailcxOneScanId = env.CHECKMARXONE_SCAN_ID
                    if (configval.buildcomponent == 'rcc_build') {
                        echo "Current build result: ${currentBuild.result}"
                        if (currentBuild.result == 'SUCCESS') {
                           ocpEmailConfig.releaseSendPipelineStatus('SUCCESS', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        } else if (currentBuild.result == 'FAILURE') {
                            ocpEmailConfig.releaseSendSimplePipelineStatus('FAILURE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName)
                        } else if (currentBuild.result == 'UNSTABLE') {
                            ocpEmailConfig.releaseSendPipelineStatus('UNSTABLE', selectedOsName, triggerTimeEDTStr, triggerTimeISTStr, releaseFileName, emailcxProjectName, emailcxOneProjectName, emailcxScanId, emailcxOneScanId)
                        }
                    }
                }
            }
        }
    }
}


------------------------------------------------releaseapprovalstage.groovy--------------------------------------------------


import org.jenkinsci.plugins.workflow.steps.FlowInterruptedException

@NonCPS
String extractProjectCode(String releaseFileName) {
  // Use NonCPS to keep Matcher out of CPS serialization
  def m = (releaseFileName =~ /^([A-Z]+[0-9]{2,4})/)
  return m.find() ? m.group(1) : null
}

def call(configval) {
  try {
    wrap([$class: 'BuildUser']) {
      // üîí Only these Jenkins users can approve
      def allowedApprovers = ['lc5751820', 'e5648518', 'lc5679161']
      def allowedApproverListStr = allowedApprovers.join(', ')
      def submitterList = allowedApprovers.join(',')

      def buildUserEmail = (env.BUILD_USER_EMAIL ?: '').trim()
      def buildUserId    = env.BUILD_USER_ID ?: env.BUILD_USER
      def buildUrl       = "${env.BUILD_URL}"

      echo "Build triggered by: ${env.BUILD_USER} (ID: ${buildUserId})"
      echo "Build user email: ${buildUserEmail ?: 'N/A'}"
      echo "Allowed approvers: ${allowedApproverListStr}"

      // ---- Read params.yaml
      if (!fileExists('./Jenkins/params.yaml')) {
        currentBuild.result = 'ABORTED'
        error "params.yaml not found at ./Jenkins/params.yaml"
      }
      def paramsYaml = readYaml file: './Jenkins/params.yaml'
      def releaseFileNameFromYaml = (paramsYaml.releaseFileName ?: '').toString().trim()
      if (!releaseFileNameFromYaml) {
        currentBuild.result = 'ABORTED'
        error "releaseFileName not found in ./Jenkins/params.yaml"
      }

      // ---- Ensure release file exists
      def checkReleaseFile = findFiles(glob: "**/${releaseFileNameFromYaml}.release")
      if (checkReleaseFile.size() == 0) {
        echo "Release file '${releaseFileNameFromYaml}.release' not found in the repo."
        currentBuild.result = 'ABORTED'
        error("Exiting due to missing release file.")
      }
      // Export early so description can use it later
      env.release_file      = checkReleaseFile[0].path
      env.release_file_name = env.release_file.replace(".release", "")

      // ---- Build Cx/CheckmarxOne project name from component type + code
      if (!configval?.swComponentType || !configval?.selectedOsName) {
        currentBuild.result = 'ABORTED'
        error "configval.swComponentType and configval.selectedOsName must be provided in the pipeline context."
      }
      def matchedCode = extractProjectCode(releaseFileNameFromYaml)
      if (!matchedCode) {
        currentBuild.result = 'ABORTED'
        error "Failed to extract project code from '${releaseFileNameFromYaml}'. Expected starting pattern like ABC123/ABCD1234."
      }
      def componentTypeUpper = configval.swComponentType.toUpperCase()
      env.Cx_CxOne_Project_Name = "IST_${componentTypeUpper}_${matchedCode}_prod"
      echo "Generated Cx/CxOne project name: ${env.Cx_CxOne_Project_Name}"

      // ---- Defaults for additional inputs (branches only; keep as CSV strings)
      def sourceBranchesDefault      = (paramsYaml.sourceBranches ?: ['main']).collect { it.toString().trim() }.join(',')
      def destinationBranchesDefault = (paramsYaml.destinationBranches ?: ['release']).collect { it.toString().trim() }.join(',')

      // ---- Variables to capture input
      def userInputRelease       = null
      def userInputProject       = null
      def userInputSrc           = null       // keep as STRING of pairs (e.g., "fo_base:release/...,sw_base:release/...")
      def userInputDest          = null
      def userInputRunCreatePR   = 'No'       // default
      def approvalReceived       = false

      // üïî First approval attempt (5 minutes) ‚Äì restricted to allowed approvers
      try {
        timeout(time: 5, unit: 'MINUTES') {
          def res = input(
            message: """Manual approval required.

Only the following users can approve: ${allowedApproverListStr}

Release file: ${releaseFileNameFromYaml}
Project name (Checkmarx/CheckmarxOne): ${env.Cx_CxOne_Project_Name}

Detected source branches: ${sourceBranchesDefault}
Detected destination branches: ${destinationBranchesDefault}

Confirm or override defaults below (format: key:branch,otherkey:branch2).""",
            ok: 'Proceed',
            parameters: [
              string(
                defaultValue: "${releaseFileNameFromYaml}",
                description: "Enter the release file name to confirm",
                name: "ConfirmedReleaseFile"
              ),
              string(
                defaultValue: "${env.Cx_CxOne_Project_Name}",
                description: "Enter the project name to confirm",
                name: "ConfirmedProjectName"
              ),
              string(
                name: 'SourceBranches',
                defaultValue: sourceBranchesDefault,
                description: 'Enter source branches (comma-separated key:branch pairs)'
              ),
              string(
                name: 'DestinationBranches',
                defaultValue: destinationBranchesDefault,
                description: 'Enter destination branches (comma-separated key:branch pairs)'
              ),
              // ‚úÖ Yes/No to control Create PR stage
              choice(
                name: 'RunCreatePR',
                choices: "Yes\nNo",
                description: 'Select "Yes" to run the Create PR stage; otherwise choose "No".'
              )
            ],
            submitter: submitterList
          )
          userInputRelease       = (res['ConfirmedReleaseFile'] ?: '').toString().trim()
          userInputProject       = (res['ConfirmedProjectName'] ?: '').toString().trim()
          userInputSrc           = (res['SourceBranches'] ?: '').toString().trim()
          userInputDest          = (res['DestinationBranches'] ?: '').toString().trim()
          userInputRunCreatePR   = (res['RunCreatePR'] ?: 'No').toString()
          approvalReceived       = true

          // Export immediately so downstream cannot see nulls
          env.Approved_SourceBranches      = userInputSrc
          env.Approved_DestinationBranches = userInputDest
          env.Approved_RunCreatePR         = userInputRunCreatePR.equalsIgnoreCase('Yes') ? 'true' : 'false'
        }
      } catch (err) {
        echo "No approval received within 5 minutes."
      }

      // üìß If not approved, email job user and wait up to 3 hours (still restricted to allowed approvers)
      if (!approvalReceived) {
        if (buildUserEmail) {
          emailext(
            to: "${buildUserEmail}",
            subject: "Approval Needed: Confirm Release, Project & Branches for Build #${env.BUILD_NUMBER}",
            body: """Hello,

A manual approval is required to proceed with the pipeline for build #${env.BUILD_NUMBER}.

Release file detected: ${releaseFileNameFromYaml}
Project name generated: ${env.Cx_CxOne_Project_Name}

Detected source branches: ${sourceBranchesDefault}
Detected destination branches: ${destinationBranchesDefault}

No approval was received within 5 minutes on Jenkins UI.

Only the following Jenkins users can approve this request: ${allowedApproverListStr}

Please go to Jenkins and approve within the next 3 hours.

Build URL: ${buildUrl}

Thanks,
Jenkins Pipeline
"""
          )
        } else {
          echo "Build user email not available; skipping email notification."
        }

        try {
          timeout(time: 3, unit: 'HOURS') {
            def res2 = input(
              message: """Manual approval required (post-email).

Only the following users can approve: ${allowedApproverListStr}

Release file: ${releaseFileNameFromYaml}
Project name (Checkmarx/CheckmarxOne): ${env.Cx_CxOne_Project_Name}

Detected source branches: ${sourceBranchesDefault}
Detected destination branches: ${destinationBranchesDefault}

Confirm or override defaults below (format: key:branch,otherkey:branch2).""",
              ok: 'Proceed',
              parameters: [
                string(
                  defaultValue: "${releaseFileNameFromYaml}",
                  description: "Enter the release file name to confirm",
                  name: "ConfirmedReleaseFile"
                ),
                string(
                  defaultValue: "${env.Cx_CxOne_Project_Name}",
                  description: "Enter the project name to confirm",
                  name: "ConfirmedProjectName"
                ),
                string(
                  name: 'SourceBranches',
                  defaultValue: sourceBranchesDefault,
                  description: 'Enter source branches (comma-separated key:branch pairs)'
                ),
                string(
                  name: 'DestinationBranches',
                  defaultValue: destinationBranchesDefault,
                  description: 'Enter destination branches (comma-separated key:branch pairs)'
                ),
                // ‚úÖ Yes/No to control Create PR stage (post-email)
                choice(
                  name: 'RunCreatePR',
                  choices: "Yes\nNo",
                  description: 'Select "Yes" to run the Create PR stage; otherwise choose "No".'
                )
              ],
              submitter: submitterList
            )
            userInputRelease       = (res2['ConfirmedReleaseFile'] ?: '').toString().trim()
            userInputProject       = (res2['ConfirmedProjectName'] ?: '').toString().trim()
            userInputSrc           = (res2['SourceBranches'] ?: '').toString().trim()
            userInputDest          = (res2['DestinationBranches'] ?: '').toString().trim()
            userInputRunCreatePR   = (res2['RunCreatePR'] ?: 'No').toString()
            approvalReceived       = true

            // Export immediately
            env.Approved_SourceBranches      = userInputSrc
            env.Approved_DestinationBranches = userInputDest
            env.Approved_RunCreatePR         = userInputRunCreatePR.equalsIgnoreCase('Yes') ? 'true' : 'false'
          }
        } catch (err2) {
          echo "No approval received after email within 3 hours."
        }
      }

      // Abort cleanly if no approval at all
      if (!approvalReceived) {
        currentBuild.result = 'ABORTED'
        error("Pipeline aborted due to no approval after UI + email notification.")
      }

      // ---- Validate strict matches for release & project name
      if (userInputRelease != releaseFileNameFromYaml) {
        currentBuild.result = 'ABORTED'
        error "User input '${userInputRelease}' does not match release file name '${releaseFileNameFromYaml}'."
      }
      if (userInputProject != env.Cx_CxOne_Project_Name) {
        currentBuild.result = 'ABORTED'
        error "User input '${userInputProject}' does not match project name '${env.Cx_CxOne_Project_Name}'."
      }

      // ---- Branch validation: only enforce format if PR is requested
      def runCreatePR = env.Approved_RunCreatePR == 'true'

      // Basic non-empty checks are okay to keep regardless
      if (!userInputSrc) {
        currentBuild.result = 'ABORTED'
        error "SourceBranches was empty; provide at least one value."
      }
      if (!userInputDest) {
        currentBuild.result = 'ABORTED'
        error "DestinationBranches was empty; provide at least one value."
      }

      if (runCreatePR) {
        // Only when PR = Yes: enforce key:branch pattern
        if (!userInputSrc.contains(':')) {
          currentBuild.result = 'ABORTED'
          error "When 'RunCreatePR' is Yes, SourceBranches must be in format key:branch (comma-separated for multiple)."
        }
        if (!userInputDest.contains(':')) {
          currentBuild.result = 'ABORTED'
          error "When 'RunCreatePR' is Yes, DestinationBranches must be in format key:branch (comma-separated for multiple)."
        }
      } else {
        echo "RunCreatePR is 'No' ‚Äî skipping key:branch pattern checks for Source/Destination branches."
      }

      // Final echoes
      echo "Confirmed release file: ${env.release_file}"
      echo "Approved SourceBranches: ${env.Approved_SourceBranches}"
      echo "Approved DestinationBranches: ${env.Approved_DestinationBranches}"
      echo "Approved RunCreatePR: ${env.Approved_RunCreatePR}"

      currentBuild.description = "${env.release_file_name}:${configval.selectedOsName}"
    }
  } catch (FlowInterruptedException fie) {
    echo "Pipeline was manually aborted."
    currentBuild.result = 'ABORTED'
    throw fie
  } catch (InterruptedException ie) {
    // Covers other interruption paths
    echo "Pipeline interrupted."
    currentBuild.result = 'ABORTED'
    throw ie
  }
}

------------------------------------------------------------selectOS.groovy-------------------------------------------------
import org.yaml.snakeyaml.Yaml

def call() {
    echo "Inside SelectOS"
    def yamlContent = libraryResource('fi/IST/OSType.yaml')
    def yaml = new Yaml()
    def data = yaml.load(yamlContent)
    echo "[DEBUG] Loaded YAML content: ${data}"
    return data.os_list
}

---------------------------------WsSetup.groovy-------------------------------------------------------------------

def call(params = [:]){
    if( params.cleanup ){
        echo "Cleaning up workspaces"
        cleanOldWorkspace( params.days ?: 5, params.jobNamePart )
        return
    }

    return setupWorkspace(params.jobNamePart)
}

private String setupWorkspace(String jobnamepart) {
    echo "Inside the setup workspaces"
     String branchFolder 
     if( env.CHANGE_ID ){
        branchFolder = env.CHANGE_BRANCH ?: env.BRANCH_NAME
     }
     else {
            branchFolder =  env.BRANCH_NAME
     }
     String updatedBranchName = branchFolder.replaceAll('/', '_')

     String workspaceName = env.CHANGE_ID ? "PR-${env.CHANGE_ID}" : "${env.BUILD_NUMBER}"

    //String workspacePath = "workspace/${updatedBranchName}/${workspaceName}"

    //  ws(workspacePath){
    //     checkout scm
    //  }

    

     String repoName = "" 
     if ( env.GIT_URL ) {
        String[] gitUrlSegments = env.GIT_URL.tokenize('/')
        String repoFileName = gitUrlSegments[-1]
        repositoryName = repoFileName.replace('.git', '')
    }

     return "${jobnamepart}/${repoName}${updatedBranchName}/${workspaceName}"
}

private void cleanOldWorkspace(int daysOld, String jobnamepart = '') {
    echo "Starting selective workspace cleanup..."

    String branchFolder = env.CHANGE_ID ? (env.CHANGE_BRANCH ?: env.BRANCH_NAME) : env.BRANCH_NAME
    String updatedBranchName = branchFolder.replaceAll('/', '_')
    String workspacePath = "/data/jenkins/workspace/${jobnamepart}/${updatedBranchName}"

    if (!workspacePath.contains('workspace')) {
        error "Invalid cleanup path detected: ${workspacePath}"
    }

    boolean isPR = env.CHANGE_ID ? true : false

    try {
        sh """
            set -e
            echo "Cleaning up directories older than ${daysOld} days in: ${workspacePath}"

            if [ -d "${workspacePath}" ]; then
                if [ ${isPR} = true ]; then
                    # Delete only PR-* folders older than N days
                    PR_DIRS=\$(find "${workspacePath}" -mindepth 1 -maxdepth 1 -type d -mtime +${daysOld} -name "PR-*")
                    echo "Found PR directories: \${PR_DIRS}"
                    if [ -n "\${PR_DIRS}" ]; then
                        echo "Deleting PR directories: \${PR_DIRS}"
                        echo "\${PR_DIRS}" | xargs -r rm -rf
                    else
                        echo "No PR directories older than ${daysOld} days found."
                    fi
                else
                    # Delete only numeric-named folders older than N days (AIX-compatible)
                    NUMERIC_DIRS=\$(find "${workspacePath}" -mindepth 1 -maxdepth 1 -type d -mtime +${daysOld})
                    echo "Found numeric-named directories: \${NUMERIC_DIRS}"
                    NUMERIC_DIRS=\$(echo "\${NUMERIC_DIRS}" | grep '/[0-9]\\{1,\\}\$')
                    echo "Filtered numeric-named directories: \${NUMERIC_DIRS}"
                    if [ -n "\${NUMERIC_DIRS}" ]; then
                        echo "Deleting numeric-named directories: \${NUMERIC_DIRS}"
                        echo "\${NUMERIC_DIRS}" | xargs -r rm -rf
                    else
                        echo "No numeric-named directories older than ${daysOld} days found."
                    fi
                fi
            else
                echo "Directory ${workspacePath} does not exist. Skipping cleanup."
            fi
        """
    } catch (Exception e) {
        echo "No directories found for cleanup or an error occurred. Proceeding to the next stage."
    }
}



/*private void cleanOldWorkspace(int daysOld, String jobnamepart = '') {
    echo "Starting selective workspace cleanup..."

    String workspacePath = env.WORKSPACE.replaceAll('/[0-9]+$', '').replaceAll('/PR-[0-9]+$', '')
    String currentBuildDir = env.CHANGE_ID ? "PR-${env.CHANGE_ID}" : "${env.BUILD_NUMBER}"


    if (!workspacePath.contains('workspace')) {
        error "Invalid cleanup path detected: ${workspacePath}"
    }

        sh """
            set -e
            echo "Cleaning up workspace directories in: ${workspacePath}"

            if [ -d "${workspacePath}" ]; then
                echo "Identifying PR and Non-PR-* directories to delete..."

                dirs=\$(ls -td ${workspacePath}/PR-* ${workspacePath}/[0-9]* 2>/dev/null | grep -v '@tmp' | grep -v "/${currentBuildDir}\$")
                dirs_to_delete=\$(echo "\$dirs" | tail -n +2)

                if [ -n "\$dirs_to_delete" ]; then
                    echo "\$dirs_to_delete" | while read dir; do
                        if [ -d "\$dir" ]; then
                            if ! lsof +D "\$dir" >/dev/null 2>&1; then
                                echo "Deleting unused directory: \$dir"
                                rm -rf "\$dir"
                            else
                                echo "Skipping active directory: \$dir"
                            fi
                        fi
                    done
                else
                    echo "No old PR or Non-PR-* directories to delete."
                fi
            else
                echo "Directory ${workspacePath} does not exist. Skipping cleanup."
            fi
    """

}

private void cleanOldWorkspace(int daysOld, String jobnamepart = '') {
    echo "Starting selective workspace cleanup..."

    String branchFolder = env.CHANGE_ID ? (env.CHANGE_BRANCH ?: env.BRANCH_NAME) : env.BRANCH_NAME
    String updatedBranchName = branchFolder.replaceAll('/', '_')
    String workspacePath = "/data/jenkins/workspace/${jobnamepart}/${updatedBranchName}"

    if (!workspacePath.contains('workspace')) {
        error "Invalid cleanup path detected: ${workspacePath}"
    }

    boolean isPR = env.CHANGE_ID ? true : false

    sh """
        set -e
        echo "Cleaning up directories older than ${daysOld} days in: ${workspacePath}"

        if [ -d "${workspacePath}" ]; then
            if [ ${isPR} = true ]; then
                # Delete only PR-* folders older than N days
                find "${workspacePath}" -mindepth 1 -maxdepth 1 -type d -mtime +${daysOld} -name "PR-*" -exec rm -rf {} +
            else
                # Delete only numeric-named folders older than N days (AIX-compatible)
                find "${workspacePath}" -mindepth 1 -maxdepth 1 -type d -mtime +${daysOld} | \
                grep '/[0-9]\\{1,\\}\$' | xargs -r rm -rf
            fi
        else
            echo "Directory ${workspacePath} does not exist. Skipping cleanup."
        fi
    """
}*/


// private void cleanOldWorkspace(int daysOld, String jobnamepart = '') {
//     echo "Inside Cleaning up workspaces"
//     String branchFolder 
//     if (env.CHANGE_ID) {
//         branchFolder = env.CHANGE_BRANCH ?: env.BRANCH_NAME
//     } else {
//         branchFolder = env.BRANCH_NAME
//     }

//     String updatedBranchName = branchFolder.replaceAll('/', '_')
//     String workspacePath = "/data/jenkins/workspace/${jobnamepart}/${updatedBranchName}" 

//     echo "workspacepath : ${workspacePath}"

//     if (!workspacePath.contains('workspace')) {
//         echo "Inside Cleaning up workspaces detected"
//         error "Invalid cleanup path detected. Path ${workspacePath}"
//     }

//     boolean isPR = env.CHANGE_ID ? true : false

//     sh """
//         set -x
//         echo "Cleaning up workspaces older than ${daysOld} days in : ${workspacePath}"
//         if [ -d "${workspacePath}" ]; then
//             for fullpath in "${workspacePath}"/*; do
//                 if [ -d "\$fullpath" ]; then
//                     dir=\$(basename "\$fullpath")
//                     # Check if directory is older than specified days
//                     if [ \$(find "\$fullpath" -prune -type d -mtime +${daysOld} -print) ]; then
//                         if [ "${isPR}" = "true" ]; then
//                             case "\$dir" in
//                                 PR-${env.CHANGE_ID}-*) 
//                                     echo "Deleting PR workspace: \$fullpath"
//                                     rm -rf "\$fullpath"
//                                     ;;
//                             esac
//                         else
//                             case "\$dir" in
//                                 [0-9]*) 
//                                     echo "Deleting numbered workspace: \$fullpath"
//                                     rm -rf "\$fullpath"
//                                     ;;
//                             esac
//                         fi
//                     fi
//                 fi
//             done
//         else
//             echo "Directory ${workspacePath} does not exist, skipping cleanup."
//         fi
//     """
// }


--------------------------------------------------------rcccppbuild.groovy-------------------------------------------------
package fi.ist
import org.jenkinsci.plugins.workflow.steps.FlowInterruptedException

def artifactUploadTgz(Map params = [:]) {
    def artifactPath = params.artifactPath
    def buildType = params.buildType
    def repoUrl = params.repoUrl
    def subPath = params.subPath

    echo "Params: ${params}"
    echo "Artifact Path: ${artifactPath}"
    echo "Build Type: ${buildType}"
    echo "Repo URL: ${repoUrl}"
    echo "Artifactory: ${params.artifactory}"

    def artifactName = artifactPath.tokenize('/').last()
    def repositoryPath = buildType == 'release' ? params.artifactory.REPO.release : params.artifactory.REPO.development
    def uploadUrlPath = "${repoUrl}/${repositoryPath}/${subPath}/${artifactName}"

    def credentialsId = buildType == 'release' ? 'svcacct_istartifact' : 'svcacct_istartifact'

    // Detect OS and version
    def detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
    def AIXVersion = detectedOS == "aix" ? sh(script: "oslevel", returnStdout: true).trim() : ""
    def isAIX73 = (detectedOS == "aix" && AIXVersion.startsWith("7.3"))

    // Apply proxy settings for AIX 7.3
    if (isAIX73) {
        echo "Detected AIX 7.3 - applying proxy settings"
        sh """
          export http_proxy=http://10.236.163.21:8080/
          export https_proxy=http://10.236.163.21:8080/
          export no_proxy=.fidev.local,.fnis.com
        """
    }

    echo "[artifactUpload] Preparing upload for artifact: ${artifactName}"
    echo "[artifactUpload] Target URL: ${uploadUrlPath}"

    withCredentials([
        usernamePassword(credentialsId: credentialsId, usernameVariable: 'ART_USER', passwordVariable: 'ART_PASS')
    ]) {
        echo "[artifactUpload] Uploading artifact..."

        def curlCommand = isAIX73 ? """
            curl --retry 5 \\
                 --retry-delay 5 \\
                 --retry-connrefused \\
                 --connect-timeout 10 \\
                 --max-time 120 \\
                 --fail \\
                 --location \\
                 -u ${ART_USER}:${ART_PASS} \\
                 -T "${artifactPath}" \\
                 "${uploadUrlPath}"
        """ : """
            curl -u ${ART_USER}:${ART_PASS} -T "${artifactPath}" "${uploadUrlPath}" --fail
        """

        def result = sh(script: curlCommand, returnStatus: true)

        if (result != 0) {
            error "[artifactUpload] Upload failed with exit code ${result}"
        } else {
            echo "[artifactUpload] Upload successful!"
        }
    }
}

def downloaddependency(Map params = [:]) {
    def Project_repo = params.project_repo.split(',')
    def GitCreds = params.gitCreds

    withCredentials([usernamePassword(credentialsId: GitCreds, usernameVariable: 'GIT_USERNAME', passwordVariable: 'GIT_PASSWORD')]) {
        for (int i = 0; i < Project_repo.size(); i++) {
            def str_branch = Project_repo[i].split(':')
            if (str_branch.size() < 2 || !str_branch[1]) {
                error "Invalid repo format or missing branch name for entry: ${Project_repo[i]}"
            }

            def repoPath = str_branch[0]
            def branch = str_branch[1]
            def repoName = repoPath.tokenize('/').last()

            echo "Cloning repo: ${repoPath} on branch: ${branch}"

           sh """
                if [ -d "${repoName}" ]; then
                    echo "Directory ${repoName} already exists. Skipping clone."
                else
                    git clone --depth 1 --branch ${branch} https://\$GIT_USERNAME:\$GIT_PASSWORD@bitbucket.fi.dev/scm/${repoPath}.git
                fi
            """
        }
    }
}
    
def build(Map params = [:]) {
    println "Building...."
    //Integer Artgen = 1
    String Build_Params
    println "${params.artFile}"
    println "Branch Type: ${params.branch_Type}"
    echo "Oracle home:${params.oracle_home}" 
    def buildMarker = params.buildMarker
    if (params.releasefile == null) {
        println "No Release file passed"
        Build_Params = "${params.build_Flags} ./branch-build.list"
    } else {
        println "Release file: ${params.releasefile}"
        Build_Params = "${params.build_Flags} ${params.releasefile}"
    }
  
    String detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()

    if (detectedOS == "linux") {
        env.HOME = "${env.WORKSPACE}"
    } else if (detectedOS == "aix") {
        String aixVersion = sh(script: 'oslevel', returnStdout: true).trim()
        if (aixVersion.startsWith("7.3")) {
            env.HOME = "/home3/istrcc-jenkins-aix73"
        } else if (aixVersion.startsWith("7.2")) {
            env.HOME = "/data/jenkins"
        } else {
            echo "Unknown AIX version: ${aixVersion}. Please set HOME path accordingly."
        }
    } else if ( detectedOS == "sunos" ){
      env.HOME = "${env.WORKSPACE}"
    }
    else {
        echo "Running on different OS. Need to set the HOME path properly!"
    }

       def buildStartEpoch = sh(
        script: "command -v perl >/dev/null 2>&1 && perl -e 'print time' || date +%s",
        returnStdout: true
       ).trim()

    writeFile file: 'edit_build.sh', text: '''#!/usr/bin/env bash
        set -eu
        IFS=$'\\n\\t'

        ARTDIR="/tmp/$1"
        OS="$2"
        SCRIPT_PATH="./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh"

        echo "[INFO] Editing build script for OS: $OS, Artifact dir: $ARTDIR"
        echo "[INFO] Target script path: $SCRIPT_PATH"

        mkdir -p "$ARTDIR"
        touch "$ARTDIR/artifact"

        awk -v ARTDIR="$ARTDIR" '
        $0 ~ /TGZPATH="\\$TGZDIR\\/\\$TGZFILE.tgz"/ {
            print;
            print "        echo \\"[DEBUG] TGZPATH is: \\$TGZPATH\\"";
            print "        echo \\"$(date +%s) \\$TGZPATH\\" >> \\"" ARTDIR "/artifact\\"";
            next
        }
        { print }
        ' "$SCRIPT_PATH" > "$SCRIPT_PATH.tmp" && mv "$SCRIPT_PATH.tmp" "$SCRIPT_PATH"

        echo "DEBUG: Showing contents of artifact file:"
        cat "$ARTDIR/artifact"
        '''
    
    withCredentials([
        usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
    ]) {
        try {
            def detectOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
            def shellScript = ""

            if (detectOS == "linux") {
                def kernelVersion = sh(script: "uname -r", returnStdout: true).trim()

                shellScript += """
                    echo "Skipping Proxy details"
                    export USERID=$JENKINS_USER
                    export USERACCESS=$JENKINS_PASSWORD
                    export SCRIPT_DIR=\$(pwd)/gitroot/ist-build-tools/autobase/scripts
                    export PATH=\$SCRIPT_DIR:\$PATH
                """

                if (kernelVersion.startsWith("5.14")) {
                    def selectedOracleHome = "/Osrc8/oracle/lin64_ora_199"

                    shellScript += """
                        echo "Detected RHEL 9"
                        echo "Using Oracle Home for SDK check: ${selectedOracleHome}"
                        if [ -f "${selectedOracleHome}/sdk/include/oci.h" ]; then
                            export CPPFLAGS="-I${selectedOracleHome}/sdk/include"
                        else
                            echo "ERROR: oci.h not found in ${selectedOracleHome}/sdk/include"
                            exit 1
                        fi
                    """
                } else {
                    shellScript += """
                        echo "Detected RHEL 8"
                    """
                }

                shellScript += """
                    mkdir -p /tmp/${params.artFile}
                    bash edit_build.sh "${params.artFile}" "${detectOS}"
                    mkdir -p \$(pwd)/rel_info
                    touch \$(pwd)/rel_info/baseline_mapping.list
                    echo -e "${params.oracle_home}" > export:ORACLE_HOME
                    echo "${params.java_home}" > export:JAVA_HOME

                    ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload ${Build_Params} 2>&1 | tee output.log
                    echo \$? > ./script_result.txt

                    if grep -q "ERROR: fail in " output.log; then
                        echo "Error found in the log. Marking build as FAILURE."
                        exit 1
                    else
                        echo "No errors found in the log."
                    fi
                """
            } else if (detectOS == "aix") {
                def AIXVersion = sh(script: "oslevel", returnStdout: true).trim()
                echo "Detected AIX version: ${AIXVersion}"

                if (AIXVersion.startsWith("7.3")) {
                    shellScript += """
                        echo "Detected AIX version: ${AIXVersion}"
                        export http_proxy=http://10.236.163.21:8080/
                        export https_proxy=http://10.236.163.21:8080/
                        export no_proxy=.fidev.local,.fnis.com
                    """
                }

                shellScript += """
                    export USERID=$JENKINS_USER
                    export USERACCESS=$JENKINS_PASSWORD
                    mkdir -p /tmp/${params.artFile}
                    bash edit_build.sh "${params.artFile}" "${detectOS}"
                    mkdir -p \$(pwd)/rel_info
                    touch \$(pwd)/rel_info/baseline_mapping.list
                    echo "${params.oracle_home}" > export:ORACLE_HOME
                    echo "${params.java_home}" > export:JAVA_HOME
                    ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload ${Build_Params} 2>&1 | tee output.log
                    echo \$? > ./script_result.txt

                    if grep -q "ERROR: fail in " output.log; then
                        echo "Error found in the log. Marking build as FAILURE."
                        exit 1
                    else
                        echo "No errors found in the log."
                    fi
                """

                if (AIXVersion.startsWith("7.2")) {
                    shellScript += """
                        echo "Detected AIX version: ${AIXVersion}"
                        export USERID=$JENKINS_USER
                        export USERACCESS=$JENKINS_PASSWORD
                        mkdir -p /tmp/${params.artFile}
                        bash edit_build.sh "${params.artFile}" "${detectOS}"
                        mkdir -p \$(pwd)/rel_info
                        touch \$(pwd)/rel_info/baseline_mapping.list
                        echo "${params.oracle_home}" > export:ORACLE_HOME
                        echo "${params.java_home}" > export:JAVA_HOME
                        ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload -e=ist_metrics_util ${Build_Params} 2>&1 | tee output.log
                        echo \$? > ./script_result.txt

                        if grep -q "ERROR: fail in " output.log; then
                            echo "Error found in the log. Marking build as FAILURE."
                            exit 1
                        else
                            echo "No errors found in the log."
                        fi
                    """
                }
            } else if (detectOS == "sunos") {
                def sunOSVersion = sh(script: "oslevel", returnStdout: true).trim()
                echo "Detected SUNOS version: ${sunOSVersion}"

                shellScript += """
                    export USERID=$JENKINS_USER
                    export USERACCESS=$JENKINS_PASSWORD
                    mkdir -p /tmp/${params.artFile}
                    bash edit_build.sh "${params.artFile}" "${detectOS}"
                    mkdir -p \$(pwd)/rel_info
                    touch \$(pwd)/rel_info/baseline_mapping.list
                    echo "${params.oracle_home}" > export:ORACLE_HOME
                    echo "${params.java_home}" > export:JAVA_HOME
                    ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload ${Build_Params} 2>&1 | tee output.log
                    echo \$? > ./script_result.txt

                    if grep -q "ERROR: fail in " output.log; then
                        echo "Error found in the log. Marking build as FAILURE."
                        exit 1
                    else
                        echo "No errors found in the log."
                    fi
                """
            }

            sh shellScript
        } catch (Exception e) {
            echo "Error during build: ${e.message}"
            currentBuild.result = 'FAILURE'
            error("Build failed due to error in log.")
        }
    }

	def Build_Script_Status = sh(script: "cat ./script_result.txt", returnStdout: true).toInteger()
          def Artgen = 0

          def allArtifacts = sh(script: "find ${env.HOME}/tgz -type f -name '*.tgz'", returnStdout: true)
              .trim().split('\n').findAll { it }

          def freshlyBuiltArtifacts = allArtifacts.findAll { path ->
              try {
                  def modTimeRaw = sh(script: "perl -e 'print((stat(\"${path}\"))[9])'", returnStdout: true).trim()
                  def modTime = modTimeRaw.isNumber() ? modTimeRaw.toLong() : 0L
                  def isFresh = modTime >= buildStartEpoch.toLong()
                  if (!isFresh) println "Skipping old artifact: ${path}"
                  return isFresh
              } catch (Exception e) {
                  println "Warning: Could not determine mod time for ${path}: ${e.message}"
                  return false
              }
          }

          def releaseLines = readFile(params.releasefile)
              .replaceAll('\r\n|\r|\n', '\n')
              .split('\n')
              .collect { it.trim() }

          def forceIndexes = releaseLines.findIndexValues { it.equalsIgnoreCase("FORCE=1") }
          def forceIndex = forceIndexes ? forceIndexes.last() : -1

          def relevantLines = []
          def forceMode = false
          def releaseMode = false

          if (forceIndex >= 0 && forceIndex < releaseLines.size() - 1) {
              relevantLines = releaseLines[(forceIndex + 1)..<releaseLines.size()]
                  .findAll { it && !it.toUpperCase().startsWith("BUILDOPT") }
              forceMode = true
          } else if (params.build_Flags?.toLowerCase()?.contains("-bt=release")) {
              println "FORCE=1 not found, but build_Flags indicates release build. Collecting all components."
              relevantLines = releaseLines.findAll { it && !it.toUpperCase().startsWith("BUILDOPT") }
              releaseMode = true
          } else {
              println "FORCE=1 not found and build_Flags is not release. Skipping artifact collection."
          }

          def expectedDbTypes = ["DB", "ORA", "PGSQL"]
          def oracleHomeRaw = sh(script: 'echo $ORACLE_HOME', returnStdout: true).trim()
          oracleHomeRaw.split('\n').each { line ->
              def matcher = line.toUpperCase() =~ /ORA[_-]?(\d{4}|(?:\d+\.\d+)|(?:19C))/
              if (matcher.find()) expectedDbTypes += "ORA-${matcher.group(1)}"
          }
          if (!expectedDbTypes.contains("ORA") && oracleHomeRaw.toLowerCase().contains("oracle")) expectedDbTypes += "ORA"

          def pgsqlHomeRaw = sh(script: 'echo $PGSQL_HOME', returnStdout: true).trim()
          if (pgsqlHomeRaw && pgsqlHomeRaw.toLowerCase().contains("pgsql")) expectedDbTypes += "PGSQL"
          expectedDbTypes = expectedDbTypes.unique()

          def extractTokens = { line ->
              def raw = line.contains('/') ? line.tokenize('/').last() : (line.contains(':') ? line.tokenize(':').last() : line)
              raw = raw.replaceAll(/[^A-Za-z0-9_.]+$/, '')
              def tokens = raw.toUpperCase().split('_').findAll { it }
              def ignorePatterns = [/^OS$/, /^LIN/, /^AIX/, /^SOLARIS/, /^HPUX/, /^I\\d+$/, /^X86_64$/, /^RHEL/, /^ARM/]
              tokens.findAll { token -> !ignorePatterns.any { pattern -> token ==~ pattern } }
          }

          def dbLines = relevantLines.findAll { it.toUpperCase().contains("_DB") }
          def nonDbLines = relevantLines.findAll { !dbLines.contains(it) }

          def dbPartLists = dbLines.collectMany { dbLine ->
              def parts = extractTokens(dbLine)
              def dbIndex = parts.findIndexOf { it == "DB" }
              if (dbIndex >= 0) {
                  expectedDbTypes.collect { dbType ->
                      def newParts = parts.collect()
                      newParts[dbIndex] = dbType
                      newParts
                  }
              } else [parts]
          }
          def nonDbPartLists = nonDbLines.collect { extractTokens(it) }

          def dbArtifacts = []
          def nonDbArtifacts = []
          def matchedArtifacts = []

          if (forceMode || releaseMode) {
              if (forceMode) {
                  dbArtifacts = dbPartLists ? freshlyBuiltArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      dbPartLists.any { parts -> parts.every { part -> upperPath.contains(part) } }
                  } : []

                  nonDbArtifacts = freshlyBuiltArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      nonDbPartLists.any { parts ->
                          def keyParts = parts
                          def component = keyParts ? keyParts[0] : ""
                          keyParts.take(2).every { part -> upperPath.contains(part) } && upperPath.contains(component)
                      }
                  }.findAll { !(dbArtifacts.contains(it)) }

                  matchedArtifacts = (dbArtifacts + nonDbArtifacts).unique()
              } else if (releaseMode) {
                  def allPartLists = relevantLines.collect { extractTokens(it) }
                  matchedArtifacts = freshlyBuiltArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      allPartLists.any { parts ->
                          def keyParts = parts
                          def component = keyParts ? keyParts[0] : ""
                          keyParts.take(2).every { part -> upperPath.contains(part) } && upperPath.contains(component)
                      }
                  }

                  dbArtifacts = dbPartLists ? matchedArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      dbPartLists.any { parts -> parts.every { part -> upperPath.contains(part) } }
                  } : []

                  nonDbArtifacts = matchedArtifacts.findAll { !(dbArtifacts.contains(it)) }
              }
          }

          println "========== ARTIFACT CLASSIFICATION =========="
          println "DB Artifact (${dbArtifacts.size()}):"
          dbArtifacts.each { println "  DB: ${it}" }

          println "Non-DB Artifacts (${nonDbArtifacts.size()}):"
          nonDbArtifacts.each { println "  Non-DB: ${it}" }

          println "========== BUILD SUMMARY =========="
          println "FORCE=1 used in release file: ${forceMode ? 'YES' : 'NO'}"
          println "Release mode: ${releaseMode ? 'YES' : 'NO'}"
          println "Expected component suffixes: ${forceMode ? (dbPartLists.size() + nonDbPartLists.size()) : relevantLines.size()}"
          println "Freshly built .tgz files detected: ${freshlyBuiltArtifacts.size()}"
          println "Matched artifacts: ${matchedArtifacts.size()}"
          println "==================================="

          if (Build_Script_Status != 0) {
              currentBuild.result = "FAILURE"
          }

          def allExist = matchedArtifacts.every { path ->
              sh(script: "[ -f '${path}' ] && echo 'true' || echo 'false'", returnStdout: true).trim() == 'true'
          }

          if (matchedArtifacts && allExist) {
              println "Artifacts Built Successfully: ${matchedArtifacts.join(', ')}"
              Artgen = 1
          } else {
              if (params.build_Flags?.contains("notgz")) {
                  println "No artifact generated."
                  Artgen = 0
              } else {
                  currentBuild.result = "SUCCESS"
                  Artgen = 0
                  println "Some or all artifacts not found. Check the build logs."
              }
          }

          return (Artgen == 0) ? "NoArtifact" : matchedArtifacts.join(',')

}

def env_linux() {
    String kernelVersion = sh(script: "uname -r", returnStdout: true).trim()

    if (kernelVersion.startsWith("5.14")) {
        env.LD_LIBRARY_PATH = "${ORACLE_HOME}/lib:/Osrc8/local/bin/_LINUX2.6_i386/bin:/usr/lib64:/usr/lib"
         env.PATH = "/share/istprod_india/e1014306/bin/RHEL9:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:.:/Osrc8/tools/bin:/Osrc8/oracle/lin64_ora_199:/Osrc8/local/bin/_LINUX2.6_i386/bin:/usr/bin/git:/usr/bin/curl:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home3/istrcc/snmp_bin"
        println "env_linux(): RHEL 9 detected, kernel ${kernelVersion}"
    } else {
        env.LD_LIBRARY_PATH = "${ORACLE_HOME}/lib:/Osrc8/oracle/lin64_ora_19C:/Osrc8/oracle/lin64_ora_19C/bin:/Osrc8/local/bin/_LINUX2.6_i386_13/lib:/usr/lib64:/usr/lib"
        env.CPPFLAGS = "-I${ORACLE_HOME}/include"
        env.PATH = "/Osrc8/local/bin/_LINUX2.6_i386_13/bin:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/Osrc/tools/bin:/Osrc/oracle/lin64_ora_199:$JAVA_HOME:$CLASSPATH:/usr/share/bcc/tools:/usr/local/lib64:/usr/lib64:/usr/lib:$PATH"
        println "env_linux(): RHEL 8 or other detected, kernel ${kernelVersion}"
    }
}

def env_aix() {

    String AIXVersion = sh(script: "oslevel", returnStdout: true).trim()
    println "env_aix(): Detected AIX version: ${AIXVersion}"

    if (AIXVersion.startsWith("7.3")) {
        env.PATH = "/opt/IBM/openxlC/17.1.2/bin:/usr/java8_64/bin:/usr/boksm/bin:/opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10:${env.PATH}:/opt/IBM/xlC/13.1.2/bin"
        env.ORACLE_HOME = "/fitools/u01/app/oracle/product/19.3"
        env.JAVA_HOME = '/opt/jdk-17.0.12+7'
        env.HOME = "/home3/istrcc-jenkins"
        env.LD_LIBRARY_PATH = '.:/fitools/u01/app/oracle/product/19.3:/fitools/u01/app/oracle/product/19.3/bin:/home3/Osrc/local/bin/_AIX4.2_risc6000/bin/lib:/usr/lib64:/usr/lib:/opt/IBM/xlc/13.1.3/bin'

    } else if (AIXVersion.startsWith("7.2")) {
        env.PATH = "/jenkins/jenkins-workspace:${env.PATH}:/opt/IBM/xlC/13.1.2/bin"
        env.ORACLE_HOME = '/Osrc/oracle/aix64_ora_1911'
        env.JAVA_HOME = '/usr/java8_64/bin'
        env.HOME = "/data/jenkins"
    } else {
        println "env_aix(): Unknown AIX version, using default HOME"
        env.HOME = "/home/jenkins"
    }

    println "env_aix(): PATH set to: ${env.PATH}"
    println "env_aix(): CUSTOM_HOME set to: ${env.HOME}"
}

def env_solaris() {
    env.ORACLE_HOME = params.oracle_home
    env.JAVA_HOME = params.java_home
    env.LD_LIBRARY_PATH = '/lib:/lib:/lib:/home3/istrcc/snmp_lib'
}

def env_hpux() {
    env.ORACLE_HOME = '/Osrc8/oracle/lin64_ora_19C'
    env.JAVA_HOME = '/usr/lib/jvm/java-1.8.0-openjdk'
    env.LD_LIBRARY_PATH = '.:/usr/lib64:/usr/lib'
}

-----------------------------------------------occcppbuild.groovy-------------------------------------

package fi.ist
import java.util.regex.Matcher

def artifactUploadZip(Map params = [:]) {
    def artifactPath = params.artifactPath
    def buildType = params.buildType
    def repoUrl = params.repoUrl
    def subPath = params.subPath

    echo "Params: ${params}"
    echo "Artifact Path: ${artifactPath}"
    echo "Build Type: ${buildType}"
    echo "Repo URL: ${repoUrl}"
    echo "Artifactory: ${params.artifactory}"

    def artifactName = artifactPath.tokenize('/').last()
    def repositoryPath = buildType == 'release' ? params.artifactory.REPO.release : params.artifactory.REPO.development
    def uploadUrlPath = "${repoUrl}/${repositoryPath}/${subPath}/${artifactName}"

    def credentialsId = buildType == 'release' ? 'svcacct_istartifact' : 'svcacct_istartifact'

    echo "[artifactUpload] Preparing upload for artifact: ${artifactName}"
    echo "[artifactUpload] Target URL: ${uploadUrlPath}"

    withCredentials([
        usernamePassword(credentialsId: credentialsId, usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
    ]) {
        echo "[artifactUpload] Uploading artifact..."
        sh "curl -u ${JENKINS_USER}:${JENKINS_PASSWORD} -T ${artifactPath} ${uploadUrlPath} --fail"
        echo "[artifactUpload] Upload successful!"
    }
}

def artifactUploadTgz(Map params = [:]) {
    def artifactPath = params.artifactPath
    def buildType = params.buildType
    def repoUrl = params.repoUrl
    def subPath = params.subPath

    echo "Params: ${params}"
    echo "Artifact Path: ${artifactPath}"
    echo "Build Type: ${buildType}"
    echo "Repo URL: ${repoUrl}"
    echo "Artifactory: ${params.artifactory}"

    def artifactName = artifactPath.tokenize('/').last()
    def repositoryPath = buildType == 'release' ? params.artifactory.REPO.release : params.artifactory.REPO.development
    def uploadUrlPath = "${repoUrl}/${repositoryPath}/${subPath}/${artifactName}"

    def credentialsId = buildType == 'release' ? 'svcacct_istartifact' : 'svcacct_istartifact'

    echo "[artifactUpload] Preparing upload for artifact: ${artifactName}"
    echo "[artifactUpload] Target URL: ${uploadUrlPath}"

    withCredentials([
        usernamePassword(credentialsId: credentialsId, usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
    ]) {
        echo "[artifactUpload] Uploading artifact..."
        sh "curl -u ${JENKINS_USER}:${JENKINS_PASSWORD} -T ${artifactPath} ${uploadUrlPath} --fail"
        echo "[artifactUpload] Upload successful!"
    }
}

def downloaddependency(Map params = [:]) {
    def Project_repo = params.project_repo.split(',')
    def GitCreds = params.gitCreds

    withCredentials([usernamePassword(credentialsId: GitCreds, usernameVariable: 'GIT_USERNAME', passwordVariable: 'GIT_PASSWORD')]) {
        for (int i = 0; i < Project_repo.size(); i++) {
            def str_branch = Project_repo[i].split(':')
            if (str_branch.size() < 2 || !str_branch[1]) {
                error "Invalid repo format or missing branch name for entry: ${Project_repo[i]}"
            }

            def str = str_branch[0].split('/')
            echo "Cloning repo: ${str_branch[0]} on branch: ${str_branch[1]}"
            sh "git clone --depth 1 --branch ${str_branch[1]} https://${GIT_USERNAME}:${GIT_PASSWORD}@bitbucket.fi.dev/scm/${str_branch[0]}.git"
        }
    }
}

def checkErrorInLog() {
    try {
        def logContent = currentBuild.rawBuild.getLog(10000).join('\n') // Increased log size
        echo "Checking log content for errors..."
        if (logContent.contains("ERROR: fail")) {
            echo "Error found in the log. Marking build as FAILURE."
            currentBuild.result = 'FAILURE'
            error("Failing the build due to error in log.")
        } else {
            echo "No errors found in the log."
        }
    } catch (Exception e) {
        echo "An error occurred: ${e.message}"
        currentBuild.result = 'FAILURE'
        error("An exception occurred while checking the log. Failing the build.")
    }
}

def updateOsNamePerlScript() {
    def overrideLogic = '''# Allow override via environment variable
    if (exists $ENV{'FORCE_OS_NAME'} && $ENV{'FORCE_OS_NAME'} ne '') {
        print "$ENV{'FORCE_OS_NAME'}\\n";
        exit 0;
    }
    '''

    def osNamePath = 'gitroot/ist-build-tools/autobase/scripts/os_name.pl'
    def fileExists = fileExists(osNamePath)

    if (!fileExists) {
        echo "[WARN] os_name.pl not found at ${osNamePath}. Creating fallback version."

        def fallbackContent = '''#!/usr/bin/perl
        use strict;
        use warnings;

        if (exists $ENV{'FORCE_OS_NAME'} && $ENV{'FORCE_OS_NAME'} ne '') {
            print "$ENV{'FORCE_OS_NAME'}\\n";
            exit 0;
        }

        # Default fallback
        print "LIN-5140-x86_64\\n";
        '''

        writeFile file: osNamePath, text: fallbackContent
        echo "Fallback os_name.pl created with FORCE_OS_NAME support."
    } else {
        try {
            def originalContent = readFile(file: osNamePath)
            echo "Successfully read os_name.pl"

            if (!originalContent.contains('FORCE_OS_NAME')) {
                def updatedContent = originalContent.replaceFirst(
                    /use strict;/,
                    Matcher.quoteReplacement("use strict;\n\n${overrideLogic}")
                )
                writeFile file: osNamePath, text: updatedContent
                echo "Patched os_name.pl to support FORCE_OS_NAME override."
            } else {
                echo "os_name.pl already supports FORCE_OS_NAME override. No changes made."
            }

           /* def debugContent = readFile(file: osNamePath)
            echo "DEBUG: Contents of patched os_name.pl:\n${debugContent}" */
        } catch (Exception e) {
            echo "ERROR: Could not read or patch os_name.pl - ${e.getMessage()}"
            error("Build failed due to os_name.pl patching error.")
        }
    }

    try {
        def osNameOutput = sh(script: "perl ${osNamePath}", returnStdout: true).trim()
        echo "Validation: os_name.pl returned: ${osNameOutput}"

        if (osNameOutput != env.FORCE_OS_NAME) {
            error("Validation failed: os_name.pl output '${osNameOutput}' does not match expected FORCE_OS_NAME '${env.FORCE_OS_NAME}'")
        } else {
            echo "Validation successful: os_name.pl output matches FORCE_OS_NAME"
        }
    } catch (Exception e) {
        echo "ERROR: Failed to validate os_name.pl - ${e.getMessage()}"
        error("Stopping build due to os_name.pl validation failure.")
    }
}

def build(Map params = [:]) {
   	println "Building...."
	String Build_Params

	println "${params.artFile}"
	println "Branch Type: ${params.branch_Type}"
	echo "Oracle home:${params.oracle_home}"

	if (!params.releasefile) {
		println "No Release file passed"
		Build_Params = "${params.build_Flags} ./Jenkins/branch-build.list"
	} else {
		println "Release file: ${params.releasefile}"
		Build_Params = "${params.build_Flags} ${params.releasefile}"
	}

	String detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
	env.HOME = "/data/jenkins"

	/*def selectedOs = env.OS_NAME ?: ""
	def supportedOsMap = [
		"RHEL8OCP": "4180",
		"RHEL9OCP": "5140"
	]

	def version = supportedOsMap.find { selectedOs.contains(it.key) }?.value

	def rawArch = sh(script: 'uname -m', returnStdout: true).trim()
	def arch = (rawArch == 'x86_64') ? 'i686' :
			   ["i386", "i686"].contains(rawArch) ? 'i686' : rawArch

	def prefix = "LIN"
	env.FORCE_OS_NAME = version ? "${prefix}-${version}-${arch}" : "LIN-5140-${arch}"
	echo "Resolved FORCE_OS_NAME: ${env.FORCE_OS_NAME}"*/
  
   
    def selectedOsName = params.selectedOsName ?: "RHEL8OCP"
    env.OS_NAME = selectedOsName
    echo "env.OS_NAME set from selectedOsName: ${env.OS_NAME}"

    echo "env.OS_NAME: ${env.OS_NAME}"
    echo "selectedOs: ${selectedOsName}"

    def supportedOsMap = [
        "RHEL8OCP": "4180",
        "RHEL9OCP": "5140"
    ]

    def version = supportedOsMap.find { selectedOsName.contains(it.key) }?.value
    echo "Matched version: ${version}"

    def rawArch = sh(script: 'uname -m', returnStdout: true).trim()
    def arch = (rawArch == 'x86_64') ? 'i686' :
               ["i386", "i686"].contains(rawArch) ? 'i686' : rawArch

    def prefix = "LIN"
    env.FORCE_OS_NAME = version ? "${prefix}-${version}-${arch}" : "LIN-5140-${arch}"
    echo "Resolved FORCE_OS_NAME: ${env.FORCE_OS_NAME}"

	updateOsNamePerlScript()

	 def buildStartEpoch = sh(
        script: "command -v perl >/dev/null 2>&1 && perl -e 'print time' || date +%s",
        returnStdout: true
       ).trim()

	writeFile file: 'edit_build.sh', text: '''#!/usr/bin/env bash
	set -eu
	IFS=$'\\n\\t'

	ARTDIR="/tmp/$1"
	OS="$2"
	SCRIPT_PATH="./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh"

	echo "[INFO] Editing build script for OS: $OS, Artifact dir: $ARTDIR"
	echo "[INFO] Target script path: $SCRIPT_PATH"

	mkdir -p "$ARTDIR"
	touch "$ARTDIR/artifact"

	if [[ -n "${KUBERNETES_SERVICE_HOST:-}" || -d "/var/run/secrets/kubernetes.io" ]]; then
		echo "[INFO] Detected Kubernetes environment. Ensuring /data/jenkins exists..."
		mkdir -p /data/jenkins || echo "[WARN] Could not create /data/jenkins. Check volume mount."
	else
		echo "[INFO] Non-Kubernetes environment detected. Skipping /data setup."
	fi

	timestamp=$(date +%s)

	awk -v ARTDIR="$ARTDIR" -v TS="$timestamp" '
	$0 ~ /TGZPATH="\\$TGZDIR\\/\\$TGZFILE\\.tgz"/ {
		print;
		print "        echo \\"[DEBUG] TGZPATH is: \\$TGZPATH\\"";
		print "        echo \\"" TS " \\$TGZPATH\\" >> \\"" ARTDIR "/artifact\\"";
		next
	}
	{ print }
	' "$SCRIPT_PATH" > "$SCRIPT_PATH.tmp" && mv "$SCRIPT_PATH.tmp" "$SCRIPT_PATH"

	echo "DEBUG: Showing contents of artifact file:"
	cat "$ARTDIR/artifact"
	'''

	def runBuildSteps = {
		try {
			sh """
				export USERID=$JENKINS_USER
				export USERACCESS=$JENKINS_PASSWORD

				export SCRIPT_DIR=\$(pwd)/gitroot/ist-build-tools/autobase/scripts
				export PATH=\$SCRIPT_DIR:\$PATH
				export CPLUS_INCLUDE_PATH=/usr/include/oracle/19.3/client64:\$CPLUS_INCLUDE_PATH

				mkdir -p /tmp/${params.artFile}
				bash edit_build.sh "${params.artFile}" "${detectedOS}"

				mkdir -p \$(pwd)/rel_info
				touch \$(pwd)/rel_info/baseline_mapping.list

				echo -e "${params.oracle_home}" > export:ORACLE_HOME
				echo "${params.java_home}" > export:JAVA_HOME
				echo "/usr/lib64\nPGSQL" > export:PGSQL_HOME
				echo "17.2\nPGSQL-17.2" > export:PGSQLPATH

				echo "Printing ldd version:"
				ldd --version 

                ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload ${Build_Params} 2>&1 | tee output.log

				echo \$? > ./script_result.txt

				if grep -q "ERROR: fail in " output.log; then
					echo "Error found in the log. Marking build as FAILURE."
					exit 1
				else
					echo "No errors found in the log."
				fi
			"""
			archiveArtifacts artifacts: '*.buildlog', allowEmptyArchive: true
		} catch (Exception e) {
			echo "An error occurred: ${e.getMessage()}"
			currentBuild.result = 'FAILURE'
			throw e
		}
	}

    if (params.Build_Component == "rcc_build") {
        withCredentials([
            usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
        ]) {
            runBuildSteps()
        }
    } else {
        withCredentials([
            usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
        ]) {
            runBuildSteps()
        }
    }
  
  
      def Build_Script_Status = sh(script: "cat ./script_result.txt", returnStdout: true).toInteger()
      def Artgen = 0

      def allArtifacts = sh(script: "find ${env.HOME}/tgz -type f -name '*.tgz'", returnStdout: true)
          .trim().split('\n').findAll { it }

      def freshlyBuiltArtifacts = allArtifacts.findAll { path ->
          try {
              def modTimeRaw = sh(script: "perl -e 'print((stat(\"${path}\"))[9])'", returnStdout: true).trim()
              def modTime = modTimeRaw.isNumber() ? modTimeRaw.toLong() : 0L
              def isFresh = modTime >= buildStartEpoch.toLong()
              if (!isFresh) println "Skipping old artifact: ${path}"
              return isFresh
          } catch (Exception e) {
              println "Warning: Could not determine mod time for ${path}: ${e.message}"
              return false
          }
      }

      def releaseLines = readFile(params.releasefile)
          .replaceAll('\r\n|\r|\n', '\n')
          .split('\n')
          .collect { it.trim() }

      def forceIndexes = releaseLines.findIndexValues { it.equalsIgnoreCase("FORCE=1") }
      def forceIndex = forceIndexes ? forceIndexes.last() : -1

      def relevantLines = []
      def forceMode = false
      def releaseMode = false

      if (forceIndex >= 0 && forceIndex < releaseLines.size() - 1) {
          relevantLines = releaseLines[(forceIndex + 1)..<releaseLines.size()]
              .findAll { it && !it.toUpperCase().startsWith("BUILDOPT") }
          forceMode = true
      } else if (params.build_Flags?.toLowerCase()?.contains("-bt=release")) {
          println "FORCE=1 not found, but build_Flags indicates release build. Collecting all components."
          relevantLines = releaseLines.findAll { it && !it.toUpperCase().startsWith("BUILDOPT") }
          releaseMode = true
      } else {
          println "FORCE=1 not found and build_Flags is not release. Skipping artifact collection."
      }

  	  def expectedDbTypes = ["DB", "ORA", "PGSQL"]
      def oracleHomeRaw = sh(script: 'echo $ORACLE_HOME', returnStdout: true).trim()
      oracleHomeRaw.split('\n').each { line ->
          def matcher = line.toUpperCase() =~ /ORA[_-]?(\d{4}|(?:\d+\.\d+)|(?:19C))/
          if (matcher.find()) expectedDbTypes += "ORA-${matcher.group(1)}"
      }
      if (!expectedDbTypes.contains("ORA") && oracleHomeRaw.toLowerCase().contains("oracle")) expectedDbTypes += "ORA"

      def pgsqlHomeRaw = sh(script: 'echo $PGSQL_HOME', returnStdout: true).trim()
      if (pgsqlHomeRaw && pgsqlHomeRaw.toLowerCase().contains("pgsql")) expectedDbTypes += "PGSQL"
      expectedDbTypes = expectedDbTypes.unique()


      def extractTokens = { line ->
          def raw = line.contains('/') ? line.tokenize('/').last() : (line.contains(':') ? line.tokenize(':').last() : line)
          raw = raw.replaceAll(/[^A-Za-z0-9_.]+$/, '')
          def tokens = raw.toUpperCase().split('_').findAll { it }
          def ignorePatterns = [/^OS$/, /^LIN/, /^AIX/, /^SOLARIS/, /^HPUX/, /^I\\d+$/, /^X86_64$/, /^RHEL/, /^ARM/]
          tokens.findAll { token -> !ignorePatterns.any { pattern -> token ==~ pattern } }
      }

      def dbLines = relevantLines.findAll { it.toUpperCase().contains("_DB") }
      def nonDbLines = relevantLines.findAll { !dbLines.contains(it) }

      def dbPartLists = dbLines.collectMany { dbLine ->
          def parts = extractTokens(dbLine)
          def dbIndex = parts.findIndexOf { it == "DB" }
          if (dbIndex >= 0) {
              expectedDbTypes.collect { dbType ->
                  def newParts = parts.collect()
                  newParts[dbIndex] = dbType
                  newParts
              }
          } else [parts]
      }
      def nonDbPartLists = nonDbLines.collect { extractTokens(it) }

      def dbArtifacts = []
      def nonDbArtifacts = []
      def matchedArtifacts = []

      if (forceMode || releaseMode) {
          if (forceMode) {
              dbArtifacts = dbPartLists ? freshlyBuiltArtifacts.findAll { path ->
                  def upperPath = path.toUpperCase()
                  dbPartLists.any { parts -> parts.every { part -> upperPath.contains(part) } }
              } : []

              nonDbArtifacts = freshlyBuiltArtifacts.findAll { path ->
                  def upperPath = path.toUpperCase()
                  nonDbPartLists.any { parts ->
                      parts.every { part -> upperPath.contains(part) } // strict match for FORCE mode
                  }
              }.findAll { !(dbArtifacts.contains(it)) }

              matchedArtifacts = (dbArtifacts + nonDbArtifacts).unique()
          } else if (releaseMode) {
              def allPartLists = relevantLines.collect { extractTokens(it) }
              matchedArtifacts = freshlyBuiltArtifacts.findAll { path ->
                  def upperPath = path.toUpperCase()
                  allPartLists.any { parts ->
                      def keyParts = parts
                      def component = keyParts ? keyParts[0] : ""
                      keyParts.take(2).every { part -> upperPath.contains(part) } && upperPath.contains(component)
                  }
              }

              dbArtifacts = dbPartLists ? matchedArtifacts.findAll { path ->
                  def upperPath = path.toUpperCase()
                  dbPartLists.any { parts -> parts.every { part -> upperPath.contains(part) } }
              } : []

              nonDbArtifacts = matchedArtifacts.findAll { !(dbArtifacts.contains(it)) }
          }
      }

      println "========== ARTIFACT CLASSIFICATION =========="
      println "DB Artifact (${dbArtifacts.size()}):"
      dbArtifacts.each { println "  DB: ${it}" }

      println "Non-DB Artifacts (${nonDbArtifacts.size()}):"
      nonDbArtifacts.each { println "  Non-DB: ${it}" }

      println "========== BUILD SUMMARY =========="
      println "FORCE=1 used in release file: ${forceMode ? 'YES' : 'NO'}"
      println "Release mode: ${releaseMode ? 'YES' : 'NO'}"
      println "Expected component suffixes: ${forceMode ? (dbPartLists.size() + nonDbPartLists.size()) : relevantLines.size()}"
      println "Freshly built .tgz files detected: ${freshlyBuiltArtifacts.size()}"
      println "Matched artifacts: ${matchedArtifacts.size()}"
      println "==================================="

      if (Build_Script_Status != 0) {
          currentBuild.result = "FAILURE"
      }

      def allExist = matchedArtifacts.every { path ->
          sh(script: "[ -f '${path}' ] && echo 'true' || echo 'false'", returnStdout: true).trim() == 'true'
      }

      if (matchedArtifacts && allExist) {
          println "Artifacts Built Successfully: ${matchedArtifacts.join(', ')}"
          Artgen = 1
      } else {
          if (params.build_Flags?.contains("notgz")) {
              println "No artifact generated."
              Artgen = 0
          } else {
              currentBuild.result = "SUCCESS"
              Artgen = 0
              println "Some or all artifacts not found. Check the build logs."
          }
      }

      return (Artgen == 0) ? "NoArtifact" : matchedArtifacts.join(',')

}

def env_linux() {
    env.ORACLE_HOME = "${params.oracle_home}"
    env.JAVA_HOME = "${params.java_home}"
    // env.LD_LIBRARY_PATH = "${params.oracle_home}/lib:${params.java_home}/lib:/usr/lib64:/usr/lib:${env.LD_LIBRARY_PATH}"
    // env.PATH = "/usr/local/bin:/usr/bin:${env.PATH}:${env.WORKSPACE}/gitroot/ist-build-tools/autobase/scripts:/usr/lib64:/usr/lib"
}

def env_aix() {
   env.ORACLE_HOME = "${params.oracle_home}"
   env.JAVA_HOME = "${params.java_home}"
   env.LD_LIBRARY_PATH = '.:/Osrc/oracle/aix64_ora_1911:/Osrc/oracle/aix64_ora_1911/bin:/Osrc/local/bin/_LINUX2.6_i386_13/lib:/usr/lib64:/usr/lib:/opt/IBM/xlC/13.1.2/bin'
   env.PATH = "/jenkins/jenkins-workspace:${env.PATH}:/opt/IBM/xlC/13.1.2/bin"
}

def env_solaris() {
    env.ORACLE_HOME = '/Osrc8/oracle/lin64_ora_19C'
    env.JAVA_HOME = '/usr/lib/jvm/java-1.8.0-openjdk'
    env.LD_LIBRARY_PATH = '.:/usr/lib64:/usr/lib'
}

def env_hpux() {
    env.ORACLE_HOME = '/Osrc8/oracle/lin64_ora_19C'
    env.JAVA_HOME = '/usr/lib/jvm/java-1.8.0-openjdk'
    env.LD_LIBRARY_PATH = '.:/usr/lib64:/usr/lib'
}

-----------------------------------------------------------------cppbuild.groovy-------------------------------------------------
package fi.ist

def artifactUploadZip(Map params = [:]) {
    def artifactPath = params.artifactPath
    def buildType = params.buildType
    def repoUrl = params.repoUrl
    def subPath = params.subPath

    echo "Params: ${params}"
    echo "Artifact Path: ${artifactPath}"
    echo "Build Type: ${buildType}"
    echo "Repo URL: ${repoUrl}"
    echo "Artifactory: ${params.artifactory}"

    def artifactName = artifactPath.tokenize('/').last()
    def repositoryPath = buildType == 'release' ? params.artifactory.REPO.release : params.artifactory.REPO.development
    def uploadUrlPath = "${repoUrl}/${repositoryPath}/${subPath}/${artifactName}"

    def credentialsId = buildType == 'release' ? 'svcacct_istartifact' : 'svcacct_istartifact'

    // Detect OS and version
    def detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
    def AIXVersion = detectedOS == "aix" ? sh(script: "oslevel", returnStdout: true).trim() : ""
    def isAIX73 = (detectedOS == "aix" && AIXVersion.startsWith("7.3"))

    // Apply proxy settings for AIX 7.3
    if (isAIX73) {
        echo "Detected AIX 7.3 - applying proxy settings"
        sh """
          export http_proxy=http://10.236.163.21:8080/
          export https_proxy=http://10.236.163.21:8080/
          export no_proxy=.fidev.local,.fnis.com
        """
    }

    echo "[artifactUpload] Preparing upload for artifact: ${artifactName}"
    echo "[artifactUpload] Target URL: ${uploadUrlPath}"

    withCredentials([
        usernamePassword(credentialsId: credentialsId, usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
    ]) {
        echo "[artifactUpload] Uploading artifact..."

        def curlCommand = isAIX73 ? """
            curl --retry 5 \\
                 --retry-delay 5 \\
                 --retry-connrefused \\
                 --connect-timeout 10 \\
                 --max-time 120 \\
                 --fail \\
                 --location \\
                 -u ${JENKINS_USER}:${JENKINS_PASSWORD} \\
                 -T "${artifactPath}" \\
                 "${uploadUrlPath}"
        """ : """
            curl -u ${JENKINS_USER}:${JENKINS_PASSWORD} -T "${artifactPath}" "${uploadUrlPath}" --fail
        """

        def result = sh(script: curlCommand, returnStatus: true)

        if (result != 0) {
            error "[artifactUpload] Upload failed with exit code ${result}"
        } else {
            echo "[artifactUpload] Upload successful!"
        }
    }
}

def artifactUploadTgz(Map params = [:]) {
    def artifactPath = params.artifactPath
    def buildType = params.buildType
    def repoUrl = params.repoUrl
    def subPath = params.subPath

    echo "Params: ${params}"
    echo "Artifact Path: ${artifactPath}"
    echo "Build Type: ${buildType}"
    echo "Repo URL: ${repoUrl}"
    echo "Artifactory: ${params.artifactory}"

    def artifactName = artifactPath.tokenize('/').last()
    def repositoryPath = buildType == 'release' ? params.artifactory.REPO.release : params.artifactory.REPO.development
    def uploadUrlPath = "${repoUrl}/${repositoryPath}/${subPath}/${artifactName}"

    def credentialsId = buildType == 'release' ? 'svcacct_istartifact' : 'svcacct_istartifact'

    // Detect OS and version
    def detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
    def AIXVersion = detectedOS == "aix" ? sh(script: "oslevel", returnStdout: true).trim() : ""
    def isAIX73 = (detectedOS == "aix" && AIXVersion.startsWith("7.3"))

    echo "[artifactUpload] Preparing upload for artifact: ${artifactName}"
    echo "[artifactUpload] Target URL: ${uploadUrlPath}"

    withCredentials([
        usernamePassword(credentialsId: credentialsId, usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
    ]) {
        echo "[artifactUpload] Uploading artifact..."

        def curlCommand = isAIX73 ? """
            http_proxy=http://10.236.163.21:8080/ \\
            https_proxy=http://10.236.163.21:8080/ \\
            no_proxy=.fidev.local,.fnis.com \\
            curl --retry 5 \\
                 --retry-delay 5 \\
                 --retry-connrefused \\
                 --connect-timeout 10 \\
                 --max-time 120 \\
                 --fail \\
                 --location \\
                 -u ${JENKINS_USER}:${JENKINS_PASSWORD} \\
                 -T "${artifactPath}" \\
                 "${uploadUrlPath}"
        """ : """
            curl -u ${JENKINS_USER}:${JENKINS_PASSWORD} -T "${artifactPath}" "${uploadUrlPath}" --fail
        """

        echo "[artifactUpload] Curl command:\n${curlCommand}"

        def result = sh(script: curlCommand, returnStatus: true)

        if (result != 0) {
            error "[artifactUpload] Upload failed with exit code ${result}"
        } else {
            echo "[artifactUpload] Upload successful!"
        }
    }
}

def downloaddependency(Map params = [:]) {
    def Project_repo = params.project_repo.split(',')
    def GitCreds = params.gitCreds

    withCredentials([usernamePassword(credentialsId: GitCreds, usernameVariable: 'GIT_USERNAME', passwordVariable: 'GIT_PASSWORD')]) {
        sh 'git config --global http.postBuffer 524288000'

        for (int i = 0; i < Project_repo.size(); i++) {
            def str_branch = Project_repo[i].split(':')
            if (str_branch.size() < 2 || !str_branch[1]) {
                error "Invalid repo format or missing branch name for entry: ${Project_repo[i]}"
            }

            def repoPath = str_branch[0]
            def branch = str_branch[1]
            def repoName = repoPath.tokenize('/').last()

            echo "Cloning repo: ${repoPath} on branch: ${branch}"

            sh """
                if [ -d "${repoName}" ]; then
                    echo "Directory ${repoName} already exists. Skipping clone."
                else
                    git clone --depth 1 --branch ${branch} https://\$GIT_USERNAME:\$GIT_PASSWORD@bitbucket.fi.dev/scm/${repoPath}.git
                fi
            """
        }
    }
}


def patchCheckmarxBranchLogic() {
  sh '''
set -euo pipefail

SCRIPT_PATH="${WORKSPACE}/gitroot/ist-build-tools/autobase/scripts/build_checkmarx_jk.ksh"

PATCH_BLOCK='
# BEGIN: Checkmarx Branch Logic Patch
BRANCH="$brn"

if [[ "$brn" == *":"* ]]; then
    src_branch="${brn%%:*}"
    target_branch="${brn##*:}"
else
    src_branch="$brn"
    target_branch=""
fi

updated_brn_name="${src_branch##*/}"
echo "DEBUG: src_branch=$src_branch, target_branch=$target_branch, brn=$brn, updated_brn_name=$updated_brn_name"

if [[ "$ver" == segment:* || "$ver" == sw_segment:* ]]; then
    if [[ -n "$target_branch" ]]; then
        BRANCH="$target_branch"
    elif [[ -n "$brn" ]]; then
        BRANCH="$brn"
    elif [[ "$BUILD_TYPE" == "develop" ]]; then
        BRANCH="master"
    else
        BRANCH="release/$updated_brn_name"
    fi
else
    if [[ "$BUILD_TYPE" == "release" || "$src_branch" == release/* ]]; then
        BRANCH="release/$updated_brn_name"
    elif [[ "$BUILD_TYPE" == "develop" ]]; then
        if [[ "$src_branch" == feature/* || "$src_branch" == hotfix/* || "$src_branch" == bugfix/* ]]; then
            BRANCH="$src_branch"
        else
            BRANCH="develop/$updated_brn_name"
        fi
    else
        echo "ERROR: Unknown BUILD_TYPE '\''$BUILD_TYPE'\''"
        exit 1
    fi
fi

BRANCH="${BRANCH%/}"
echo "DEBUG: Final BRANCH=$BRANCH"
# END: Checkmarx Branch Logic Patch
'

if grep -q "^# BEGIN: Checkmarx Branch Logic Patch$" "$SCRIPT_PATH"; then
  echo "[PATCH] Already applied‚Äîskipping."
  exit 0
fi

start_line="$(awk '
  $0 ~ /^[[:space:]]*BRANCH[[:space:]]*=[[:space:]]*"\\$brn"[[:space:]]*($|#)/ { print NR; exit }
' "$SCRIPT_PATH")"

if [ -z "${start_line:-}" ]; then
  echo "[PATCH][ERROR] Could not locate BRANCH=\"\\$brn\" in: $SCRIPT_PATH"
  exit 1
fi

end_line="$(awk -v s="$start_line" '
  NR > s {
    if ($0 ~ /^[[:space:]]*if([[:space:]]|\\[)/) { depth++; seen=1 }
    if ($0 ~ /^[[:space:]]*fi[[:space:]]*$/) {
      if (depth>0) depth--;
      if (seen && depth==0) { print NR; exit }
    }
  }
' "$SCRIPT_PATH")"

if [ -z "${end_line:-}" ]; then
  echo "[PATCH][ERROR] Could not determine end of mini-block."
  exit 1
fi

tmp="$(mktemp)"
awk -v s="$start_line" -v e="$end_line" -v block="$PATCH_BLOCK" '
  NR==s { printf "%s\\n", block; next }
  NR > s && NR <= e { next }
  { print }
' "$SCRIPT_PATH" > "$tmp"

mv --force "$tmp" "$SCRIPT_PATH"

if ! grep -q "^# BEGIN: Checkmarx Branch Logic Patch$" "$SCRIPT_PATH"; then
  echo "[PATCH][ERROR] BEGIN marker not found after apply."
  exit 1
fi
if ! grep -q "^# END: Checkmarx Branch Logic Patch$" "$SCRIPT_PATH"; then
  echo "[PATCH][ERROR] END marker not found after apply."
  exit 1
fi

if ! grep -Eq 'updated_brn_?name[[:space:]]*=[[:space:]]*["'\'' ]*\\$\\{?src_branch##\\*/\\}?["'\'' ]*' "$SCRIPT_PATH"; then
  echo "[PATCH][ERROR] New BRANCH logic signature not found after apply."
  exit 1
fi

count="$(grep -c '^# BEGIN: Checkmarx Branch Logic Patch$' "$SCRIPT_PATH" || true)"
if [ "${count:-0}" -ne 1 ]; then
  echo "[PATCH][ERROR] Unexpected number of BEGIN markers (${count}); expected exactly 1."
  exit 1
fi

echo "===== PATCH PREVIEW ====="
line="$(grep -n '^# BEGIN: Checkmarx Branch Logic Patch$' "$SCRIPT_PATH" | head -1 | cut -d: -f1 || true)"
if [ -n "${line:-}" ]; then
  nl -ba "$SCRIPT_PATH" | sed -n "$line,$((line+40))p"
fi
echo "===== END PATCH PREVIEW ====="

if command -v ksh >/dev/null 2>&1; then
  ksh -n "$SCRIPT_PATH" && echo "[PATCH] Syntax OK (ksh)."
elif command -v bash >/dev/null 2>&1; then
  bash -n "$SCRIPT_PATH" && echo "[PATCH] Syntax OK (bash)."
else
  sh -n "$SCRIPT_PATH" && echo "[PATCH] Syntax OK (sh)."
fi
'''
}

def build(Map params = [:]) {
    println "Building...."
   // Integer Artgen = 1
    String Build_Params
    println "${params.artFile}"
    println "Branch Type: ${params.branch_Type}"
    echo "Oracle home:${params.oracle_home}" 
    def buildMarker = params.buildMarker
    if (params.releasefile == null) {
        println "No Release file passed"
        Build_Params = "${params.build_Flags} ./branch-build.list"
    } else {
        println "Release file: ${params.releasefile}"
        Build_Params = "${params.build_Flags} ${params.releasefile}"
    }
  
    String detectedOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()

    if (detectedOS == "linux") {
        env.HOME = "${env.WORKSPACE}"
    } else if (detectedOS == "aix") {
        String aixVersion = sh(script: 'oslevel', returnStdout: true).trim()
        if (aixVersion.startsWith("7.3")) {
            env.HOME = "${env.WORKSPACE}"
        } else if (aixVersion.startsWith("7.2")) {
            env.HOME = "/data/jenkins"
        } else {
            echo "Unknown AIX version: ${aixVersion}. Please set HOME path accordingly."
        }
    } else {
        echo "Running on different OS. Need to set the HOME path properly!"
    }

    def buildStartEpoch = sh(
        script: "command -v perl >/dev/null 2>&1 && perl -e 'print time' || date +%s",
        returnStdout: true
    ).trim()

    writeFile file: 'edit_build.sh', text: '''#!/usr/bin/env bash
        set -eu
        IFS=$'\\n\\t'

        ARTDIR="/tmp/$1"
        OS="$2"
        SCRIPT_PATH="./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh"

        echo "[INFO] Editing build script for OS: $OS, Artifact dir: $ARTDIR"
        echo "[INFO] Target script path: $SCRIPT_PATH"

        mkdir -p "$ARTDIR"
        touch "$ARTDIR/artifact"

        awk -v ARTDIR="$ARTDIR" '
        $0 ~ /TGZPATH="\\$TGZDIR\\/\\$TGZFILE.tgz"/ {
            print;
            print "        echo \\"[DEBUG] TGZPATH is: \\$TGZPATH\\"";
            print "        echo \\"$(date +%s) \\$TGZPATH\\" >> \\"" ARTDIR "/artifact\\"";
            next
        }
        { print }
        ' "$SCRIPT_PATH" > "$SCRIPT_PATH.tmp" && mv "$SCRIPT_PATH.tmp" "$SCRIPT_PATH"

        echo "DEBUG: Showing contents of artifact file:"
        cat "$ARTDIR/artifact"
        '''
    
      withCredentials([
              usernamePassword(credentialsId: 'svcacct_istartifact', usernameVariable: 'JENKINS_USER', passwordVariable: 'JENKINS_PASSWORD')
          ]) {
              try {
                  def detectOS = sh(script: 'uname', returnStdout: true).trim().toLowerCase()
                  def shellScript = ""

                  if (detectOS == "linux") {
                      String kernelVersion = sh(script: "uname -r", returnStdout: true).trim()

                      if (kernelVersion.startsWith("5.14")) {
                          shellScript += """
                              echo "Detected RHEL 9"
                              export USERID=${JENKINS_USER}
                              export USERACCESS=${JENKINS_PASSWORD}

                              echo "Installing ICU development libraries and updated Bison..."
                              sudo dnf install -y libicu-devel bison || echo "dnf fallback failed"

                              export PATH="/Osrc8/local/bin/_LINUX2.6_i386/bin:/usr/bin:/usr/local/bin:\$PATH"
                              export ACLOCAL_PATH="/Osrc8/local/bin/_LINUX2.6_i386/share/aclocal"
                              export BISON="/usr/bin/bison"
                              export PERL="/usr/bin/perl"

                              echo "=== Bison Check ==="
                              echo "BISON env points to: \$BISON"
                              echo "Version from BISON: \$(\$BISON --version | head -n 1)"
                              echo "Version from PATH: \$(bison --version | head -n 1)"
                              echo "Binary resolved by PATH: \$(which bison)"
                              echo "Binary resolved by BISON: \$BISON"

                              echo "Using autoconf from: \$(which autoconf)"
                              echo "Using automake from: \$(which automake)"
                              echo "Using m4 from: \$(which m4)"
                              echo "Using Perl from: \$(which perl)"
                              perl -v

                              mkdir -p /tmp/${params.artFile}
                              bash edit_build.sh "${params.artFile}" "${detectOS}"

                              mkdir -p \$(pwd)/rel_info
                              touch \$(pwd)/rel_info/baseline_mapping.list

                              echo -e "${params.oracle_home}" > export:ORACLE_HOME
                              echo "${params.java_home}" > export:JAVA_HOME
                              echo -e "/usr/lib64\\nPGSQL" > export:PGSQL_HOME
                              echo -e "17.4\\nPGSQL-17.4" > export:PGSQLPATH

                              ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload ${Build_Params} 2>&1 | tee output.log

                              echo \$? > ./script_result.txt

                              if grep -q "ERROR: fail in " output.log; then
                                  echo "Error found in the log. Marking build as FAILURE."
                                  exit 1
                              else
                                  echo "No errors found in the log."
                              fi
                          """
                      } else {
                          shellScript += """
                              echo "Detected RHEL 8"
                              export USERID=${JENKINS_USER}
                              export USERACCESS=${JENKINS_PASSWORD}

                              export PATH="/Osrc8/local/bin/_LINUX2.6_i386_13/bin:/usr/bin:/usr/local/bin:\$PATH"
                              export BISON="/usr/bin/bison"

                              mkdir -p /tmp/${params.artFile}
                              bash edit_build.sh "${params.artFile}" "${detectOS}"

                              mkdir -p \$(pwd)/rel_info
                              touch \$(pwd)/rel_info/baseline_mapping.list

                              echo -e "${params.oracle_home}" > export:ORACLE_HOME
                              echo "${params.java_home}" > export:JAVA_HOME
                              echo -e "/usr/lib64\\nPGSQL" > export:PGSQL_HOME
                              echo -e "17.4\\nPGSQL-17.4" > export:PGSQLPATH

                              ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload ${Build_Params} 2>&1 | tee output.log

                              echo \$? > ./script_result.txt

                              if grep -q "ERROR: fail in " output.log; then
                                  echo "Error found in the log. Marking build as FAILURE."
                                  exit 1
                              else
                                  echo "No errors found in the log."
                              fi
                          """
                      }
                  } else if (detectOS == "aix") {
                      def AIXVersion = sh(script: "oslevel", returnStdout: true).trim()
                      echo "Detected AIX version: ${AIXVersion}"

                      if (AIXVersion.startsWith("7.3")) {
                          shellScript += """
                              export http_proxy=http://10.236.163.21:8080/
                              export https_proxy=http://10.236.163.21:8080/
                              export no_proxy=.fidev.local,.fnis.com
                          """
                      }

                      shellScript += """
                          export USERID=${JENKINS_USER}
                          export USERACCESS=${JENKINS_PASSWORD}

                          mkdir -p /tmp/${params.artFile}
                          bash edit_build.sh "${params.artFile}" "${detectOS}"
                          mkdir -p \$(pwd)/rel_info
                          touch \$(pwd)/rel_info/baseline_mapping.list

                          echo "${params.oracle_home}" > export:ORACLE_HOME
                          echo "${params.java_home}" > export:JAVA_HOME

                          ksh ./gitroot/ist-build-tools/autobase/scripts/build_release_bb.ksh -noupload ${Build_Params} 2>&1 | tee output.log

                          echo \$? > ./script_result.txt

                          if grep -q "ERROR: fail in " output.log; then
                              echo "Error found in the log. Marking build as FAILURE."
                              exit 1
                          else
                              echo "No errors found in the log."
                          fi
                      """
                  }

                  sh shellScript
              } catch (Exception e) {
                  echo "Error during build: ${e.message}"
                  currentBuild.result = 'FAILURE'
                  error("Build failed due to error in log.")
              }
          }
  
         
          def Build_Script_Status = sh(script: "cat ./script_result.txt", returnStdout: true).toInteger()
          def Artgen = 0

          def allArtifacts = sh(script: "find ${env.HOME}/tgz -type f -name '*.tgz'", returnStdout: true)
              .trim().split('\n').findAll { it }

          def freshlyBuiltArtifacts = allArtifacts.findAll { path ->
              try {
                  def modTimeRaw = sh(script: "perl -e 'print((stat(\"${path}\"))[9])'", returnStdout: true).trim()
                  def modTime = modTimeRaw.isNumber() ? modTimeRaw.toLong() : 0L
                  def isFresh = modTime >= buildStartEpoch.toLong()
                  if (!isFresh) println "Skipping old artifact: ${path}"
                  return isFresh
              } catch (Exception e) {
                  println "Warning: Could not determine mod time for ${path}: ${e.message}"
                  return false
              }
          }

          def releaseLines = readFile(params.releasefile)
              .replaceAll('\r\n|\r|\n', '\n')
              .split('\n')
              .collect { it.trim() }

          def forceIndexes = releaseLines.findIndexValues { it.equalsIgnoreCase("FORCE=1") }
          def forceIndex = forceIndexes ? forceIndexes.last() : -1

          def relevantLines = []
          def forceMode = false
          def releaseMode = false

          if (forceIndex >= 0 && forceIndex < releaseLines.size() - 1) {
              relevantLines = releaseLines[(forceIndex + 1)..<releaseLines.size()]
                  .findAll { it && !it.toUpperCase().startsWith("BUILDOPT") }
              forceMode = true
          } else if (params.build_Flags?.toLowerCase()?.contains("-bt=release")) {
              println "FORCE=1 not found, but build_Flags indicates release build. Collecting all components."
              relevantLines = releaseLines.findAll { it && !it.toUpperCase().startsWith("BUILDOPT") }
              releaseMode = true
          } else {
              println "FORCE=1 not found and build_Flags is not release. Skipping artifact collection."
          }

          def expectedDbTypes = ["DB", "ORA", "PGSQL"]
          def oracleHomeRaw = sh(script: 'echo $ORACLE_HOME', returnStdout: true).trim()
          oracleHomeRaw.split('\n').each { line ->
              def matcher = line.toUpperCase() =~ /ORA[_-]?(\d{4}|(?:\d+\.\d+)|(?:19C))/
              if (matcher.find()) expectedDbTypes += "ORA-${matcher.group(1)}"
          }
          if (!expectedDbTypes.contains("ORA") && oracleHomeRaw.toLowerCase().contains("oracle")) expectedDbTypes += "ORA"

          def pgsqlHomeRaw = sh(script: 'echo $PGSQL_HOME', returnStdout: true).trim()
          if (pgsqlHomeRaw && pgsqlHomeRaw.toLowerCase().contains("pgsql")) expectedDbTypes += "PGSQL"
          expectedDbTypes = expectedDbTypes.unique()

          def extractTokens = { line ->
              def raw = line.contains('/') ? line.tokenize('/').last() : (line.contains(':') ? line.tokenize(':').last() : line)
              raw = raw.replaceAll(/[^A-Za-z0-9_.]+$/, '')
              def tokens = raw.toUpperCase().split('_').findAll { it }
              def ignorePatterns = [/^OS$/, /^LIN/, /^AIX/, /^SOLARIS/, /^HPUX/, /^I\\d+$/, /^X86_64$/, /^RHEL/, /^ARM/]
              tokens.findAll { token -> !ignorePatterns.any { pattern -> token ==~ pattern } }
          }

          def dbLines = relevantLines.findAll { it.toUpperCase().contains("_DB") }
          def nonDbLines = relevantLines.findAll { !dbLines.contains(it) }

          def dbPartLists = dbLines.collectMany { dbLine ->
              def parts = extractTokens(dbLine)
              def dbIndex = parts.findIndexOf { it == "DB" }
              if (dbIndex >= 0) {
                  expectedDbTypes.collect { dbType ->
                      def newParts = parts.collect()
                      newParts[dbIndex] = dbType
                      newParts
                  }
              } else [parts]
          }
          def nonDbPartLists = nonDbLines.collect { extractTokens(it) }

          def dbArtifacts = []
          def nonDbArtifacts = []
          def matchedArtifacts = []

          if (forceMode || releaseMode) {
              if (forceMode) {
                  dbArtifacts = dbPartLists ? freshlyBuiltArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      dbPartLists.any { parts -> parts.every { part -> upperPath.contains(part) } }
                  } : []

                  nonDbArtifacts = freshlyBuiltArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      nonDbPartLists.any { parts ->
                          def keyParts = parts
                          def component = keyParts ? keyParts[0] : ""
                          keyParts.take(2).every { part -> upperPath.contains(part) } && upperPath.contains(component)
                      }
                  }.findAll { !(dbArtifacts.contains(it)) }

                  matchedArtifacts = (dbArtifacts + nonDbArtifacts).unique()
              } else if (releaseMode) {
                  def allPartLists = relevantLines.collect { extractTokens(it) }
                  matchedArtifacts = freshlyBuiltArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      allPartLists.any { parts ->
                          def keyParts = parts
                          def component = keyParts ? keyParts[0] : ""
                          keyParts.take(2).every { part -> upperPath.contains(part) } && upperPath.contains(component)
                      }
                  }

                  dbArtifacts = dbPartLists ? matchedArtifacts.findAll { path ->
                      def upperPath = path.toUpperCase()
                      dbPartLists.any { parts -> parts.every { part -> upperPath.contains(part) } }
                  } : []

                  nonDbArtifacts = matchedArtifacts.findAll { !(dbArtifacts.contains(it)) }
              }
          }

          println "========== ARTIFACT CLASSIFICATION =========="
          println "DB Artifact (${dbArtifacts.size()}):"
          dbArtifacts.each { println "  DB: ${it}" }

          println "Non-DB Artifacts (${nonDbArtifacts.size()}):"
          nonDbArtifacts.each { println "  Non-DB: ${it}" }

          println "========== BUILD SUMMARY =========="
          println "FORCE=1 used in release file: ${forceMode ? 'YES' : 'NO'}"
          println "Release mode: ${releaseMode ? 'YES' : 'NO'}"
          println "Expected component suffixes: ${forceMode ? (dbPartLists.size() + nonDbPartLists.size()) : relevantLines.size()}"
          println "Freshly built .tgz files detected: ${freshlyBuiltArtifacts.size()}"
          println "Matched artifacts: ${matchedArtifacts.size()}"
          println "==================================="

          if (Build_Script_Status != 0) {
              currentBuild.result = "FAILURE"
          }

          def allExist = matchedArtifacts.every { path ->
              sh(script: "[ -f '${path}' ] && echo 'true' || echo 'false'", returnStdout: true).trim() == 'true'
          }

          if (matchedArtifacts && allExist) {
              println "Artifacts Built Successfully: ${matchedArtifacts.join(', ')}"
              Artgen = 1
          } else {
              if (params.build_Flags?.contains("notgz")) {
                  println "No artifact generated."
                  Artgen = 0
              } else {
                  currentBuild.result = "SUCCESS"
                  Artgen = 0
                  println "Some or all artifacts not found. Check the build logs."
              }
          }

          return (Artgen == 0) ? "NoArtifact" : matchedArtifacts.join(',')
}

def env_linux() {
    env.ORACLE_HOME = "${params.oracle_home}"
    env.JAVA_HOME = "${params.java_home}"

    // Get kernel version
    def kernelVersion = sh(script: "uname -r", returnStdout: true).trim()

    if (kernelVersion.startsWith("5.14")) {
        env.LIBPATH = ":/home3/istrcc/BUILD/LIN-95/build/pdir/lib:/lib:/home3/istrcc/snmp_lib"
        env.LD_LIBRARY_PATH = "/usr/lib64/:/home3/istrcc/snmp_lib"
        env.DEBUGINFOD_IMA_CERT_PATH = "/etc/keys/ima"
        env.MODULEPATH = "/etc/scl/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles:/usr/share/modulefiles"
        echo "Linux Kernel 5.14 detected ‚Äî custom environment variables applied."
    } else {
        env.LD_LIBRARY_PATH = ".:/Osrc8/oracle/lin64_ora_19C:/Osrc8/oracle/lin64_ora_19C/bin:/Osrc8/local/bin/_LINUX2.6_i386_13/lib:/usr/lib64:/usr/lib"
        echo "Default Linux environment variables applied."
    }
}


def env_aix() {

    String AIXVersion = sh(script: "oslevel", returnStdout: true).trim()
    println "env_aix(): Detected AIX version: ${AIXVersion}"

   // env.ORACLE_HOME = '/Osrc/oracle/aix64_ora_1911'
   // env.JAVA_HOME = '/usr/java8_64/bin'
   // env.LD_LIBRARY_PATH = '.:/Osrc/oracle/aix64_ora_1911:/Osrc/oracle/aix64_ora_1911/bin:/Osrc/local/bin/_LINUX2.6_i386_13/lib:/usr/lib64:/usr/lib:/opt/IBM/xlC/13.1.2/bin'

    if (AIXVersion.startsWith("7.3")) {
        env.PATH = "/opt/IBM/openxlC/17.1.2/bin:/usr/java8_64/bin:/usr/boksm/bin:/opt/freeware/lib/gcc/powerpc-ibm-aix7.3.0.0/10:${env.PATH}:/opt/IBM/xlC/13.1.2/bin"
        env.ORACLE_HOME = "/fitools/u01/app/oracle/product/19.3"
        env.JAVA_HOME = '/opt/jdk-17.0.12+7'
        env.HOME = "/home3/istrcc-jenkins"
        env.LD_LIBRARY_PATH = '.:/fitools/u01/app/oracle/product/19.3:/fitools/u01/app/oracle/product/19.3/bin:/home3/Osrc/local/bin/_AIX4.2_risc6000/bin/lib:/usr/lib64:/usr/lib:/opt/IBM/xlc/13.1.3/bin'

    } else if (AIXVersion.startsWith("7.2")) {
        env.PATH = "/jenkins/jenkins-workspace:${env.PATH}:/opt/IBM/xlC/13.1.2/bin"
        env.ORACLE_HOME = '/Osrc/oracle/aix64_ora_1911'
        env.JAVA_HOME = '/usr/java8_64/bin'
        env.HOME = "/data/jenkins"
    } else {
        println "env_aix(): Unknown AIX version, using default HOME"
        env.HOME = "/home/jenkins"
    }

    println "env_aix(): PATH set to: ${env.PATH}"
    println "env_aix(): CUSTOM_HOME set to: ${env.HOME}"
}

def env_solaris() {
    env.ORACLE_HOME = '/Osrc8/oracle/lin64_ora_19C'
    env.JAVA_HOME = '/usr/lib/jvm/java-1.8.0-openjdk'
    env.LD_LIBRARY_PATH = '.:/usr/lib64:/usr/lib'
}

def env_hpux() {
    env.ORACLE_HOME = '/Osrc8/oracle/lin64_ora_19C'
    env.JAVA_HOME = '/usr/lib/jvm/java-1.8.0-openjdk'
    env.LD_LIBRARY_PATH = '.:/usr/lib64:/usr/lib'
}


---------------------------------------------------------------istPodAgents.yaml-----------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: ist-build-agent
spec:
  containers:
  - name: jnlp
    image: sipd-docker-dev.docker.fi.dev/jenkins/inbound-agent:latest-rhel-ubi9-jdk17
    imagePullPolicy: Always
    env:
    - name: HOME
      value: /home/jenkins
    - name: JAVA_TOOL_OPTIONS
      value: "-Xms1024m -Xmx1536m -XX:+UseG1GC -XX:MaxGCPauseMillis=200"
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    resources:
      requests:
        cpu: 550m
        memory: 2048Mi
      limits:
        cpu: 700m
        memory: 3048Mi
    tty: true
    workingDir: /home/jenkins

  - name: ist-build-agent
    image: istsw-docker-snapshot-local.docker.fi.dev/build-images/build:libnslfix
    imagePullPolicy: Always
    command: ["cat"]
    env:
    - name: JAVA_TOOL_OPTIONS
      value: "-Xms1024m -Xmx1280m"
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    - name: HOME
      value: /home/jenkins
    resources:
      requests:
        cpu: 400m
        memory: 1280Mi
      limits:
        cpu: 500m
        memory: 1536Mi
    volumeMounts:
    - mountPath: /data
      name: data-volume
    tty: true
    workingDir: /home/jenkins

  - name: python
    image: registry.access.redhat.com/ubi9/python-311:latest
    imagePullPolicy: Always
    command: ["cat"]
    env:
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    tty: true
    workingDir: /home/jenkins

  - name: opa-cli
    image: sipd-docker-dev.docker.fi.dev/openpolicyagent/opa:latest-debug
    imagePullPolicy: Always
    command: ["cat"]
    env:
    - name: HOME
      value: /home/jenkins
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 150m
        memory: 512Mi
    tty: true
    workingDir: /home/jenkins

  imagePullSecrets:
  - name: jnlpcred
  - name: istswcred

  volumes:
  - name: data-volume
    emptyDir: {}

  restartPolicy: Never
  
  
-------------------------------------------------------------------istpodagentsRhel9.yaml-----------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: ist-build-agent
spec:
  containers:
  - name: jnlp
    image: sipd-docker-dev.docker.fi.dev/jenkins/inbound-agent:latest-rhel-ubi9-jdk17
    imagePullPolicy: Always
    env:
    - name: HOME
      value: /home/jenkins
    - name: JAVA_TOOL_OPTIONS
      value: "-Xms1024m -Xmx1536m -XX:+UseG1GC -XX:MaxGCPauseMillis=200"
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    resources:
      requests:
        cpu: 550m
        memory: 2048Mi
      limits:
        cpu: 700m
        memory: 3048Mi
    tty: true
    workingDir: /home/jenkins

  - name: ist-build-agent
    image: istsw-docker-snapshot-local.docker.fi.dev/build-images/build:9.6
    imagePullPolicy: Always
    command: ["cat"]
    env:
    - name: JAVA_TOOL_OPTIONS
      value: "-Xms1024m -Xmx1280m"
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    - name: HOME
      value: /home/jenkins
    resources:
      requests:
        cpu: 400m
        memory: 1280Mi
      limits:
        cpu: 500m
        memory: 1536Mi
    volumeMounts:
    - mountPath: /data
      name: data-volume
    tty: true
    workingDir: /home/jenkins

  - name: python
    image: registry.access.redhat.com/ubi9/python-311:latest
    imagePullPolicy: Always
    command: ["cat"]
    env:
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    tty: true
    workingDir: /home/jenkins
    
  - name: opa-cli
    image: sipd-docker-dev.docker.fi.dev/openpolicyagent/opa:latest-debug
    imagePullPolicy: Always
    command: ["cat"]
    env:
    - name: HOME
      value: /home/jenkins
    - name: HTTP_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: HTTPS_PROXY
      value: "http://vlmazsdlproxy.fidev.local:8080"
    - name: NO_PROXY
      value: "localhost,127.0.0.1,.fidev.local,.cluster.local,.fi.dev,.svc"
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 150m
        memory: 512Mi
    tty: true
    workingDir: /home/jenkins

  imagePullSecrets:
  - name: jnlpcred
  - name: istswcred

  volumes:
  - name: data-volume
    emptyDir: {}

  restartPolicy: Never



----------------------------------------ocpodagents.yaml

apiVersion: v1
kind: Pod
spec:
  containers:
    - name: jnlp
      image: sipd-docker-dev.docker.fi.dev/jenkins/inbound-agent
      tty: true
      env:
        - name: JAVA_TOOL_OPTIONS
          value: "-Duser.home=/home/jenkins"
        - name: MAVEN_CONFIG
          value: "/home/jenkins/.m2"
        - name: HTTP_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: HTTP_PROXY
        - name: HTTPS_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: HTTPS_PROXY
        - name: NO_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: NO_PROXY
      envFrom:
        - configMapRef:
            name: proxy-config
      workingDir: /home/jenkins
      imagePullPolicy: Always
      resources:
        limits:
            memory: 2Gi
            cpu: 500m
        requests:
            memory: 128Mi
            cpu: 50m
    - name: python
      image: registry.access.redhat.com/ubi9/python-311:1-17.1692772360
      tty: true
      command:
      - cat
      env:
        - name: HTTP_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: HTTP_PROXY
        - name: HTTPS_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: HTTPS_PROXY
        - name: NO_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: NO_PROXY
      envFrom:
        - configMapRef:
            name: proxy-config
      workingDir: /home/jenkins
      imagePullPolicy: Always
    - name: opa-cli
      image: sipd-docker-dev.docker.fi.dev/openpolicyagent/opa:latest-debug
      tty: true
      command:
      - cat
      workingDir: /home/jenkins
      imagePullPolicy: Always 
    - name: cx-flow
      image: sipd-docker-dev.docker.fi.dev/checkmarx/cx-flow:871dd9b
      tty: true
      command:
      - cat
      env:
        - name: HTTP_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: HTTP_PROXY
        - name: HTTPS_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: HTTPS_PROXY
        - name: NO_PROXY
          valueFrom:
            configMapKeyRef:
              name: proxy-config
              key: NO_PROXY
      envFrom:
        - configMapRef:
            name: proxy-config
      workingDir: /home/jenkins
      imagePullPolicy: Always
      resources:
        limits:
            memory: 2Gi
            cpu: 500m
        requests:
            memory: 128Mi
            cpu: 50m   
  imagePullSecrets:
    - name: artifactory


------------------ostype.yaml-----------------------------------
os_list:
   'RHEL8OCP' : 'ist-build-jenkins'
   'RHEL9OCP' : 'ist-build-jenkins'  
   'RHEL8' : 'ojaistrhel8build'
   'RHEL8ISTRCC': 'maa5rap07'
   'RHEL9' : 'istl9build'
   'AIX7.2' : 'IST-AIX'
   'AIX7.3' : 
   'SOLARIS' : 
   
 ------------------------------------cxflowparams.yaml-----------------------------------------------
 
 cx-flow:
  bug-tracker: JIRA
  bug-tracker-impl:
    - Jira
  filter-severity:
    #Severety to triger the tickets creation
    - High
    - Medium
    - Low
  filter-category:
  filter-cwe:
  filter-status:
  filter-state:
  mitre-url: https://cwe.mitre.org/data/definitions/%s.html
  #codebash-url: https://customer.codebashing.com/courses

checkmarx:
  base-url: https://fi.checkmarx.net
  username: ${Checkmarx_User}
  password: ${Checkmarx_Passwd}
  version: 9.5
  client-id: resource_owner_client
  client-secret: 014DF517-39D1-4453-B7B3-9930C563627C
  scope: access_control_api sast_rest_api
  #team: /CxServer
  url: ${checkmarx.base-url}/cxrestapi
  #WSDL Config
  portal-url: ${checkmarx.base-url}/cxwebinterface/Portal/CxWebService.asmx
  sdk-url: ${checkmarx.base-url}/cxwebinterface/SDK/CxSDKWebService.asmx
  portal-wsdl: ${checkmarx.base-url}/Portal/CxWebService.asmx?wsdl
  sdk-wsdl: ${checkmarx.base-url}/SDK/CxSDKWebService.asmx?wsdl

jira:
  url: https://jira.fi.dev/
  username: Svcacct-istjira
  token: ''
  token-type: PAT
  #Jira Project Id
  project: ISTDEV
  #Jira Issue type
  issue-type: Story
  #Jira priorities mapping
  priorities:
    High: "2 - High"
    Medium: "3 - Medium"
  #Jira Trasition status
  open-transition: Defined
  close-transition: Complete
  open-status:
    - Defined
    - In Progress
    - Ready For Test
    - In Test
  closed-status:
    - Completed
    - Closed
  http-timeout : 150000
  sast-issue-summary-format: "[VULNERABILITY] in [PROJECT] with severity [SEVERITY] @ [FILENAME]"
  sast-issue-summary-branch-format: "[VULNERABILITY] in [PROJECT] with severity [SEVERITY] @ [FILENAME][[BRANCH]]"
  suppress-code-snippets:
    - Hardcoded_Password_in_Connection_String
    - Password_In_Comment
    - Use_Of_Hardcoded_Password
  fields:
    #    - type: cx #[ cx | static | result ]
    #      name: Platform # cx custom field name | cx-scan | cwe, category, severity, application, *project*, repo-name, branch, repo-url, namespace, recommendations, loc, site, issueLink, filename, language
    #      jira-field-name: Application
    #      jira-field-type: label #[ security | text | label | single-select | multi-select ]
    - type: cx
      name: cx-scan
      jira-field-name: Application
      jira-field-type: label
    - type: result
      name: application
      jira-field-name: Application
      jira-field-type: label
    - type: result
      name: cve
      jira-field-name: CVEs
      jira-field-type: label
    - type: result
      name: cwe
      jira-field-name: CWEs
      jira-field-type: label
    - type: result
      name: category
      jira-field-name: Category
    - type: result
      name: loc
      jira-field-name: LOC
      jira-field-type: label
      jira-default-value: XXXXX
	  
	  
------------------------------ist-jenkins-pipeine-libraray-------------------------------------
resources/fi/ist  --> all yamsls  istpodagents.yaml, istpodagetsrhel9.yaml, ocpodagents.yaml

---------------------------cd------------------------------nb--------------------------------

template:
  name: IST-SWITCH-NB-Template
  type: Pipeline
  orgIdentifier: IST
  spec:
    stages:
      - stage:
          name: Set Up Environment
          identifier: Set_Up_Environment
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            service:
              serviceRef: org.ISTSwitchDevSvc
              serviceInputs:
                serviceDefinition:
                  type: Ssh
                  spec:
                    artifacts:
                      primary:
                        primaryArtifactRef: <+input>
                        sources: <+input>
            environment:
              environmentRef: org.ISTSwitchEnv
              deployToAll: false
              infrastructureDefinitions:
                - identifier: <+pipeline.variables.TARGET_SERVER>
            execution:
              steps:
                - step:
                    type: Command
                    name: Set up variables
                    identifier: Set_up_variables
                    spec:
                      onDelegate: true
                      environmentVariables: []
                      outputVariables:
                        - name: Working_Directory
                          type: String
                          value: working
                        - name: ORACLE_HOME
                          type: String
                          value: oracle
                        - name: JAVA_HOME
                          type: String
                          value: java
                        - name: ISTMBREGION
                          type: String
                          value: region
                        - name: Artifact_Download_directory
                          type: String
                          value: Artifact_directory
                        - name: Node_name
                          type: String
                          value: Node_name
                        - name: Site_id
                          type: String
                          value: Site_id
                        - name: PGSQL_HOME
                          type: String
                          value: pgsql
                      commandUnits:
                        - identifier: Fetch_config_Values
                          name: Fetch config Values
                          type: Script
                          spec:
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/bash

                                  #Pipeline variables
                                  server_name="<+pipeline.variables.TARGET_SERVER>"
                                  user_account="<+pipeline.variables.USER_ACCOUNT>"
                                  env="<+pipeline.variables.Deployment_Env>"
                                  working_dir="<+pipeline.variables.HOME_PATH>"

                                  [[ "$working_dir" == "null" ]] && working_dir=""

                                  # Check if user provided working directory (non-empty and not just spaces)
                                  if [ -n "$working_dir" ]; then
                                      echo "[INFO] Using provided working directory: $working_dir"
                                      working="$working_dir"
                                  else

                                    case "$server_name" in
                                    "vlmazistqc100RHEL8"|"vlmazistdev102RHEL9")
                                      working="/apps/$user_account/harness/$env/switch"
                                      ;;
                                    "maa5afiistap04AIX73")
                                      working="/ist_qa/$user_account/harness/$env/switch"
                                      ;;
                                    "maa5afiistap06AIX")
                                      working="/ist_qa/$user_account/harness/$env/switch"
                                      ;;
                                    *)
                                      echo "Error: Invalid server and user account combination."
                                      echo "Hint: If '$server_name' is a valid target, please update this script to include it in the case block."
                                      exit 1
                                      ;;
                                    esac

                                  fi

                                  echo "Pipeline Execution ID: <+pipeline.sequenceId>"

                                  # Save the resolved Harness expression to a file

                                  cat <<EOF > env_file.yaml
                                  <+pipeline.stages.Set_Up_Environment.spec.configFiles.devcdconfig.gitFiles[0].fileContent>
                                  EOF

                                  # Extract values using yq
                                  oracle=$(yq e ".servers.\"${server_name}\".\"${user_account}\".oracle" env_file.yaml)
                                  java=$(yq e ".servers.\"${server_name}\".\"${user_account}\".java" env_file.yaml)
                                  region=$(yq e ".servers.\"${server_name}\".\"${user_account}\".region" env_file.yaml)
                                  Node_name=$(yq e ".servers.\"${server_name}\".\"${user_account}\".Node_name" env_file.yaml)
                                  pgsql=$(yq e ".servers.\"${server_name}\".\"${user_account}\".pgsql" env_file.yaml)

                                  # Normalize null values
                                  [[ "$oracle" == "null" ]] && oracle=""
                                  [[ "$pgsql" == "null" ]] && pgsql=""
                                  [[ "$java" == "null" ]] && java=""
                                  [[ "$region" == "null" ]] && region=""
                                  [[ "$Node_name" == "null" ]] && Node_name=""

                                  # Check if values were extracted
                                  if [[ -z "$working" || -z "$java" || -z "$region" || -z "$Node_name" ]]; then
                                    echo "Error: Invalid server and user account combination. Failing the pipeline."
                                    rm env_file.yaml
                                    exit 1
                                  fi

                                  Artifact_directory=$working/tgz

                                  node_number=${Node_name//[!0-9]/}

                                  # Determine Site_id based on whether node_number is even or odd
                                  if (( node_number % 2 == 0 )); then
                                  Site_id=2
                                  else
                                  Site_id=1
                                  fi

                                  # Print the extracted values
                                  echo "Working Directory: $working"
                                  echo "Artifact Download directory: $Artifact_directory"
                                  echo "JAVA HOME: $java"
                                  echo "ISTMBREGION: $region"
                                  echo "Node_name: $Node_name"
                                  echo "Site_id: $Site_id"
                                  echo "ORACLE HOME: ${oracle:-Not Provided}"
                                  echo "PGSQL HOME: ${pgsql:-Not Provided}"

                                  # Clean up
                                  rm env_file.yaml

                                  ###########################Validate user input for fresh Installation#############################

                                  fresh_installation="<+pipeline.variables.FRESH_INSTALLATION>"
                                  USE_DMKLINK="<+pipeline.variables.USE_DMKLINK>"

                                  # -----------------------------
                                  # Validation: Disallow update + DMKLINK together
                                  # -----------------------------
                                  if [ "$fresh_installation" = "No" ] && [ "$USE_DMKLINK" = "Yes" ]; then
                                      echo "[ERROR] Invalid combination: Update (FRESH_INSTALLATION=No) and DMKLINK install (USE_DMKLINK=Yes) cannot happen together."
                                      exit 1
                                  fi

                                  filename="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"

                                  # Extract TriggerType
                                  TriggerType="$(echo "$filename" | awk '{
                                    if (match($0, /(FullTrigger|PartialTrigger)/)) {
                                      print substr($0, RSTART, RLENGTH)
                                    }
                                  }')"

                                  echo "TriggerType: $TriggerType"

                                  # Validation check
                                  if [[ "$fresh_installation" == "Yes" && "$TriggerType" == "PartialTrigger" ]]; then
                                  echo "Validation Error: Partial Trigger cannot be selected during a fresh installation."
                                  exit 1
                                  else
                                  echo "Configuration is valid. Proceeding..."
                                  fi
                    timeout: 10m
                - step:
                    type: Command
                    name: Validate OS and Artifact Compatibility
                    identifier: Validate_OS_and_Artifact_Compatibility
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Validate_OS_and_Artifact
                          name: "Validate OS and Artifact "
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  # Navigate to the working directory
                                  WORKING_DIR="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                      if [ -d "$WORKING_DIR" ]; then
                                        cd "$WORKING_DIR"
                                     else
                                       echo "‚ùå Error: Working directory not found ‚Äî $WORKING_DIR"
                                        exit 1
                                      fi

                                  echo "Checking tgz directory..."
                                  tgz_dir="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>"

                                  if [ -d "$tgz_dir" ]; then
                                        echo "[INFO] Artiffact Download Directory found - $tgz_dir "
                                     else
                                        echo "‚ùå Error: Artiffact Download Directory not found ‚Äî $tgz_dir"
                                        exit 1
                                  fi

                                  # Detect OS type
                                  os_type=$(uname -s)
                                  platform_id=""

                                  # Function to map Linux kernel to server name
                                  map_linux_kernel() {
                                      kernel_version=$(uname -r)
                                      if [[ "$kernel_version" == *el8* ]]; then
                                          echo "LIN-4180-i686-64"
                                      elif [[ "$kernel_version" == *el9* ]]; then
                                          echo "LIN-5140-i686-64"
                                      else
                                          echo "LIN-Unknown"
                                      fi
                                  }

                                  # Function to map AIX oslevel to server name
                                  map_aix_oslevel() {
                                      aix_version=$(oslevel)
                                      case "$aix_version" in
                                          7.2*)
                                              echo "AIX-720-64"
                                              ;;
                                          7.3*)
                                              echo "AIX-730-64"
                                              ;;
                                          *)
                                              echo "AIX-Unknown"
                                              ;;
                                      esac
                                  }

                                  # Function to map Solaris version to server name
                                  map_solaris_version() {
                                      solaris_version=$(uname -r)
                                      case "$solaris_version" in
                                          5.11)
                                              echo "SOL-2114-M7-64"
                                              ;;
                                          5.10)
                                              echo "SOL-211-M7-64"
                                              ;;
                                          *)
                                              echo "SOL-Unknown"
                                              ;;
                                      esac
                                  }

                                  # Main logic
                                  case "$os_type" in
                                      Linux)
                                          echo "Detected Linux"
                                          echo "Kernel Version: $(uname -r)"
                                          platform_id=$(map_linux_kernel)
                                          ;;
                                      AIX)
                                          echo "Detected AIX"
                                          echo "OS Level: $(oslevel)"
                                          platform_id=$(map_aix_oslevel)
                                          ;;
                                      SunOS)
                                          echo "Detected Solaris"
                                          echo "OS Version: $(uname -r)"
                                          platform_id=$(map_solaris_version)
                                          ;;
                                      *)
                                          echo "Unknown OS: $os_type"
                                          platform_id="Unknown"
                                          ;;
                                  esac

                                  # Output the mapped platform ID
                                  echo "Platform ID: $platform_id"

                                  artifact_name="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"
                                  echo "Selected Artifact Name for Deployment: $artifact_name"

                                  if [ -z "$platform_id" ] || [ -z "$artifact_name" ]; then
                                      echo "Not Found Platform_ID and Artifact_Name"
                                      exit 2
                                  fi

                                  # Extract platform part from artifact name
                                  artifact_platform="$(echo "$artifact_name" | awk -F'_' '{print $(NF-1)"_"$NF}' \
                                      | sed 's/_FullTrigger.zip//;s/_PartialTrigger.zip//;s/.zip//')"

                                  # Compare
                                  if [ "$artifact_platform" = "$platform_id" ]; then
                                      echo "‚úÖ Match: Artifact platform ($artifact_platform) matches Platform ID ($platform_id)"
                                      exit 0
                                  else
                                      echo "‚ùå Mismatch: Artifact platform ($artifact_platform) does NOT match Platform ID ($platform_id)"
                                      exit 1
                                  fi

                                  # List files and print working directory
                                  ls -l
                                  pwd

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?

                                  # Fail pipeline if subshell failed
                                  if [ $exit_status -ne 0 ]; then
                                      exit $exit_status
                                  fi
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Command
                    name: Validate switch version
                    identifier: Validate_switch_version
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Validate_Switch_version
                          name: Validate Switch version
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  WORKING_DIR="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                      if [ -d "$WORKING_DIR" ]; then
                                        cd "$WORKING_DIR"
                                     else
                                       echo "‚ùå Error: Working directory not found ‚Äî $WORKING_DIR"
                                        exit 1
                                      fi

                                  # Find the latest pdir 
                                  latest_pdir=$(ls -td pdir20* 2>/dev/null | head -1)

                                  if [ -z "$latest_pdir" ]; then
                                  echo "No latest pdir found. Skipping version comparison and related steps."
                                  VERSION_MISMATCH=0
                                  echo "$VERSION_MISMATCH" > output_variable.txt
                                  exit 0
                                  else
                                  echo "latest Pdir: $latest_pdir"
                                  # Continue with the rest of the script

                                  TGZ_FILE="$latest_pdir/TGZ_state.info"
                                  ARTIFACT_NAME="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"
                                  echo "Artifact Zip File: $ARTIFACT_NAME"

                                  # Extract first SW line from TGZ_state.info
                                  sw_line="$(awk '/SW_/ {print $3; exit}' "$TGZ_FILE")"

                                  # Extract version, platform, and optional PV
                                  installed_version="$(echo "$sw_line" | \
                                    sed 's/^SW_\([0-9][0-9]*\.[0-9][0-9]*\.[0-9][0-9]*\.[0-9][0-9]*\.[0-9][0-9]*\)_\([A-Za-z0-9-]*\)\(_BASE\)\{0,1\}_*\(PV[0-9]*\)\{0,1\}\.tgz$/\1 \2 \4/' | \
                                    tr -d '\r' | xargs)"

                                  # -------------------------------
                                  # Artifact version parsing logic
                                  # -------------------------------
                                  filename="$ARTIFACT_NAME"

                                  # Extract SW part (e.g., 770)
                                  sw_part="$(echo "$filename" | sed -n 's/.*SW\([0-9]\{3\}\)SP.*/\1/p')"

                                  # Extract SP part (handles SP29RC1, SP29_)
                                  sp_part="$(echo "$filename" | sed -n 's/.*SP\([0-9][0-9]\).*/\1/p')"

                                  # Extract PV if present
                                  pv_part="$(echo "$filename" | sed -n 's/.*\(PV[0-9]*\)_.*/\1/p')"

                                  # Extract platform (handles both PV and non-PV formats)
                                  if echo "$filename" | grep -q "PV"; then
                                      platform="$(echo "$filename" | sed -n 's/.*PV[0-9]*_\([A-Za-z0-9-]*\)_.*$/\1/p')"
                                  else
                                      platform="$(echo "$filename" | sed -n 's/^.*SP[0-9][0-9]_\([A-Za-z0-9-]*\)_.*$/\1/p')"
                                  fi

                                  # Parse version
                                  major=$(echo "$sw_part" | cut -c1)
                                  minor=$(echo "$sw_part" | cut -c2)
                                  patch=$(echo "$sw_part" | cut -c3)

                                  # Construct version string
                                  version="${major}.${minor}.${patch}.${sp_part}.01"

                                  # Combine artifact version
                                  if [ -n "$pv_part" ]; then
                                      artifact_version="${version} ${platform} ${pv_part}"
                                  else
                                      artifact_version="${version} ${platform}"
                                  fi

                                  # Debug output
                                  echo "Installed version = [$installed_version]"
                                  echo "Artifact version  = [$artifact_version]"

                                  # Compare installed artifacts with selected artifact
                                  if [ "$installed_version" = "$artifact_version" ]; then
                                      echo "Version match: $installed_version"
                                  else
                                      echo "Version mismatch!"
                                      echo "Installed: $installed_version"
                                      echo "Artifact : $artifact_version"

                                      exit 1
                                  fi


                                  fi

                                  EOF
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                      condition: <+pipeline.variables.FRESH_INSTALLATION> == "No"
              rollbackSteps: []
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: MarkAsFailure
          when:
            pipelineStatus: All
      - stage:
          name: Dowload Artifact
          identifier: Dowload_Artifacts
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Check Disk Space
                    identifier: Check_Disc_Space
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Check_Disk_Space
                          name: Check Disk Space
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  WORKING_DIR="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                      if [ -d "$WORKING_DIR" ]; then
                                        cd "$WORKING_DIR"
                                     else
                                       echo "‚ùå Error: Working directory not found ‚Äî $WORKING_DIR"
                                        exit 1
                                      fi

                                  # Extract the first directory after root and add leading slash
                                  mount_point="/$(echo "$WORKING_DIR" | cut -d'/' -f2)"

                                  echo "Mount Point: $mount_point"

                                  OS_TYPE=$(uname)

                                  # Get disk usage for the mount point
                                  if [ "$OS_TYPE" = "Linux" ]; then
                                      USAGE="$(df -P "$mount_point" | awk 'NR==2 {gsub("%","",$5); print $5}')"
                                  elif [ "$OS_TYPE" = "AIX" ]; then
                                      USAGE="$(df -k "$mount_point" | awk 'NR>1 {for(i=1;i<=NF;i++) if($i ~ /%$/) {gsub("%","",$i); print $i; break}}')"
                                      
                                  else
                                      echo "Unsupported OS: $OS_TYPE"
                                      exit 1
                                  fi

                                  # Check if usage exceeds threshold
                                  THRESHOLD=96
                                  if [ -z "$USAGE" ]; then
                                      echo "Could not determine disk usage for $mount_point"
                                      exit 1
                                  fi

                                  if [ "$USAGE" -ge "$THRESHOLD" ]; then
                                      echo "CRITICAL: $mount_point is ${USAGE}% full. Please take action!"
                                      #exit 1
                                  else
                                      echo "OK: $mount_point usage is ${USAGE}%"
                                  fi

                                  EOF

                                  # Capture the exit status 
                                  exit_status=$?

                                  # Exit with the captured status
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    failureStrategies:
                      - onFailure:
                          errors:
                            - AllErrors
                          action:
                            type: StageRollback
                - step:
                    type: Command
                    name: Download Artifacts
                    identifier: Download_Artifacts
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Removing_the_Previous_Downloaded_Artifacts
                          name: Removing the Previous Downloaded Artifacts
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  ARTIFACT_DIR="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>"

                                  if [ -d "$ARTIFACT_DIR" ]; then
                                    cd "$ARTIFACT_DIR"
                                  else
                                    echo "‚ùå Error: Artifact directory not found ‚Äî $ARTIFACT_DIR"
                                    exit 1
                                  fi

                                  echo "Current user: $(whoami)"
                                  echo "Current working directory is: $(pwd)"

                                  # List of files to keep
                                  keep_files="build_env overriding_option_installer"

                                  # Collect .tgz files safely
                                  tgz_files=$(ls *.tgz 2>/dev/null)

                                  # Check if any .tgz files were found
                                  if [ -z "$tgz_files" ]; then
                                    echo "‚ÑπÔ∏è No tgz files found in the current directory."
                                  else
                                    for file in $tgz_files; do
                                      keep=0
                                      for keep_file in $keep_files; do
                                        if [ "${file%%.*}" = "$keep_file" ]; then
                                          keep=1
                                          break
                                        fi
                                      done

                                      if [ $keep -eq 0 ]; then
                                        rm "$file"
                                      fi
                                    done
                                  fi

                                  ls -l

                                  sleep 2
                                  EOF
                        - identifier: Download_Build_env_override_installer_scripts
                          name: Download Build env override installer scripts
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  # Navigate to the artifact download directory
                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>

                                  echo "Current user: $(whoami)"
                                  echo "Current working directory is: $(pwd)"

                                  current_user=$(whoami)
                                  os_type=$(uname)

                                  # Set proxy only for AIX users
                                  if [ "$os_type" = "AIX" ]; then
                                    export http_proxy="http://10.236.163.21:8080/"
                                    export https_proxy="http://10.236.163.21:8080/"
                                  fi

                                  filename="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"

                                  os_flavor="$(echo "$filename" | awk '{
                                    if (match($0, /(LIN|SOL|HPUX|AIX)-[0-9A-Za-z-]*/)) {
                                      print substr($0, RSTART, RLENGTH)
                                    }
                                  }')"

                                  echo "Extracted OS_FLAVOR: $os_flavor"

                                  # Determine OS_TYPE based on OS_FLAVOR
                                  case "$os_flavor" in
                                    LIN-*) OS_TYPE="lin" ;;
                                    SOL-*) OS_TYPE="sol" ;;
                                    AIX-*) OS_TYPE="aix" ;;
                                    HPUX-*) OS_TYPE="hpux" ;;
                                    *)
                                      echo "Unsupported OS_FLAVOR: $OS_FLAVOR"
                                      exit 1
                                      ;;
                                  esac

                                  echo "Determined OS_TYPE: $OS_TYPE"

                                  # Define the tool URL
                                  tool_url="<+pipeline.variables.ARTIFACT_TOOL_URL>"

                                  # Download build_env if not present
                                  if [ ! -f "build_env" ]; then
                                    curl -f -u "<+pipeline.variables.JFROG_USER>:<+pipeline.variables.JFROG_PASS>" -O "$tool_url/$OS_TYPE/build_env" || exit 1
                                  else
                                    echo "build_env already exists, skipping download."
                                  fi

                                  # Download overriding_option_installer if not present
                                  if [ ! -f "overriding_option_installer" ]; then
                                    curl -f -u "<+pipeline.variables.JFROG_USER>:<+pipeline.variables.JFROG_PASS>" -O "$tool_url/$OS_TYPE/overriding_option_installer" || exit 1
                                  else
                                    echo "overriding_option_installer already exists, skipping download."
                                  fi

                                  # List files and print working directory
                                  ls -l
                                  pwd

                                  EOF
                        - identifier: Download_IST_SWITCH_Zip_Artifacts
                          name: Download IST SWITCH Zip Artifacts
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>

                                  echo "Current user: $(whoami)"
                                  echo "Current working directory is: $(pwd)"

                                  current_user=$(whoami)
                                  os_type=$(uname)

                                  # Set proxy only for AIX users
                                  if [ "$os_type" = "AIX" ]; then
                                    export http_proxy="http://10.236.163.21:8080/"
                                    export https_proxy="http://10.236.163.21:8080/"
                                  fi

                                  # Make scripts executable
                                  chmod +x build_env
                                  chmod +x overriding_option_installer

                                  zip_artifact_url="<+artifact.metadata.url>"

                                  artifact_file_name="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"

                                  # Determine OS type
                                  os_type=$(uname)

                                  # Check if artifact is compatible with the OS
                                  if [ "$os_type" = "Linux" ]; then
                                    if echo "$artifact_file_name" | grep -q "AIX"; then
                                      echo "This is a Linux server. AIX artifact '$artifact_file_name' is not compatible. Skipping download."
                                      exit 1
                                    fi
                                  elif [ "$os_type" = "AIX" ]; then
                                    if echo "$artifact_file_name" | grep -q "LIN"; then
                                      echo "This is an AIX server. Linux artifact '$artifact_file_name' is not compatible. Skipping download."
                                      exit 1
                                    fi
                                  else
                                    echo "Unsupported OS: $os_type"
                                    exit 1
                                  fi

                                  # Function to download zip artifact
                                  download_zip_artifact() {
                                    echo "Downloading zip artifact from URL: $zip_artifact_url"
                                    if ! curl -u "<+pipeline.variables.JFROG_USER>:<+pipeline.variables.JFROG_PASS>" -O "$zip_artifact_url" ; then
                                      echo "Failed to download zip artifact from $zip_artifact_url"
                                      exit 1
                                    fi
                                  }

                                  # Download zip artifact if specified
                                  if [ -n "$zip_artifact_url" ]; then
                                    download_zip_artifact
                                  fi
                                  ls -l

                                  EOF

                                  # Capture the exit status of the dzdo su - strauss1 command
                                  EXIT_STATUS=$?

                                  # Check if the command inside the su block failed
                                  if [ $EXIT_STATUS -ne 0 ]; then
                                    echo "The script inside the $selected_user block failed. Exiting with status $EXIT_STATUS."
                                    exit $EXIT_STATUS
                                  fi
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Command
                    name: Unzip file
                    identifier: Unzip_file
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Unzip_file
                          name: Unzip file
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>

                                  echo "Current user: $(whoami)"

                                  # Unzip the artifact
                                  unzip "<+artifact.metadata.fileName>"

                                  ls -ltr

                                  echo "Current working directory is: $(pwd)"

                                  # Delete CLOUD-based artifacts
                                  CLOUD_FILES=$(find . -type f -name "*CLOUD*")

                                  if [ -z "$CLOUD_FILES" ]; then
                                    echo "‚ÑπÔ∏è No CLOUD-based artifacts found. Skipping deletion."
                                  else
                                    echo "Listing CLOUD-based artifacts to be deleted:"
                                    echo "$CLOUD_FILES" | xargs ls -l

                                    echo "Deleting CLOUD-based artifacts..."
                                    echo "$CLOUD_FILES" | xargs rm -f

                                    echo "Deletion completed."
                                  fi

                                  # Extract expected version from zip filename using awk + cut
                                  ZIP_NAME="<+artifact.metadata.fileName>"
                                  SWVER="$(echo "$ZIP_NAME" | awk -F'SW' '{print substr($2,1,3)}')"
                                  EXPECTED_VER="$(echo "$SWVER" | cut -c1).$(echo "$SWVER" | cut -c2).$(echo "$SWVER" | cut -c3)"

                                  echo "Expected version: $EXPECTED_VER"

                                  # --- FO_ Artifact Validation ---
                                  FO_FILES=$(find . -type f -name "FO_*.tgz")
                                  if [ -z "$FO_FILES" ]; then
                                    echo "‚ÑπÔ∏è No FO_ artifacts found. Skipping FO_ validation."
                                  else
                                    FO_MISMATCHES=$(echo "$FO_FILES" | while read file; do
                                      FILENAME=$(basename "$file")
                                      VER=$(echo "$FILENAME" | cut -d'_' -f2)
                                      echo "$VER" | grep -q "^$EXPECTED_VER" || echo "$FILENAME"
                                    done)

                                    if [ -n "$FO_MISMATCHES" ]; then
                                      echo "‚ùå FO_ Validation failed. The following artifacts do not match expected version $EXPECTED_VER:"
                                      echo "$FO_MISMATCHES"
                                      exit 2
                                    else
                                      echo "‚úÖ FO_ Validation successful. All FO_ artifacts match expected version $EXPECTED_VER."
                                    fi
                                  fi

                                  # --- SW_ Artifact Validation ---
                                  SW_FILES=$(find . -type f -name "SW_*.tgz")
                                  if [ -z "$SW_FILES" ]; then
                                    echo "‚ÑπÔ∏è No SW_ artifacts found. Skipping SW_ validation."
                                  else
                                    SW_MISMATCHES=$(echo "$SW_FILES" | while read file; do
                                      FILENAME=$(basename "$file")
                                      VER=$(echo "$FILENAME" | cut -d'_' -f2)
                                      echo "$VER" | grep -q "^$EXPECTED_VER" || echo "$FILENAME"
                                    done)

                                    if [ -n "$SW_MISMATCHES" ]; then
                                      echo "‚ùå SW_ Validation failed. The following artifacts do not match expected version $EXPECTED_VER:"
                                      echo "$SW_MISMATCHES"
                                      exit 2
                                    else
                                      echo "‚úÖ SW_ Validation successful. All SW_ artifacts match expected version $EXPECTED_VER."
                                    fi
                                  fi

                                  # Remove the original zip file
                                  rm "<+artifact.metadata.fileName>"

                                  ls -l

                                  EOF
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      condition: ""
                      stageStatus: Success
              rollbackSteps:
                - step:
                    type: Email
                    name: Disk Space Usage Alert
                    identifier: Disk_Space_Usage_Alert
                    spec:
                      to: <+pipeline.variables.NOTIFY_TO>
                      cc: <+pipeline.variables.NOTIFY_CC>
                      subject: Disk Usage Alert on <+pipeline.variables.TARGET_SERVER>
                      body: |
                        <!DOCTYPE html>
                        <html lang="en">
                        <head>
                          <meta charset="UTF-8">
                          <title>Disk Usage Status</title>
                          <style>
                            body {
                              font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                              background-color: #f9f9f9;
                              margin: 0;
                              padding: 30px 20px;
                            }

                            .notification-wrapper {
                              display: flex;
                              justify-content: center;
                            }

                            .notification-box {
                              position: relative;
                              background-color: #fff;
                              border-left: 6px solid #e74c3c;
                              padding: 18px 24px 18px 50px;
                              box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
                              width: 100%;
                              max-width: 360px;
                              border-radius: 8px;
                              font-size: 15px;
                            }

                            .notification-box::before {
                              content: "‚ö†Ô∏è";
                              position: absolute;
                              left: 16px;
                              top: 18px;
                              font-size: 20px;
                            }

                            .notification-box h3 {
                              margin: 0 0 10px;
                              font-size: 18px;
                              color: #2c3e50;
                            }

                            .notification-box p {
                              margin: 0;
                              color: #555;
                              line-height: 1.5;
                            }

                            .highlight {
                              font-weight: 600;
                              color: #c0392b;
                            }

                            .close-btn {
                              position: absolute;
                              top: 10px;
                              right: 12px;
                              background: none;
                              border: none;
                              font-size: 18px;
                              color: #aaa;
                              cursor: pointer;
                            }

                            .close-btn:hover {
                              color: #333;
                            }
                          </style>
                        </head>
                        <body>

                          <div class="notification-wrapper">
                            <div class="notification-box" id="notification">
                              <button class="close-btn" onclick="document.getElementById('notification').style.display='none';">&times;</button>
                              <h3>Disk Usage Status</h3>
                             <p>Disk usage on <span class="highlight"><+pipeline.variables.TARGET_SERVER></span> has exceeded the threshold of <span class="highlight">96%</span>.</p>
                            </div>
                          </div>

                        </body>
                        </html>
                    timeout: 10m
            service:
              useFromStage:
                stage: Set_Up_Environment
          tags: {}
          when:
            pipelineStatus: Success
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: MarkAsFailure
      - stage:
          name: Stop Application
          identifier: Stop_Application
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Stop Application
                    identifier: Stop_Application
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Stop_Application
                          name: Stop Application
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  WORKING_DIR="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  if [ -d "$WORKING_DIR" ]; then
                                    cd "$WORKING_DIR"
                                  else
                                    echo "‚ùå Error: Working directory not found ‚Äî $WORKING_DIR"
                                    exit 1
                                  fi

                                  echo "Current user: $(whoami)"

                                  ls -ld 

                                  # Set environment variables
                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  # Find the latest profile
                                  latest_profile=$(ls -td profile20* 2>/dev/null | head -1)

                                  # Exit immediately if no profile is found
                                  if [[ -z "$latest_profile" ]]; then
                                  echo "No profile found. Skipping all steps."
                                  exit 0
                                  fi

                                  echo "Profile file found = $latest_profile"

                                  . "./$latest_profile"

                                  export LOGNAME=$(whoami)

                                  # Attempt to bring down Application
                                  chkProcess=$(ps -f -u "$LOGNAME" | grep -w mbtsk | grep -v grep)
                                  if [ -z "$chkProcess" ]; then
                                      echo "IST is already stopped. Skipping istshutdown."
                                  else
                                      echo "IST is running. Executing istshutdown.sh..."
                                      cd $OPRODUCT_ROOT/bin && ksh istshutdown.sh
                                  fi

                                  echo "Current user: $(whoami)"
                                  echo "Cleaning IPC resources for key: $LOGNAME"

                                  # Remove shared memory segments
                                  for id in $(ipcs -m | grep "$LOGNAME" | awk '{print $2}'); do
                                      echo "Removing shared memory segment ID: $id"
                                      ipcrm -m "$id"
                                  done

                                  # Remove semaphores
                                  for id in $(ipcs -s | grep "$LOGNAME" | awk '{print $2}'); do
                                      echo "Removing semaphore ID: $id"
                                      ipcrm -s "$id"
                                  done

                                  # Remove message queues
                                  for id in $(ipcs -q | grep "$LOGNAME" | awk '{print $2}'); do
                                      echo "Removing message queue ID: $id"
                                      ipcrm -q "$id"
                                  done

                                  echo "Cleanup complete."

                                  echo "Checking Application Status........."

                                  sleep 60

                                  # Checking Application Status
                                  cd $OPRODUCT_ROOT/bin && ksh iststatuscheck.sh 

                                  EOF

                                  # Capture the exit status 
                                  exit_status=$?

                                  # Exit with the captured status
                                  exit $exit_status
                    timeout: 10m
                    when:
                      stageStatus: Success
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
              rollbackSteps: []
            service:
              useFromStage:
                stage: Set_Up_Environment
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: MarkAsFailure
          when:
            pipelineStatus: Success
      - stage:
          name: Backup
          identifier: Backup
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Backup
                    identifier: Backup
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables:
                        - name: Latest_profile
                          type: String
                          value: latest_profile
                        - name: BACKUP_TAKEN
                          type: String
                          value: BACKUP_TAKEN
                      commandUnits:
                        - identifier: Backup
                          name: "Backup "
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                    is_aix=false
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                    is_aix=true
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  # -----------------------------
                                  # Set up working directory
                                  # -----------------------------
                                  Working_Directory="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  cd $Working_Directory

                                  # Get the last folder name from Working_Directory (basename)
                                  last_folder=$(basename "$Working_Directory")
                                  cd "$Working_Directory/.." && [ -d "$last_folder" ] && chmod 777 "$last_folder" && cd "$Working_Directory"

                                  pwd
                                  ls -ltr

                                  echo "Current user: $(whoami)"

                                  INSTALL_DIR="$Working_Directory"
                                  echo "Installed dir is: $INSTALL_DIR"
                                  BACKUP_DIR="$INSTALL_DIR/backup_$(date +%Y%m%d_%H%M%S)"
                                  BACKUP_ARCHIVE="$BACKUP_DIR/backup.tar.gz"

                                  # Find the latest pdir and profile
                                  latest_pdir=$(ls -td "$INSTALL_DIR"/pdir20* 2>/dev/null | head -1)
                                  latest_profile=$(ls -td "$INSTALL_DIR"/profile20* 2>/dev/null | head -1)

                                  # Write latest_profile to a temporary file
                                  echo "$latest_profile" > output_variable.txt

                                  filename="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"

                                  # Extract TriggerType
                                  TriggerType="$(echo "$filename" | awk '{
                                    if (match($0, /(FullTrigger|PartialTrigger)/)) {
                                      print substr($0, RSTART, RLENGTH)
                                    }
                                  }')"

                                  echo "Artifact Type Selected: $TriggerType"

                                  # Pipeline variables
                                  FRESH_INSTALLATION="<+pipeline.variables.FRESH_INSTALLATION>"
                                  USE_DMKLINK="<+pipeline.variables.USE_DMKLINK>"

                                  # -----------------------------
                                  # Function to create tar archive
                                  # -----------------------------
                                  create_backup() {
                                      if [ "$(uname)" = "AIX" ]; then
                                          tar -cf "$BACKUP_DIR/backup.tar" -C "$INSTALL_DIR" "$@"
                                          gzip "$BACKUP_DIR/backup.tar"
                                      else
                                          tar -czf "$BACKUP_ARCHIVE" -C "$INSTALL_DIR" "$@"
                                      fi
                                  }

                                  # -----------------------------
                                  # Backup Logic
                                  # -----------------------------
                                  if [ "$FRESH_INSTALLATION" = "Yes" ] && [ "$USE_DMKLINK" = "No" ]; then
                                      echo "[INFO] Fresh installation with clean DB (USE_DMKLINK=No). Backing up pdir and profile."
                                      if [ -d "$latest_pdir" ] && [ -f "$latest_profile" ]; then
                                          mkdir -p "$BACKUP_DIR"
                                          create_backup "$(basename "$latest_pdir")" "$(basename "$latest_profile")"
                                      else
                                          echo "[WARNING] Required items missing. Skipping backup."
                                          rm -rf "$BACKUP_DIR"
                                      fi
                                  elif [ "$FRESH_INSTALLATION" = "Yes" ] && [ "$USE_DMKLINK" = "Yes" ]; then
                                      echo "[INFO] Fresh installation without clean DB (USE_DMKLINK=Yes). No backup required."
                                  elif [ "$FRESH_INSTALLATION" = "No" ]; then
                                      echo "[INFO] Update scenario. Backing up pdir and profile."
                                      if [ -d "$latest_pdir" ] && [ -f "$latest_profile" ]; then
                                          mkdir -p "$BACKUP_DIR"
                                          create_backup "$(basename "$latest_pdir")" "$(basename "$latest_profile")"
                                      else
                                          echo "[WARNING] Required items missing. Skipping backup."
                                          rm -rf "$BACKUP_DIR"
                                      fi
                                  else
                                      echo "[INFO] Unknown scenario. No backup performed."
                                  fi

                                  # -----------------------------
                                  # Verify backup archive
                                  # -----------------------------
                                  if [ -f "$BACKUP_ARCHIVE" ]; then
                                      if ! gunzip -c "$BACKUP_ARCHIVE" | tar -tf - >/dev/null; then
                                          echo "[WARNING] Backup verification failed - corrupt archive"
                                          rm -rf "$BACKUP_DIR"
                                      else
                                          echo "[SUCCESS] Backup archive created at: $BACKUP_ARCHIVE"
                                          ls -l "$BACKUP_ARCHIVE"

                                          # Save backup metadata
                                          echo "BACKUP_DIR=$BACKUP_DIR" > "$INSTALL_DIR/backup_vars.env"
                                          echo "BACKUP_PDIR=$latest_pdir" >> "$INSTALL_DIR/backup_vars.env"
                                          echo "BACKUP_PROFILE=$latest_profile" >> "$INSTALL_DIR/backup_vars.env"
                                          echo "BACKUP_ARCHIVE=$BACKUP_ARCHIVE" >> "$INSTALL_DIR/backup_vars.env"
                                      fi
                                  else
                                      echo "[INFO] No backup archive was created due to missing files or skipped backup."
                                  fi

                                  # -----------------------------
                                  # Write backup status
                                  # -----------------------------
                                  if [ -f "$BACKUP_ARCHIVE" ]; then
                                      BACKUP_TAKEN=Yes
                                      echo "$BACKUP_TAKEN" > backup_status.env
                                  else
                                      BACKUP_TAKEN=No
                                      echo "$BACKUP_TAKEN" > backup_status.env
                                  fi

                                  EOF

                                  # Read latest_profile from the temporary file
                                  latest_profile=$(cat output_variable.txt)
                                  echo "Latest profile: $latest_profile"

                                  BACKUP_TAKEN=$(cat backup_status.env)
                                  echo "Backup taken status: $BACKUP_TAKEN"
                    timeout: 1h 30m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
              rollbackSteps: []
            service:
              useFromStage:
                stage: Set_Up_Environment
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: MarkAsFailure
      - stage:
          name: Install Switch Application
          identifier: Install_Switch_Application
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Run Build Env Script
                    identifier: Run_Build_Env_Script
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables:
                        - name: Installation_type
                          type: String
                          value: installation_type
                      commandUnits:
                        - identifier: Install_package_with_build_env_script
                          name: Install package with build_env script
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'INNER_EOF'

                                  # Get current user and OS type
                                  current_user=$(whoami)
                                  os_type=$(uname)

                                  # Apply PATH update only for AIX users
                                  if [ "$os_type" = "AIX" ]; then
                                    export PATH="/usr/java8_64/bin:$PATH"
                                  fi

                                  Working_Dir="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  cd $Working_Dir

                                  [ -f build_env.log ] && rm build_env.log

                                  fresh_installation="<+pipeline.variables.FRESH_INSTALLATION>"
                                  use_dmklink="<+pipeline.variables.USE_DMKLINK>"

                                  if [ "$fresh_installation" = "Yes" ] && [ "$use_dmklink" = "Yes" ]; then
                                      prot_dir=$(ls -td prot_dir_* 2>/dev/null | head -1)

                                      if [ -n "$prot_dir" ]; then
                                          echo "Found Protect Dir: $prot_dir"
                                      else
                                          echo "Error: Protected Dir not found. Failing the pipeline."
                                          exit 1
                                      fi
                                  fi

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="$Working_Dir"

                                  echo "HOME is set to: $HOME"

                                  # Remove old output files
                                  [ -f $HOME/baseline_ora_files.txt ] && rm $HOME/baseline_ora_files.txt
                                  [ -f $HOME/postinstall_ora_files.txt ] && rm $HOME/postinstall_ora_files.txt
                                  [ -f $HOME/ora_diff_report.txt ] && rm $HOME/ora_diff_report.txt

                                  # Function to convert yes/no to 1/0
                                  convert_yes_no() {
                                      input=$1
                                      if [ "$input" = "yes" ]; then
                                          echo 1
                                      elif [ "$input" = "no" ]; then
                                          echo 0
                                      else
                                          echo "[ERROR] Invalid input: $input. Expected 'yes' or 'no'."
                                          exit 1
                                      fi
                                  }

                                  # Function to convert yes/no to 0/1 for confirm_install and run_tests
                                  convert_reverse_yes_no() {
                                      input=$1
                                      if [ "$input" = "yes" ]; then
                                          echo 0
                                      elif [ "$input" = "no" ]; then
                                          echo 1
                                      else
                                          echo "[ERROR] Invalid input: $input. Expected 'yes' or 'no'."
                                          exit 1
                                      fi
                                  }

                                  # Extract OS_FLAVOR from the artifact filename
                                  filename="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"

                                  os_flavor="$(echo "$filename" | awk '{
                                    if (match($0, /(LIN|SOL|HPUX|AIX)-[0-9A-Za-z-]*/)) {
                                      print substr($0, RSTART, RLENGTH)
                                    }
                                  }')"

                                  echo "Extracted OS_FLAVOR: $os_flavor"

                                  # Fetching harness variables
                                  continue_sp_fo=$(convert_yes_no "<+pipeline.variables.CONTINUE_SP_FO>")
                                  continue_sp_sw=$(convert_yes_no "<+pipeline.variables.CONTINUE_SP_SW>")
                                  confirm_install=$(convert_reverse_yes_no "<+pipeline.variables.CONFIRM_INSTALL>")
                                  run_tests=$(convert_reverse_yes_no "no")

                                  filename="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"

                                  # Extract TriggerType
                                  TriggerType="$(echo "$filename" | awk '{
                                    if (match($0, /(FullTrigger|PartialTrigger)/)) {
                                      print substr($0, RSTART, RLENGTH)
                                    }
                                  }')"

                                  echo "TriggerType: $TriggerType"

                                  fresh_installation="<+pipeline.variables.FRESH_INSTALLATION>"
                                  use_dmklink="<+pipeline.variables.USE_DMKLINK>"
                                  dmklink_path="$Working_Dir/$prot_dir"

                                  # Determine installation_type based on TriggerType and fresh_installation
                                  if [ "$TriggerType" = "FullTrigger" ] && [ "$fresh_installation" = "Yes" ]; then
                                      if [ "$use_dmklink" = "Yes" ]; then
                                          installation_type="Install_With_DMKLINK"
                                      else
                                          installation_type="Install"
                                      fi
                                  else
                                      installation_type="Update"
                                  fi

                                  # Validate variables to prevent unexpected behavior
                                  if [ -z "$os_flavor" ] || [ -z "$confirm_install" ] || [ -z "$run_tests" ]; then
                                      echo "[ERROR] One or more required variables are missing"
                                      exit 1
                                  fi

                                  echo "[INFO] Starting the Harness Pipeline...."
                                  echo "Configuration Selected:"
                                  echo "- OS Flavor: $os_flavor"
                                  echo "- Continue with Service Packs (FO): $continue_sp_fo"
                                  echo "- Continue with Service Packs (SW): $continue_sp_sw"
                                  echo "- Confirm Install: $confirm_install"
                                  echo "- Run Tests: $run_tests"
                                  echo "- Installation Type: $installation_type"

                                  ls -ltr

                                  # Gather all .tgz files in the current directory
                                  artifacts=$(ls *.tgz 2>/dev/null | tr '\n' ' ')

                                  # Function to check installed packages
                                  check_installed_packages() {
                                      ./build_env -list | grep 'installed' | awk '{print $NF}'
                                  }

                                  # Determine the Final Command based on installation type
                                  if [ "$installation_type" = "Install" ]; then
                                    cmd="./build_env -os=$os_flavor"
                                  elif [ "$installation_type" = "Install_With_DMKLINK" ]; then
                                    cmd="./build_env -os=$os_flavor -dmklink=$dmklink_path" 
                                  else
                                    cmd="./build_env -os=$os_flavor $artifacts"
                                  fi

                                  echo "[INFO] Final Installation Command: $cmd"

                                  export CMD="$cmd"

                                  if [ "$installation_type" = "Install" ] || [ "$installation_type" = "Install_With_DMKLINK" ]; then
                                      /usr/bin/expect << EXPECT_EOF
                                      set timeout -1
                                      set home \$env(HOME)
                                      set cmd \$env(CMD)
                                      
                                      spawn sh -c "$cmd"

                                      expect {
                                          "Some SERVICE-PACK(s) are missing. How to you want to continue ?*" {
                                              send "$continue_sp_fo\r" 
                                              exp_continue
                                              send "$continue_sp_sw\r"
                                              exp_continue
                                          }
                                          "Please confirm to install the above*" {
                                              send "$confirm_install\r"
                                              exp_continue
                                          }
                                          "Do you want to exercise some run test on the binaries ?*" {
                                              send "1\r"
                                              exp_continue
                                          }
                                          "Override with file in clear" {
                                              send "0\r"
                                              exp_continue
                                          }
                                          "Override with hex-dump in clear" {
                                              send "0\r"
                                              exp_continue
                                          }
                                          "Override tokenization with ECHO only" {
                                              send "0\r"
                                              exp_continue
                                          }
                                          "Override with shared memory unlocked" {
                                              send "1\r"
                                              exp_continue
                                          }
                                          eof
                                      }
                                  EXPECT_EOF

                                  elif [ "$installation_type" = "Update" ]; then

                                      latest_profile="<+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.Latest_profile>"
                                      echo "Latest profile found: $latest_profile"
                                      
                                      . "$latest_profile"
                                   
                                      echo "Product root: $OPRODUCT_ROOT"

                                      BASE_DIR="$OPRODUCT_ROOT"
                                      UDM="$BASE_DIR/sql"
                                      TRIG="$BASE_DIR/sql_scripts"
                                      OUT="$HOME/baseline_ora_files.txt"

                                      scan_before_install() {
                                          {
                                              [ -d "$UDM" ] && find "$UDM" -type f -name "*.ora" | sed 's|^|[UDM] |'
                                              [ -d "$TRIG" ] && find "$TRIG" -type f -name "*.ora" | sed 's|^|[TRIGGER] |'
                                          } > "$OUT"

                                          echo "[INFO] Pre-installation scan complete: $OUT"
                                      }

                                      # Run the scan
                                      scan_before_install

                                      installed_packages_before=$(check_installed_packages)
                                      echo "Installed packages before update: $installed_packages_before"

                                      export CMD="./build_env -os=$os_flavor $artifacts"

                                      /usr/bin/expect << EXPECT_EOF
                                      set timeout -1
                                      set home \$env(HOME)
                                      set cmd \$env(CMD)
                                      
                                      spawn sh -c "$cmd"

                                      expect {
                                          "Do you want to install again*" {
                                              send "1\r"
                                              exp_continue
                                          }
                                          "Do you want to delete it and continue the installation*" {
                                              send "1\r"
                                              exp_continue
                                          }
                                          "Replacing*" {
                                              send "2\r"
                                              exp_continue
                                          }
                                          "Override with file in clear" {
                                              send "0\r"
                                              exp_continue
                                          }
                                          "Override with hex-dump in clear" {
                                              send "0\r"
                                              exp_continue
                                          }
                                          "Override tokenization with ECHO only" {
                                              send "0\r"
                                              exp_continue
                                          }
                                          "Override with shared memory unlocked" {
                                              send "1\r"
                                              exp_continue
                                          }
                                          
                                      }
                                  EXPECT_EOF

                                      installed_packages_after=$(check_installed_packages)
                                      echo "Installed packages after update: $installed_packages_after"
                                  fi


                                  # Write latest_profile to a temporary file
                                  echo "$installation_type" > $HOME/output_variable.txt

                                  INNER_EOF

                                  # Capture the exit status
                                  exit_status=$?

                                  # Fail pipeline if subshell failed
                                  if [ $exit_status -ne 0 ]; then
                                      exit $exit_status
                                  fi

                                  # Read latest_profile from the temporary file
                                  installation_type=$(cat output_variable.txt)
                                  echo "Installation Type: $installation_type"
                    timeout: 1h
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Command
                    name: Check Installation Status
                    identifier: Check_Installation_Status
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables:
                        - name: latest_profile
                          type: String
                          value: latest_profile
                        - name: latest_pdir
                          type: String
                          value: latest_pdir
                      commandUnits:
                        - identifier: Check_Installation_Status
                          name: Check Installation Status
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  [ -f output_variable.txt ] && rm output_variable.txt

                                  LOG_FILE="build_env.log"

                                  # Get the last lines of the log file
                                  LAST_LINES=$(tail -n 10 "$LOG_FILE")

                                  # Check the last 10 lines for "Program Aborted" or "Program Completed"
                                  if echo "$LAST_LINES" | grep -q "Program Aborted"; then
                                      echo "Pipeline failed due to program abortion."
                                      exit 1
                                  else
                                      if echo "$LAST_LINES" | grep -q "Program Completed"; then
                                          echo "Pipeline succeeded."
                                      fi
                                  fi

                                  # Find the latest pdir and profile
                                  latest_profile=$(ls -td profile20* 2>/dev/null | head -1)
                                  latest_pdir=$(ls -td pdir20* 2>/dev/null | head -1)

                                  if [ -z "$latest_profile" ]; then
                                      echo "[WARNING] No profile found"
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir file: $latest_pdir"
                                  fi

                                  # Write latest_profile to a temporary file
                                  echo "latest_profile=$latest_profile" > output_variable.txt
                                  echo "latest_pdir=$latest_pdir" >> output_variable.txt

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?

                                  # Fail pipeline if subshell failed
                                  if [ $exit_status -ne 0 ]; then
                                      exit $exit_status
                                  fi

                                  # Read latest_profile & latest_pdir from the temporary file
                                  latest_profile=$(awk -F= '/^latest_profile=/ {print $2}' output_variable.txt)
                                  latest_pdir=$(awk -F= '/^latest_pdir=/ {print $2}' output_variable.txt)
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Command
                    name: Set up Profile
                    identifier: Set_up_Profile
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Set_up_Profile
                          name: Set up Profile
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  #Update ISTMBREGION value
                                  NEW_VALUE="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.ISTMBREGION>"

                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"

                                  PROFILE_FILE="$latest_profile"

                                  # Insert HOME path, echo, and a blank line above ISTMBREGION
                                  HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  sed "/^ISTMBREGION=.*/i\\
                                  export HOME=$HOME\\
                                  echo \\\"HOME PATH is set to \$HOME\\\"\\

                                  " "$PROFILE_FILE" > "${PROFILE_FILE}.tmp" && mv "${PROFILE_FILE}.tmp" "$PROFILE_FILE"

                                  # Replace the ISTMBREGION line with the new value
                                  sed "s/^ISTMBREGION=.*/ISTMBREGION=$NEW_VALUE/" "$PROFILE_FILE" > "${PROFILE_FILE}.tmp" && mv "${PROFILE_FILE}.tmp" "$PROFILE_FILE"

                                  echo "ISTMBREGION updated to $NEW_VALUE in $PROFILE_FILE"

                                  ORACLE_HOME_PATH="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.ORACLE_HOME>"
                                  JAVA_HOME_PATH="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.JAVA_HOME>"
                                    
                                  # Update or insert ORACLE_HOME
                                  sed "/^[#]* *ORACLE_HOME=/c\\
                                  ORACLE_HOME=$ORACLE_HOME_PATH
                                  " "$PROFILE_FILE" > "${PROFILE_FILE}.tmp" && mv "${PROFILE_FILE}.tmp" "$PROFILE_FILE"

                                  sed "/^[#]* *export ORACLE_HOME/c\\
                                  export ORACLE_HOME
                                  " "$PROFILE_FILE" > "${PROFILE_FILE}.tmp" && mv "${PROFILE_FILE}.tmp" "$PROFILE_FILE"

                                  # Update or insert JAVA_HOME
                                  sed "/^[#]* *JAVA_HOME=/c\\
                                  JAVA_HOME=$JAVA_HOME_PATH
                                  " "$PROFILE_FILE" > "${PROFILE_FILE}.tmp" && mv "${PROFILE_FILE}.tmp" "$PROFILE_FILE"

                                  sed "/^[#]* *export JAVA_HOME/c\\
                                  export JAVA_HOME
                                  " "$PROFILE_FILE" > "${PROFILE_FILE}.tmp" && mv "${PROFILE_FILE}.tmp" "$PROFILE_FILE"

                                  echo "ORACLE_HOME and JAVA_HOME updated and uncommented in $PROFILE_FILE"

                                  chmod 755 $PROFILE_FILE

                                  #Script to append alias definitions to a profile file using here-document
                                  CONFIG_FILE="$PROFILE_FILE"

                                  # Define alias block using here-document
                                  cat <<'EOF1' >> "$CONFIG_FILE"
                                  export LM2PORT=7654
                                  alias l='ls -lrta'
                                  alias c='clear'
                                  alias site='cd $OSITE_ROOT'
                                  alias cfg='cd $OSITE_ROOT/cfg'
                                  alias data='cd $OSITE_ROOT/data'
                                  alias debug='cd $OLOGDIR/debug'
                                  alias dbutil='cd $OSITE_ROOT/dbutil'
                                  alias jgui='cd $OPRODUCT_ROOT/javagui'
                                  alias cert='cd $OSITE_ROOT/certdata'
                                  alias log='cd $OLOGDIR'
                                  alias pdir='cd $OPRODUCT_ROOT'
                                  EOF1

                                  echo "Alias are appended to $PROFILE_FILE"

                                  PGSQL_HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.PGSQL_HOME>"

                                  # Append PGSQL paths only if PGSQL_HOME exists
                                  if [[ -n "$PGSQL_HOME" && "$PGSQL_HOME" != "null" ]]; then
                                      echo "Appending PGSQL paths to $CONFIG_FILE"
                                      cat <<EOF2 >> "$CONFIG_FILE"
                                  export PATH=$PGSQL_HOME/bin:\$PATH
                                  export LD_LIBRARY_PATH=$PGSQL_HOME/lib:\$LD_LIBRARY_PATH
                                  EOF2
                                  else
                                      echo "PGSQL_HOME not provided, skipping PostgreSQL path setup."
                                  fi

                                  EOF
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                      condition: <+pipeline.stages.Install_Switch_Application.spec.execution.steps.Run_Build_Env_Script_0.output.outputVariables.Installation_type> == "Install" || <+pipeline.stages.Install_Switch_Application.spec.execution.steps.Run_Build_Env_Script_0.output.outputVariables.Installation_type> == "Install_With_DMKLINK"
                - step:
                    type: Command
                    name: Istparam config
                    identifier: Istparam_config
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Istparam_config
                          name: Istparam config
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  set -x

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  pwd

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"

                                  if [ -z "$latest_profile" ]; then
                                      echo "[WARNING] No profile found"
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir file: $latest_pdir"
                                  fi

                                  current_user=$(whoami)
                                  os_type=$(uname)

                                  # Set proxy only for AIX users
                                  if [ "$os_type" = "AIX" ]; then
                                    export http_proxy="http://10.236.163.21:8080/"
                                    export https_proxy="http://10.236.163.21:8080/"
                                  fi

                                  # Define the artifact URL (replace with actual URL)
                                  ARTIFACT_URL="<+pipeline.variables.ISTPARAMS_JFROG>"

                                  cd $latest_pdir/ositeroot/cfg/

                                  curl -f -u "<+pipeline.variables.JFROG_USER>:<+pipeline.variables.JFROG_PASS>" -O "$ARTIFACT_URL"

                                  # Check if the download was successful
                                  if [ $? -eq 0 ]; then
                                      echo "istparam.cfg successfully downloaded to $latest_pdir/ositeroot/cfg/"
                                  else
                                      echo "Failed to download istparam.cfg" >&2
                                      exit 1
                                  fi

                                  sleep 5

                                  # Check if ^M exists using tr and wc
                                  if [ "$(tr -d '\r' < istparam.cfg | wc -c)" -ne "$(wc -c < istparam.cfg)" ]; then
                                      tr -d '\r' < istparam.cfg > istparam_clean.cfg
                                      mv istparam_clean.cfg istparam.cfg
                                      echo "Cleaned istparam.cfg"
                                  else
                                      echo "No ^M characters found. No cleanup needed."
                                  fi

                                  echo "Replacing the correct Node name value in istparam.cfg"
                                  node_name="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Node_name>"
                                  sed "s/node08/$node_name/g" istparam.cfg > istparam_updated.cfg && mv istparam_updated.cfg istparam.cfg

                                  #Write the node_id to nodeid.cfg file
                                  node_id="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Site_id>"
                                  echo "$node_id" > nodeid.cfg

                                  # Create apm.src file under cfg folder

                                  CONFIG_FILE="apm.src"

                                  # Content to append
                                  CONTENT=$(cat <<'EOF2'

                                  api   api  localhost  null  oasisvm  null  null  OPRODUCT_ROOT  ovm/api.cfg  OVM_API  null  1  0  0x0000ffff  9  001003O
                                   
                                  comgr sys localhost null istcomgr null null null null COMGR null 1 0 0x00000000 0 100100

                                  #apacs  apacs  localhost  null  oasisvm  null  null  OPRODUCT_ROOT  ovm/apacs.cfg  OVM_APACS  null  1  0  0x00000000 99  001003

                                  #hyp  hyp  localhost  null  oasisvm  null  null  OPRODUCT_ROOT  ovm/hyp.cfg  OVM_HYP  null  1  0  0x0000ffff  9  001003

                                  visaagt  NET  localhost  null istagent  null liboistiso.DLL OPRODUCT_ROOT cfg/visaagt.cfg SMSFormatter7 SharedCash 1 0 0x0000ffff 0 100101 110
                                   

                                  EOF2
                                  )

                                  # Insert the content to the file
                                  echo "$CONTENT" > "$CONFIG_FILE"

                                  echo "apm.src file created successfully under cfg directory."


                                  EOF
                    timeout: 10m
                    when:
                      stageStatus: Success
                      condition: <+pipeline.stages.Install_Switch_Application.spec.execution.steps.Run_Build_Env_Script_0.output.outputVariables.Installation_type>=="Install"
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
              rollbackSteps:
                - step:
                    type: Email
                    name: App install rollback email
                    identifier: App_install_rollback_email
                    spec:
                      to: <+pipeline.variables.NOTIFY_TO>
                      cc: <+pipeline.variables.NOTIFY_CC>
                      subject: Rollback notification <+pipeline.name>
                      body: |
                        <!DOCTYPE html>
                        <html>
                          <body style="font-family: Arial, sans-serif; background-color: #e9f1f7; padding: 20px; color: #2c3e50;">
                            <div style="max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 10px; padding: 20px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);">
                              <h2 style="color: #d9534f; border-bottom: 2px solid #dc3545; padding-bottom: 10px;">Harness Pipeline Failed</h2>
                              <p>Dear Team,</p>
                              <p>The <strong><+pipeline.name>;</strong> execution encountered a failure at stage <strong><+stage.name>;</strong>.</p>

                              <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Project Name</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><+project.name></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Pipeline Name</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong><+pipeline.name></strong></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Failed Stage</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong><+stage.name></strong></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Status</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong>Failed</strong></td>
                                </tr>
                              </table>

                              <p style="margin-top: 20px;">
                                Failed Pipeline Link: 
                                <a href="<+pipeline.executionUrl>" style="background-color: #dc3545; color: white; padding: 10px 15px; text-decoration: none; border-radius: 5px;">View Pipeline Execution</a>
                              </p>

                              <p style="margin-top: 20px; font-weight: bold; color: #d9534f;">
                                Rollback with previous pdir will be executed.
                              </p>

                              <p style="margin-top: 20px;">Regards,<br/>CICD Team</p>

                              <p style="font-size: 12px; color: #6c757d; margin-top: 30px;">
                                This is an automated email generated by the Harness pipeline. Please do not reply to this email.
                              </p>
                            </div>
                          </body>
                        </html>
                    timeout: 10m
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes"
                - step:
                    type: HarnessApproval
                    name: Rollback Approval
                    identifier: Rollback_Approval
                    spec:
                      approvalMessage: Please review the following information and approve the pipeline progression
                      includePipelineExecutionHistory: true
                      isAutoRejectEnabled: false
                      approvers:
                        userGroups: <+input>.selectOneFrom(org.SW_QC_Approvers,org.SW_Dev_Approvers)
                        minimumCount: 1
                        disallowPipelineExecutor: false
                      approverInputs: []
                    timeout: 1d
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes"
                - step:
                    type: Command
                    name: Rollback to previous pdir
                    identifier: Rollback_to_previous_pdir
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables:
                        - name: Restored_profile
                          type: String
                          value: restored_profile
                      commandUnits:
                        - identifier: Rollback
                          name: Rollback
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  set -e

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  INSTALL_DIR="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  BACKUP_VARS="$INSTALL_DIR/backup_vars.env"

                                  export HOME="$INSTALL_DIR"

                                  echo "HOME is set to: $HOME"

                                  # Load backup variables
                                  if [ ! -f "$BACKUP_VARS" ]; then
                                      echo "[ERROR] Backup variables file not found!"
                                      exit 1
                                  fi

                                  . "$BACKUP_VARS"

                                  # Verify backup variables
                                  if [ -z "$BACKUP_DIR" ] || [ -z "$BACKUP_PDIR" ] || [ -z "$BACKUP_PROFILE" ]; then
                                      echo "[ERROR] Backup variables are not set correctly!"
                                      exit 1
                                  fi

                                  # Verify archive
                                  if [ ! -f "$BACKUP_ARCHIVE" ]; then
                                      echo "[ERROR] Backup archive not found!"
                                      exit 1
                                  fi

                                  # Validate archive based on OS
                                  if [ "$(uname)" = "AIX" ]; then
                                      if ! gunzip -c "$BACKUP_ARCHIVE" | tar -tf - >/dev/null; then
                                          echo "[ERROR] Backup archive is corrupt!"
                                          exit 1
                                      fi
                                  else
                                      if ! tar -tzf "$BACKUP_ARCHIVE" >/dev/null; then
                                          echo "[ERROR] Backup archive is corrupt!"
                                          exit 1
                                      fi
                                  fi

                                  # Remove existing files
                                  if [ -d "$INSTALL_DIR/$(basename "$BACKUP_PDIR")" ]; then
                                      echo "[INFO] Removing existing pdir directory: $(basename "$BACKUP_PDIR")"
                                      rm -rf "$INSTALL_DIR/$(basename "$BACKUP_PDIR")"
                                  fi

                                  if [ -f "$INSTALL_DIR/$(basename "$BACKUP_PROFILE")" ]; then
                                      echo "[INFO] Removing existing profile file: $(basename "$BACKUP_PROFILE")"
                                      rm -f "$INSTALL_DIR/$(basename "$BACKUP_PROFILE")"
                                  fi

                                  # Remove prot_dir if it was backed up
                                  if [ -n "$BACKUP_PROT_DIR" ] && [ -d "$INSTALL_DIR/prot_dir" ]; then
                                      echo "[INFO] Removing existing prot_dir directory"
                                      rm -rf "$INSTALL_DIR/prot_dir"
                                  fi

                                  # Extract backup
                                  echo "[INFO] Extracting backup archive..."
                                  if [ "$(uname)" = "AIX" ]; then
                                      gunzip -c "$BACKUP_ARCHIVE" | tar -xvf - -C "$INSTALL_DIR"
                                  else
                                      tar -xzf "$BACKUP_ARCHIVE" -C "$INSTALL_DIR"
                                  fi

                                  restored_profile="$INSTALL_DIR/$(basename "$BACKUP_PROFILE")"

                                  # Verify restoration
                                  if [ ! -d "$INSTALL_DIR/$(basename "$BACKUP_PDIR")" ] || [ ! -f "$restored_profile" ]; then
                                      echo "[ERROR] Rollback verification failed"
                                      exit 1
                                  fi

                                  if [ -n "$BACKUP_PROT_DIR" ] && [ ! -d "$INSTALL_DIR/prot_dir" ]; then
                                      echo "[ERROR] prot_dir restoration failed"
                                      exit 1
                                  fi

                                  echo "[SUCCESS] Restoration completed successfully"

                                  # Write latest_profile to a temporary file
                                  echo "$restored_profile" > output_variable.txt

                                  EOF

                                  # Read latest_profile from the temporary file
                                  restored_profile=$(cat output_variable.txt)
                                  echo "Restored Profile: $restored_profile"
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes"
                - step:
                    type: Command
                    name: Start Application and Check status
                    identifier: Start_Application_and_Check_status
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Start_Application
                          name: Start Application
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  # Using output variable from last stage
                                  restored_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.rollbackSteps.Rollback_to_previous_pdir_0.output.outputVariables.Restored_profile>"

                                  echo "Restored profile found: $restored_profile"

                                  . "$restored_profile"

                                  # Start the Switch Application
                                  cd $OPRODUCT_ROOT/bin && ksh iststartup.sh 

                                  EOF
                        - identifier: Check_Application_Status
                          name: Check Application Status
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  # Using output variable from last stage
                                  restored_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.rollbackSteps.Rollback_to_previous_pdir_0.output.outputVariables.Restored_profile>"

                                  echo "Restored profile found: $restored_profile"

                                  . "$restored_profile"

                                  sleep 25

                                  echo "Checking Application Status....."

                                  # Check the Switch Application stats
                                  cd $OPRODUCT_ROOT/bin && ksh iststatuscheck.sh

                                  chkProcess=`ps -f -u $LOGNAME | grep -w mbtsk | grep -v grep`;

                                  [ -z "$chkProcess" ] && exit 1

                                  EOF

                                  # Capture the exit status 
                                  exit_status=$?

                                  # Exit with the captured status
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes"
            service:
              useFromStage:
                stage: Set_Up_Environment
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: StageRollback
      - stage:
          name: Pdeploy Execution
          identifier: Pdeploy_Execution
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Validate DB type
                    identifier: Validate_DB_type
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Validate_DB_type
                          name: Validate DB type
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>

                                  HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  # Find the latest pdir and profile
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"

                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[ERROR] Missing latest_pdir or latest_profile ‚Äî skipping clean up db execution."
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir directory: $latest_pdir"
                                  fi

                                  # Source the profile
                                  . "$HOME/$latest_profile"

                                  DB_Vendor="<+stage.variables.Database_vendor>"

                                  DB_Vendor_norm=$(echo "$DB_Vendor" | tr '[:upper:]' '[:lower:]')

                                  installed_packages=$(./build_env -list 2>/dev/null | awk '/installed/ {print $NF}')
                                  echo "Installed packages: $installed_packages"

                                  installed_db=""
                                  printf '%s\n' "$installed_packages" | grep '_ORA-'   >/dev/null 2>&1 && installed_db="oracle"
                                  printf '%s\n' "$installed_packages" | grep '_PGSQL-' >/dev/null 2>&1 && installed_db="pgsql"

                                  if [ -z "$installed_db" ]; then
                                      echo "[WARN] No DB flavor detected in installed packages."
                                  elif [ "$installed_db" = "$DB_Vendor_norm" ]; then
                                      echo "[OK] DB vendor matches: $installed_db"
                                  else
                                      echo "[ERROR] DB vendor mismatch!"
                                      echo "Requested: $DB_Vendor_norm"
                                      echo "Installed: $installed_db"
                                      exit 1
                                  fi

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Command
                    name: Validate Pdeploy DB Details
                    identifier: Validate_Pdeploy_DB_Details
                    spec:
                      onDelegate: true
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Validate_Pdeploy_DB_Details
                          name: Validate Pdeploy DB Details
                          type: Script
                          spec:
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  ########################## Validate DB details ##########################

                                  missing_vars=""

                                  # List DB variables to check
                                  for var_name in DB_server DB_port Database_vendor Database_name Database_user \
                                                Database_password Owner_dbuser Owner_dbpassword Database_tns_name \
                                                Nodeagt_keystore_pass Nodeagt_key_manager_pass Nodeagt_truststore_pass \
                                                Ent_database_vendor Ent_database_name Ent_database_user Ent_database_password \
                                                Ent_schema_name Ent_owner_dbuser Ent_owner_dbpassword Ent_database_tns_name \
                                                Tok_database_vendor Tok_database_name Tok_database_user Tok_database_password \
                                                Tok_schema_name Tok_owner_dbuser Tok_owner_dbpassword Tok_database_tns_name \
                                                Klc_database_vendor Klc_database_name Klc_database_user Klc_database_password \
                                                Klc_schema_name Klc_owner_dbuser Klc_owner_dbpassword Klc_database_tns_name \
                                                keystore_password oas_user oas_pass
                                  do
                                    value=$(eval echo \$$var_name)
                                    if [ -z "$value" ]; then
                                      missing_vars="$missing_vars $var_name"
                                    fi
                                  done

                                  if [ -z "$missing_vars" ]; then
                                    echo "‚úÖ All DB details provided. Proceeding with pipeline..."
                                  else
                                    echo "‚ùå Missing DB credentials for:$missing_vars"
                                    exit 1
                                  fi


                                  ##############DB Variables Validation###############

                                  DB_VENDOR="<+stage.variables.Database_vendor>"
                                  ORACLE_HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.ORACLE_HOME>"
                                  PGSQL_HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.PGSQL_HOME>"

                                  # Validation logic
                                  if [[ "$DB_VENDOR" == "oracle" ]]; then
                                    if [[ -n "$ORACLE_HOME" && "$ORACLE_HOME" != "null" ]]; then
                                      echo "ORACLE_HOME is set: $ORACLE_HOME"
                                    else
                                      echo "Error: ORACLE_HOME must be provided for Oracle database vendor."
                                      exit 1
                                    fi
                                  elif [[ "$DB_VENDOR" == "pgsql" ]]; then
                                    if [[ -n "$PGSQL_HOME" && "$PGSQL_HOME" != "null" ]]; then
                                      echo "PGSQL_HOME is set: $PGSQL_HOME"
                                    else
                                      echo "Error: PGSQL_HOME must be provided for PostgreSQL database vendor."
                                      exit 1
                                    fi
                                  else
                                    echo "Database vendor is neither oracle nor pgsql, skipping checks."
                                  fi
                    timeout: 10m
                - step:
                    type: Command
                    name: Clean Oracle DB
                    identifier: Clean_Oracle_DB
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Clean_Oracle_DB
                          name: Clean Oracle DB
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  # Step 1: Dynamically create .tnsnames.ora using Harness stage variables
                                  tnsnames_content="<+stage.variables.Database_tns_name> =
                                    (DESCRIPTION =
                                      (ADDRESS = (PROTOCOL = TCP)(HOST = <+stage.variables.DB_server>)(PORT = <+stage.variables.DB_port>))
                                      (CONNECT_DATA =
                                        (SERVER = DEDICATED)
                                        (SERVICE_NAME = <+stage.variables.Database_tns_name>)
                                      )
                                    )"

                                  echo "$tnsnames_content" > .tnsnames.ora
                                  chmod 755 .tnsnames.ora
                                  export TNS_ADMIN=$(pwd)
                                  echo "‚úÖ .tnsnames.ora file has been created and content inserted."

                                  # Set up HOME path
                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  echo "HOME PATH is set to $HOME"

                                  # Find the latest pdir and profile
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"

                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[ERROR] Missing latest_pdir or latest_profile ‚Äî skipping clean up db execution."
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir directory: $latest_pdir"
                                  fi

                                  # Source the profile
                                  . "./$latest_profile"

                                  # Step 2: Create DBclean.sql using a here-document
                                  cat <<EOF_SQL > DBclean.sql
                                  BEGIN
                                     FOR cur_rec IN (
                                        SELECT object_name, object_type
                                          FROM user_objects
                                         WHERE object_type IN (
                                                  'TABLE',
                                                  'VIEW',
                                                  'PACKAGE',
                                                  'PROCEDURE',
                                                  'FUNCTION',
                                                  'SEQUENCE'
                                               )
                                     )
                                     LOOP
                                        BEGIN
                                           IF cur_rec.object_type = 'TABLE' THEN
                                              EXECUTE IMMEDIATE 'DROP TABLE "' || cur_rec.object_name || '" CASCADE CONSTRAINTS';
                                           ELSE
                                              EXECUTE IMMEDIATE 'DROP ' || cur_rec.object_type || ' "' || cur_rec.object_name || '"';
                                           END IF;
                                        EXCEPTION
                                           WHEN OTHERS THEN
                                              DBMS_OUTPUT.put_line('FAILED: DROP ' || cur_rec.object_type || ' "' || cur_rec.object_name || '"');
                                        END;
                                     END LOOP;
                                  END;
                                  /

                                  PURGE RECYCLEBIN;
                                  EOF_SQL

                                  echo "‚úÖ DBclean.sql file has been created."

                                  # Step 3: Get TNS name
                                  TNS_NAME="<+stage.variables.Database_tns_name>"

                                  if [ -z "$TNS_NAME" ]; then
                                    echo "‚ùå Error: TNS name not set in environment ($TNS_NAME)"
                                    exit 1
                                  fi

                                  # Step 4: Define DB users as a list of label:user:pass entries
                                  db_users_list="
                                  Database_user:<+stage.variables.Database_user>:<+stage.variables.Database_password>
                                  Ent_database_user:<+stage.variables.Ent_database_user>:<+stage.variables.Ent_database_password>
                                  Tok_database_user:<+stage.variables.Tok_database_user>:<+stage.variables.Tok_database_password>
                                  Klc_database_user:<+stage.variables.Klc_database_user>:<+stage.variables.Klc_database_password>
                                  Owner_dbuser:<+stage.variables.Owner_dbuser>:<+stage.variables.Owner_dbpassword>
                                  Ent_owner_dbuser:<+stage.variables.Ent_owner_dbuser>:<+stage.variables.Ent_owner_dbpassword>
                                  Tok_owner_dbuser:<+stage.variables.Tok_owner_dbuser>:<+stage.variables.Tok_owner_dbpassword>
                                  Klc_owner_dbuser:<+stage.variables.Klc_owner_dbuser>:<+stage.variables.Klc_owner_dbpassword>
                                  "

                                  # Step 5: Loop through each unique DB user and run cleanup
                                  seen_users=""

                                  echo "üîç Parsed DB users:"
                                  for entry in $db_users_list; do
                                    label=$(echo "$entry" | cut -d: -f1)
                                    user=$(echo "$entry" | cut -d: -f2)
                                    pass=$(echo "$entry" | cut -d: -f3)

                                    if [ -z "$user" ] || [ -z "$pass" ]; then
                                      echo "‚ö†Ô∏è Skipping entry due to missing user or password: [$label] user='$user', pass='${pass:+***}'"
                                      continue
                                    fi

                                    echo "‚úÖ [$label] User='$user', Pass='${pass:+***}'"

                                    echo "$seen_users" | grep -q "^$user$"
                                    if [ $? -ne 0 ]; then
                                      echo "üîÑ Cleaning DB for user: $user on TNS: $TNS_NAME"
                                      output=$(sqlplus -s "${user}/${pass}@${TNS_NAME}" @DBclean.sql 2>&1)
                                      echo "$output"

                                      echo "$output" | grep "ORA-" >/dev/null 2>&1
                                      if [ $? -eq 0 ]; then
                                       echo "‚ùå Cleanup failed for $user using TNS: $TNS_NAME"
                                       echo "üëâ Please verify that:"
                                       echo "   - The TNS alias '$TNS_NAME' exists and resolves correctly in .tnsnames.ora"
                                       echo "   - The database listener on <+stage.variables.DB_server>:<+stage.variables.DB_port> is running"
                                       echo "   - The credentials for user '$user' are correct"
                                       exit 1
                                      else
                                        echo "‚úÖ Cleanup completed for $user"
                                      fi
                                      seen_users="$seen_users
                                  $user"
                                    else
                                      echo "‚è≠Ô∏è Skipping duplicate user: $user"
                                    fi
                                  done

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                      condition: <+stage.variables.Database_vendor> == "oracle"
                - step:
                    type: Command
                    name: "Clean Pgsql DB "
                    identifier: Clean_Pgsql_DB
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Clean_Pgsql_DB
                          name: "Clean Pgsql DB "
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Switch user based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  # Find the latest pdir and profile
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"

                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[ERROR] Missing latest_pdir or latest_profile ‚Äî skipping clean up db execution."
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir directory: $latest_pdir"
                                  fi

                                  # Source the profile
                                  . "./$latest_profile"

                                  echo "checking pgsql version.."
                                  psql --version

                                  echo "Current user: $(whoami)"

                                  # DB connection details
                                  DB_NAME="<+stage.variables.Database_name>"
                                  DB_HOST="<+stage.variables.DB_server>"
                                  DB_PORT="<+stage.variables.DB_port>"

                                  # Create output folder
                                  output_dir="pgsql_cleanup_outputs"
                                  [ ! -d "$output_dir" ] && mkdir -p "$output_dir"

                                  # DB users list
                                  db_users_list="
                                  Database_user:<+stage.variables.Database_user>:<+stage.variables.Database_password>
                                  Ent_database_user:<+stage.variables.Ent_database_user>:<+stage.variables.Ent_database_password>
                                  Tok_database_user:<+stage.variables.Tok_database_user>:<+stage.variables.Tok_database_password>
                                  Klc_database_user:<+stage.variables.Klc_database_user>:<+stage.variables.Klc_database_password>
                                  Owner_dbuser:<+stage.variables.Owner_dbuser>:<+stage.variables.Owner_dbpassword>
                                  Ent_owner_dbuser:<+stage.variables.Ent_owner_dbuser>:<+stage.variables.Ent_owner_dbpassword>
                                  Tok_owner_dbuser:<+stage.variables.Tok_owner_dbuser>:<+stage.variables.Tok_owner_dbpassword>
                                  Klc_owner_dbuser:<+stage.variables.Klc_owner_dbuser>:<+stage.variables.Klc_owner_dbpassword>
                                  "

                                  seen_users=""
                                  timestamp=$(date +%d%b%y_%H%M%S)

                                  for entry in $db_users_list; do
                                    label=$(echo "$entry" | cut -d: -f1)
                                    user=$(echo "$entry" | cut -d: -f2)
                                    pass=$(echo "$entry" | cut -d: -f3)

                                    if [ -z "$user" ] || [ -z "$pass" ]; then
                                      echo "‚ö†Ô∏è Skipping $label due to missing credentials"
                                      continue
                                    fi

                                    echo "$seen_users" | grep -q "^$user$"
                                    if [ $? -ne 0 ]; then
                                      echo "üîÑ Processing schema for user: $user"
                                      export PGPASSWORD="$pass"

                                      # Check if schema has any objects
                                      object_count=$(psql -h "$DB_HOST" -p "$DB_PORT" -d "$DB_NAME" -U "$user" -t -c "
                                        SELECT COUNT(*) FROM (
                                          SELECT tablename FROM pg_tables WHERE schemaname = '$user'
                                          UNION
                                          SELECT viewname FROM pg_views WHERE schemaname = '$user'
                                          UNION
                                          SELECT sequencename FROM pg_sequences WHERE schemaname = '$user'
                                        ) AS objects;
                                      " | xargs)

                                      if [ "$object_count" -eq 0 ]; then
                                        echo "‚è≠Ô∏è No objects found for $user ‚Äî skipping file creation."
                                        continue
                                      fi

                                      # Step 1: Create object list
                                      psql -h "$DB_HOST" -p "$DB_PORT" -d "$DB_NAME" -U "$user" -c "\copy (
                                        SELECT * FROM (
                                          SELECT tablename AS object_name, 'table' AS object_type FROM pg_tables WHERE schemaname = '$user'
                                          UNION
                                          SELECT viewname AS object_name, 'view' AS object_type FROM pg_views WHERE schemaname = '$user'
                                          UNION
                                          SELECT sequencename AS object_name, 'sequence' AS object_type FROM pg_sequences WHERE schemaname = '$user'
                                        ) abc
                                      ) TO '$output_dir/object_list_${user}.txt'"

                                      # Step 2: Create DROP script
                                      psql -h "$DB_HOST" -p "$DB_PORT" -d "$DB_NAME" -U "$user" -c "\copy (
                                        SELECT * FROM (
                                          SELECT 'DROP TABLE IF EXISTS \"' || tablename || '\" CASCADE;' AS ddl FROM pg_tables WHERE schemaname = '$user'
                                          UNION
                                          SELECT 'DROP VIEW IF EXISTS \"' || viewname || '\" CASCADE;' AS ddl FROM pg_views WHERE schemaname = '$user'
                                          UNION
                                          SELECT 'DROP SEQUENCE IF EXISTS \"' || sequencename || '\" CASCADE;' AS ddl FROM pg_sequences WHERE schemaname = '$user'
                                        ) abc
                                      ) TO '$output_dir/Objectdrop_${user}.sql'"

                                      echo "‚úÖ [$label] $object_count objects will be dropped for schema: $user"

                                      # Step 3: Execute DROP script
                                      echo "Proceeding with cleanup for $user..."
                                      psql -h "$DB_HOST" -p "$DB_PORT" -d "$DB_NAME" -U "$user" -a -f "$output_dir/Objectdrop_${user}.sql" > "$output_dir/log_${user}_${timestamp}.log" 2>&1

                                      if [ $? -ne 0 ]; then
                                        echo "‚ùå Error during cleanup for $user. Check log: $output_dir/log_${user}_${timestamp}.log"
                                      else
                                        echo "‚úÖ Cleanup completed for $user. Log: $output_dir/log_${user}_${timestamp}.log"
                                      fi

                                      seen_users="$seen_users
                                  $user"
                                    else
                                      echo "‚è≠Ô∏è Skipping duplicate user: $user"
                                    fi
                                  done

                                  echo "‚úÖ Cleanup summary:"
                                  echo "$seen_users"

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                      condition: <+stage.variables.Database_vendor> == "pgsql"
                - step:
                    identifier: pdeploy_execution
                    name: Pdeploy execution
                    type: Command
                    timeout: 1h
                    spec:
                      onDelegate: false
                      commandUnits:
                        - identifier: script_execution
                          name: Pdeploy Execution
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  # Check if Database_vendor is oracle
                                  if [ "<+stage.variables.Database_vendor>" = "oracle" ]; then
                                    # Define the content to be inserted into the .tnsnames.ora file
                                    tnsnames_content="<+stage.variables.Database_tns_name> =
                                      (DESCRIPTION =
                                        (ADDRESS = (PROTOCOL = TCP)(HOST = <+stage.variables.DB_server>)(PORT = <+stage.variables.DB_port>))
                                        (CONNECT_DATA =
                                          (SERVER = DEDICATED)
                                          (SERVICE_NAME = <+stage.variables.Database_tns_name>)
                                        )
                                      )"

                                    # Create the .tnsnames.ora file and insert the content
                                    echo "$tnsnames_content" > .tnsnames.ora

                                    # Set permissions
                                    chmod 755 .tnsnames.ora

                                    # Print a success message
                                    echo ".tnsnames.ora file has been created and content has been inserted."
                                  else
                                    echo "Database vendor is not Oracle. Skipping .tnsnames.ora creation."
                                  fi

                                  #set up HOME path 
                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  # Find the latest pdir directory (without suffix)
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"

                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[ERROR] Missing latest_pdir or latest_profile ‚Äî skipping Pdeploy execution."
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir directory: $latest_pdir"
                                  fi

                                  #Source the profile
                                  . "./$latest_profile"

                                  echo "Pipeline Execution ID: <+pipeline.sequenceId>"

                                  #Removing the existing pdeploy_execution log file
                                  for dir in prot_dir_*; do
                                      [ -d "$dir" ] && rm -rf "$dir"
                                  done
                                  ls pdeploy_automation* 1>/dev/null 2>&1 && rm pdeploy_automation*

                                  cd $latest_pdir/bin 
                                  cmd="./pdeploy"
                                  echo "[INFO] pdeploy Command: $cmd"

                                  /usr/bin/expect <<'EOF2'

                                  set timeout 180
                                  log_file -a "<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/pdeploy_automation_[exec date +%Y%m%d].log"
                                  set env(HOME) "<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  # Terminal control characters
                                  set esc "\x1b"
                                  set up "\x1b\[A"
                                  set down "\x1b\[B"
                                  set enter "\r"

                                  # Logging utility
                                  proc log {level msg} {
                                      puts ">>> $level: $msg"
                                  }

                                  # Auto-detect OS
                                  set os_type [exec uname]
                                  if {[string match "AIX" $os_type]} {
                                      set is_aix 1
                                      log "INFO" "Detected AIX environment"
                                  } else {
                                      set is_aix 0
                                      log "INFO" "Detected non-AIX environment (assumed RHEL)"
                                  }

                                  # Escape regex special characters
                                  proc escape_regex {str} {
                                      regsub -all {([][(){}.+*?^$\\|])} $str {\\\1} str
                                      return $str
                                  }

                                  # Clear field using backspaces or DELs
                                  proc clear_field {backspaces} {
                                      log "INFO" "Clearing field with $backspaces characters"
                                      for {set i 0} {$i < $backspaces} {incr i} {
                                          if {$::is_aix} {
                                              send "\177"
                                          } else {
                                              send "\b"
                                          }
                                          sleep 0.1
                                      }
                                  }

                                  # Navigate to a menu item
                                  proc navigate_to {menu_item} {
                                      global down enter
                                      set max_attempts 30
                                      set attempts 0
                                      set escaped_item [escape_regex $menu_item]
                                      set pattern [format {(?i)%s} $escaped_item]

                                      expect {
                                          -re $pattern {
                                              send "$enter"
                                              return 1
                                          }
                                          timeout {
                                              while {$attempts < $max_attempts} {
                                                  send "$down"
                                                  sleep 1
                                                  expect {
                                                      -re $pattern {
                                                          send "$enter"
                                                          return 1
                                                      }
                                                      timeout {
                                                          incr attempts
                                                      }
                                                  }
                                              }
                                          }
                                      }

                                      log "ERROR" "Failed to find menu item: $menu_item"
                                      return 0
                                  }

                                  # Return to main menu
                                  proc go_back_to_main_menu {} {
                                      global esc
                                      set max_attempts 5
                                      set attempts 0
                                      while {$attempts < $max_attempts} {
                                          send "$esc$esc"
                                          sleep 1
                                          expect {
                                              -re "Apply System Parameters" {
                                                  return 1
                                              }
                                              timeout {
                                                  incr attempts
                                              }
                                          }
                                      }
                                      log "ERROR" "Failed to return to main menu"
                                      return 0
                                  }

                                  # Perform a step with confirmation prompts
                                  proc perform_step {menu_item confirm_prompts} {
                                      global enter esc

                                      if {![navigate_to $menu_item]} {
                                          log "ERROR" "Failed to navigate to $menu_item"
                                          exit 1
                                      }

                                      foreach prompt $confirm_prompts {
                                          expect {
                                              -re $prompt {
                                                  send "y$enter"
                                                  sleep 1
                                              }
                                              timeout {
                                                  log "ERROR" "Timeout waiting for confirmation prompt: $prompt"
                                                  exit 1
                                              }
                                          }
                                      }

                                      expect {
                                          -re "DONE.*RETURN TO MENU" {
                                              send "$esc$esc"
                                              sleep 1
                                          }
                                          timeout {
                                              log "ERROR" "Timeout waiting for DONE message"
                                              exit 1
                                          }
                                      }
                                  }

                                  # Enter parameters into fields
                                  proc enter_parameters {params} {
                                      global enter

                                      set fields_to_clear {
                                          "Site_id" "Nodeagt_use_tls" "Ent_use_tls" "Tok_use_tls"
                                          "Ent_database_vendor" "Ent_database_name" "Ent_database_user"
                                          "Ent_database_password" "Ent_confirm_db_pwd" "Ent_schema_name"
                                          "Ent_owner_dbuser" "Ent_owner_dbpassword" "Ent_owner_dbpassword_confirm"
                                          "Ent_database_tns_name" "Tok_database_vendor" "Tok_database_name"
                                          "Tok_database_user" "Tok_database_password" "Tok_confirm_db_pwd"
                                          "Tok_schema_name" "Tok_owner_dbuser" "Tok_owner_dbpassword"
                                          "Tok_owner_dbpassword_confirm" "Tok_database_tns_name"
                                          "Klc_database_vendor" "Klc_database_name" "Klc_database_user"
                                          "Klc_database_password" "Klc_confirm_db_pwd" "Klc_schema_name"
                                          "Klc_owner_dbuser" "Klc_owner_dbpassword" "Klc_owner_dbpassword_confirm"
                                          "Klc_database_tns_name"
                                      }

                                      array set field_clear_strategy {
                                          "Ent_schema_name" 70
                                          "Ent_owner_dbuser" 70
                                          "Ent_owner_dbpassword" 70
                                          "Ent_owner_dbpassword_confirm" 70
                                          "Ent_database_tns_name" 70
                                          "Ent_database_password" 70
                                          "Ent_confirm_db_pwd" 70
                                          "Ent_use_tls" 20
                                          "Tok_database_tns_name" 70
                                          "Klc_database_tns_name" 70
                                      }

                                      foreach {prompt value} $params {
                                          log "INFO" "Processing field: $prompt"
                                          set escaped_prompt [escape_regex $prompt]
                                          set pattern [format {(?i)%s\s*\[} $escaped_prompt]

                                          expect {
                                              -re $pattern {
                                                  log "INFO" "Matched prompt: $prompt"

                                                  if {[lsearch -exact $fields_to_clear $prompt] != -1} {
                                                      set backspaces 30
                                                      if {[info exists field_clear_strategy($prompt)]} {
                                                          set backspaces $field_clear_strategy($prompt)
                                                      }

                                                      clear_field $backspaces
                                                      sleep 2
                                                  }

                                                  log "DEBUG" "Sending value to $prompt: '$value'"
                                                  send "$value$enter"
                                                  sleep 0.3
                                              }
                                              timeout {
                                                  log "ERROR" "Timeout waiting for prompt: $prompt"
                                                  exit 1
                                              }
                                          }
                                      }
                                  }

                                  set system_params {
                                      "Site_id" "<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Site_id>"
                                      "Product_name" "switch"
                                      "Node_name" "<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Node_name>"
                                      "Int_host_name" ""
                                      "Ext_host_name" ""
                                      "Database_vendor" "<+stage.variables.Database_vendor>"
                                      "Database_name" "<+stage.variables.Database_name>"
                                      "Database_user" "<+stage.variables.Database_user>"
                                      "Database_password" "<+stage.variables.Database_password>"
                                      "Confirm_db_pwd" "<+stage.variables.Database_password>"
                                      "Schema_name" "<+stage.variables.Owner_dbuser>"
                                      "Owner_dbuser" "<+stage.variables.Owner_dbuser>"
                                      "Owner_dbpassword" "<+stage.variables.Owner_dbpassword>"
                                      "Owner_dbpassword_confirm" "<+stage.variables.Owner_dbpassword>"
                                      "Database_tns_name" "<+stage.variables.Database_tns_name>"
                                      "Tablespace" ""
                                      "Index_tablespace" ""
                                      "Lob_tablespace" ""
                                      "Institution_id" ""
                                      "Inst_type" "fi MAIN"
                                      "Inst_name" "fi"
                                      "Inst_curr_code" "840"
                                      "System_cntry_code" "840"
                                      "Protected_directory" "<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/prot_dir_<+pipeline.sequenceId>"
                                      "Short_db_names" ""
                                      "Mas_trace_level" ""
                                      "Nbr_of_fr_servers" ""
                                      "Nbr_of_val_servers" ""
                                      "Nbr_of_vld_servers" ""
                                      "Nbr_of_fee_servers" ""
                                      "Nbr_of_post_servers" ""
                                      "Mas_tax_dbuserid" ""
                                      "Mas_tax_dbpassword" ""
                                      "Mas_tax_confirm_db_pwd" ""
                                      "Api_server_port" ""
                                      "Db_pool_init" ""
                                      "Db_pool_num" ""
                                      "Api_pool_init" ""
                                      "Api_pool_num" ""
                                      "Guiserver_port" ""
                                      "Nodeagt_msg_port" ""
                                      "Nodeagt_ctrl_port" ""
                                      "Nodeagt_msg_timeout" ""
                                      "Nodeagt_otracelevel" ""
                                      "Nodeagt_root_trace_level" ""
                                      "Nodeagt_use_tls" "y"
                                      "Nodeagt_keystore_pass" "<+stage.variables.Nodeagt_keystore_pass>"
                                      "Nodeagt_confirm_ks_pass" "<+stage.variables.Nodeagt_keystore_pass>"
                                      "Nodeagt_key_manager_pass" "<+stage.variables.Nodeagt_key_manager_pass>"
                                      "Nodeagt_confirm_km_pass" "<+stage.variables.Nodeagt_key_manager_pass>"
                                      "Nodeagt_truststore_pass" "<+stage.variables.Nodeagt_truststore_pass>"
                                      "Nodeagt_confirm_ts_pass" "<+stage.variables.Nodeagt_truststore_pass>"
                                      "Nodeagt_need_client_auth" ""
                                  }

                                  spawn ./pdeploy

                                  expect {
                                      -re "Install Server" {
                                          sleep 1
                                          if {![navigate_to "Install Server"]} { exit 1 }
                                          sleep 1
                                      }
                                      timeout { log "ERROR" "Timeout at main menu"; exit 1 }
                                  }

                                  expect {
                                      -re "Install Product" {
                                          sleep 1
                                          if {![navigate_to "Install Product"]} { exit 2 }
                                          sleep 1
                                      }
                                      timeout { log "ERROR" "Timeout at product menu"; exit 2 }
                                  }

                                  expect {
                                      -re "Setup System Parameters" {
                                          sleep 1
                                          send "$enter"
                                          enter_parameters $system_params
                                      }
                                  }

                                  if {![go_back_to_main_menu]} {
                                      exit 5
                                  }
                                  send "$down"
                                  perform_step "Apply System Parameters" {"Are you sure you want to apply the system parameters.*" "Confirm.*"}
                                  send "$down$down"
                                  perform_step "Prepare DB Scripts" {"Proceed with Prepare DB Script.*"}
                                  send "$down"

                                  set timeout 1500

                                  perform_step "Create DB Tables" {"Are you sure you want to create/append Product DB.*"}
                                  send "$down"

                                  # Reset timeout
                                  set timeout 180

                                  perform_step "Create DB Grant" {"Are you sure you want to create DB Grant.*"}
                                  send "$down"

                                  # Before long step
                                  set timeout 3000

                                  perform_step "Insert DB System Records" {"Are you sure.*insert DB records.*"}
                                  send "$down"

                                  # Reset timeout
                                  set timeout 180

                                  perform_step "Insert DB Inst Base Records" {"Are you sure.*insert DB records.*"}
                                  send "$down$down$down"
                                  perform_step "Register Site" {}
                                  send "$down"
                                  # perform_step "Register Node" {"Confirm"}
                                  if {![navigate_to "Register Node"]} {
                                      log "ERROR" "Failed to navigate to Register Node"
                                      exit 1
                                  }

                                  expect {
                                      -re "Confirm.*" {
                                          send "y$enter"
                                          sleep 1

                                          # Handle optional second prompt
                                          expect {
                                              -re "Add Node:.*on iHost:.*\\(y/n\\).*" {
                                                  send "y$enter"
                                                  sleep 1

                                                  # Wait for final message
                                                  expect {
                                                      -re ".*PRESS ANY KEY TO RETURN TO MENU.*" {
                                                          send "$enter"
                                                          sleep 1
                                                      }
                                                      timeout {
                                                          log "ERROR" "Timeout waiting for return to menu prompt"
                                                          exit 1
                                                      }
                                                  }
                                              }
                                              -re ".*PRESS ANY KEY TO RETURN TO MENU.*" {
                                                  send "$enter"
                                                  sleep 1
                                              }
                                              timeout {
                                                  log "INFO" "No additional prompt after confirmation"
                                              }
                                          }
                                      }
                                      timeout {
                                          log "ERROR" "Timeout waiting for 'Confirm' prompt"
                                          exit 1
                                      }
                                  }

                                  send "$down$down"
                                  perform_step "List Site" {}
                                  send "$down"
                                  perform_step "List Node" {}

                                  # Return to main menu after final step
                                  if {![go_back_to_main_menu]} {
                                      exit 6
                                  }

                                  send "$down"
                                  sleep 1
                                  send "$enter"

                                  #Install Entitlement 

                                  set entitlement_params {
                                      "Ent_database_vendor" "<+stage.variables.Ent_database_vendor>"
                                      "Ent_database_name" "<+stage.variables.Ent_database_name>"
                                      "Ent_database_user" "<+stage.variables.Ent_database_user>"
                                      "Ent_database_password" "<+stage.variables.Ent_database_password>"
                                      "Ent_confirm_db_pwd" "<+stage.variables.Ent_database_password>"
                                      "Ent_schema_name" "<+stage.variables.Ent_schema_name>"
                                      "Ent_owner_dbuser" "<+stage.variables.Ent_owner_dbuser>"
                                      "Ent_owner_dbpassword" "<+stage.variables.Ent_owner_dbpassword>"
                                      "Ent_owner_dbpassword_confirm" "<+stage.variables.Ent_owner_dbpassword>"
                                      "Ent_database_tns_name" "<+stage.variables.Ent_database_tns_name>"
                                      "Tablespace" ""
                                      "Index_tablespace" ""
                                      "Lob_tablespace" ""
                                      "Ent_port" ""
                                      "Ent_use_tls" "y"
                                      "Ent_authenticate_peer" ""
                                      "Security_host" ""
                                      "Auth_port" ""
                                      "Auth_control_host" ""
                                      "Auth_control_port" ""
                                      "Auth_encoding_transition" ""
                                      "Auth_min_password_length" ""
                                      "Auth_password_no_numeric_suffix" ""
                                      "Auth_password_no_numeric_prefix" ""
                                      "Auth_password_no_repeated_chars" ""
                                      "Auth_password_no_user_id" ""
                                      "Auth_password_history_depth" ""
                                      "Auth_use_tls" ""
                                      "Auth_authenticate_peer" ""
                                  }

                                  expect {
                                      -re "Setup System Parameters" {
                                          sleep 1
                                          send "$enter"
                                          enter_parameters $entitlement_params
                                      }
                                  }

                                  if {![go_back_to_main_menu]} {
                                      exit 5
                                  }

                                  send "$down"
                                  perform_step "Apply System Parameters" {"Are you sure you want to apply the system parameters.*"}
                                  send "$down"
                                  perform_step "Prepare DB Scripts" {"Proceed with Prepare DB Script.*"}
                                  send "$down"
                                  perform_step "Create DB Tables" {"Are you sure you want to create/append Entitlement DB.*"}
                                  send "$down"
                                  perform_step "Create DB Grant" {"Are you sure you want to create DB Grant.*"}
                                  send "$down"

                                  if {![navigate_to "Insert DB System Records"]} {
                                      log "ERROR" "Failed to navigate to Insert DB System Records"
                                      exit 1
                                  }

                                  # Wait for either login prompt or return-to-menu message
                                  expect {
                                      -re ".*Enter user name.*" {
                                          log "INFO" "Login prompt detected"
                                          send "<+stage.variables.oas_user>\r"
                                          expect -re ".*Enter password.*"
                                          send "<+stage.variables.oas_pass>\r"
                                          expect -re ".*Verifying - Enter password.*"
                                          send "<+stage.variables.oas_pass>\r"
                                          sleep 1
                                          exp_continue
                                      }
                                      -re ".*Are you sure you want to insert DB records.*" {
                                          log "INFO" "Insert DB records confirmation prompt detected"
                                          send "y\r"
                                          exp_continue
                                      }
                                      -re ".*PRESS ANY KEY TO RETURN TO MENU.*" {
                                          send "$enter"
                                          sleep 1
                                      }
                                      timeout {
                                          log "INFO" "No expected prompt appeared, continuing..."
                                      }
                                  }

                                  if {![go_back_to_main_menu]} {
                                      exit 5
                                  }

                                  send "$down"
                                  sleep 0.5
                                  send "$enter"

                                  #Install Tokenizer
                                  set tokenizer_params {
                                      "Start_tokenizer" ""
                                      "Tok_database_vendor" "<+stage.variables.Tok_database_vendor>"
                                      "Tok_database_name" "<+stage.variables.Tok_database_name>"
                                      "Tok_database_user" "<+stage.variables.Tok_database_user>"
                                      "Tok_database_password" "<+stage.variables.Tok_database_password>"
                                      "Tok_confirm_db_pwd" "<+stage.variables.Tok_database_password>"
                                      "Tok_schema_name" "<+stage.variables.Tok_schema_name>"
                                      "Tok_owner_dbuser" "<+stage.variables.Tok_owner_dbuser>"
                                      "Tok_owner_dbpassword" "<+stage.variables.Tok_owner_dbpassword>"
                                      "Tok_owner_dbpassword_confirm" "<+stage.variables.Tok_owner_dbpassword>"
                                      "Tok_database_tns_name" "<+stage.variables.Tok_database_tns_name>"
                                      "Tablespace" ""
                                      "Index_tablespace" ""
                                      "Tok_idle_timeout" ""
                                      "Tok_sess_timeout" ""
                                      "Tok_timeout" ""
                                      "Tok_max_client" ""
                                      "Tok_standalone" ""
                                      "Tok_use_tls" "y"
                                      "Tok_server_mbox" ""
                                      "Tok_host" ""
                                      "Tok_port" ""
                                      "Tok_server_cert_file" ""
                                      "Tok_server_key_pwd_file" ""
                                      "Tok_server_key_file" ""
                                      "Tok_ca_cert_file" ""
                                      "Tok_otracelevel" ""
                                      "Tok_comm_debug" ""
                                  }

                                  expect {
                                      -re "Setup System Parameters" {
                                          sleep 1
                                          send "$enter"
                                          enter_parameters $tokenizer_params
                                      }
                                  }

                                  if {![go_back_to_main_menu]} {
                                      exit 5
                                  }

                                  send "$down"

                                  perform_step "Apply System Parameters" {"Are you sure you want to apply the system parameters.*"}
                                  send "$down"
                                  perform_step "Prepare DB Scripts" {"Proceed with Prepare DB Script.*"}
                                  send "$down"
                                  perform_step "Create DB Tables" {"Are you sure you want to create/append Tokenizer DB.*"}
                                  send "$down"
                                  perform_step "Create DB Grant" {"Are you sure you want to create DB Grant.*"}
                                  send "$down"
                                  perform_step "Insert DB System Records" {".*PRESS ANY KEY TO RETURN TO.*"}

                                  if {![go_back_to_main_menu]} {
                                      exit 5
                                  }

                                  send "$down"
                                  sleep 0.5
                                  send "$enter"

                                  #Install Key Life Cycle

                                  set klc_params {
                                      "Klc_database_vendor" "<+stage.variables.Klc_database_vendor>"
                                      "Klc_database_name" "<+stage.variables.Klc_database_name>"
                                      "Klc_database_user" "<+stage.variables.Klc_database_user>"
                                      "Klc_database_password" "<+stage.variables.Klc_database_password>"
                                      "Klc_confirm_db_pwd" "<+stage.variables.Klc_database_password>"
                                      "Klc_schema_name" "<+stage.variables.Klc_schema_name>"
                                      "Klc_owner_dbuser" "<+stage.variables.Klc_owner_dbuser>"
                                      "Klc_owner_dbpassword" "<+stage.variables.Klc_owner_dbpassword>"
                                      "Klc_owner_dbpassword_confirm" "<+stage.variables.Klc_owner_dbpassword>"
                                      "Klc_database_tns_name" "<+stage.variables.Klc_database_tns_name>"
                                      "Tablespace" ""
                                      "Index_tablespace" ""
                                      "Klc_otracelevel" ""
                                  }

                                  expect {
                                      -re "Setup System Parameters" {
                                          sleep 1
                                          send "$enter"
                                          enter_parameters $klc_params
                                      }
                                  }

                                  if {![go_back_to_main_menu]} {
                                      exit 6
                                  }

                                  send "$down"

                                  perform_step "Apply System Parameters" {"Are you sure you want to apply the system parameters.*"}
                                  send "$down"
                                  perform_step "Prepare DB Scripts" {"Proceed with Prepare DB Script.*"}
                                  send "$down"
                                  perform_step "Create DB Tables" {"Are you sure you want to create/append Key Life Cycle DB.*"}
                                  send "$down"
                                  perform_step "Create DB Grant" {"Are you sure you want to create DB Grant.*"}
                                  send "$down"
                                  perform_step "Insert DB System Records" {"Are you sure you want to insert DB records.*"}

                                  if {![go_back_to_main_menu]} {
                                      exit 7
                                  }

                                  send "$down"
                                  sleep 0.5
                                  send "$enter"

                                  # Enable TLS

                                  #0. Generate and Export APP Certificates 
                                  #1. Import Certificates for APP   

                                  if {![navigate_to "Generate and Export APP Certificates"]} {
                                      log "ERROR" "Failed to navigate to Generate and Export APP Certificates"
                                      exit 1
                                  }

                                  expect {
                                      -re "Certificate files will be deleted.*proceed.*\\(y/n\\)" {
                                          send "y\r"
                                          sleep 1
                                      }
                                      timeout {
                                          log "ERROR" "Timeout waiting for certificate deletion confirmation"
                                          exit 1
                                      }
                                  }

                                  expect {
                                      -re "Customer Organization:" {
                                          send "fi\r"
                                          sleep 0.5
                                      }
                                  }

                                  expect {
                                      -re "File Suffix.*:" {
                                          send "\r"
                                          sleep 0.5
                                      }
                                  }

                                  set timeout 15
                                  set keystore_password "<+stage.variables.keystore_password>"

                                  # Initial keystore password prompt
                                  expect {
                                      -re "Enter keystore password:" {
                                          send "$keystore_password\r"
                                          sleep 0.5
                                      }
                                  }

                                  # Re-enter password
                                  expect {
                                      -re "Re-enter new password:" {
                                          send "$keystore_password\r"
                                          sleep 0.5
                                      }
                                  }

                                  # Optional "same as keystore" prompt
                                  expect {
                                      -re "Enter key password for.*same as keystore.*" {
                                          send "$keystore_password\r"
                                          sleep 0.5
                                          expect {
                                              -re "Re-enter new password:" {
                                                  send "$keystore_password\r"
                                                  sleep 0.5
                                              }
                                              timeout {
                                                  # If re-entry prompt doesn't appear, continue
                                              }
                                          }
                                      }
                                      timeout {
                                          # If "same as keystore" doesn't appear, continue
                                      }
                                  }

                                  # Final keystore password prompt (during PKCS12 conversion or PEM export)
                                  expect {
                                      -re "Enter keystore password:" {
                                          send "$keystore_password\r"
                                          sleep 0.5
                                      }
                                      timeout {
                                          # Optional, may not appear depending on flow
                                      }
                                  }

                                  # Optional final confirmation
                                  expect {
                                      -re "DONE.*RETURN TO MENU" {
                                          send "\r"
                                          sleep 1
                                      }
                                      timeout {
                                          # No menu prompt, continue silently
                                      }
                                  }


                                  EOF2

                                  EOF
                      environmentVariables: []
                      outputVariables: []
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                - step:
                    type: Command
                    name: Execute Ora Triggers
                    identifier: Execute_Ora_Triggers
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Execute_Ora_Triggers
                          name: Execute Ora Triggers
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh
                                  set -e  # Exit on script-level errors

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  # Get latest profile and pdir
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"

                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[ERROR] Missing latest_pdir or latest_profile ‚Äî skipping DB cleanup."
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir directory: $latest_pdir"
                                  fi

                                  # Source the profile
                                  . "./$latest_profile"

                                  cd "$latest_pdir/sql_scripts/" || exit 1

                                  echo "Listing available scripts (excluding .pgsql):"
                                  ls -1 | grep -E '\.ora$|\.sql$' | grep -v '\.pgsql$'

                                  # Get TNS name
                                  TNS_NAME="<+stage.variables.Database_tns_name>"
                                  if [ -z "$TNS_NAME" ]; then
                                    echo "‚ùå Error: TNS name not set in environment ($TNS_NAME)"
                                    exit 1
                                  fi

                                  # App user credentials
                                  user="<+stage.variables.Database_user>"
                                  pass="<+stage.variables.Database_password>"

                                  # Owner user credentials
                                  owner_dbuser="<+stage.variables.Owner_dbuser>"
                                  owner_dbpass="<+stage.variables.Owner_dbpassword>"

                                  # Build dynamic list of scripts
                                  scripts=$(ls -1 | grep -E '\.ora$|\.sql$' | grep -v '\.pgsql$')

                                  [ -f producer_cat.sql ] && \
                                  grep -v '^#' producer_cat.sql | grep -v '^#pragma' | grep -v '^[[:space:]]*$' | \
                                  awk '/values/ { if ($0 !~ /;$/) $0=$0";" } /commit/ { if ($0 !~ /;$/) $0=$0";" } { print }' > producer_cat_tmp.sql && \
                                  mv producer_cat_tmp.sql producer_cat.sql

                                  # Function to run scripts for a given user
                                  run_scripts_for_user() {
                                    dbuser=$1
                                    dbpass=$2
                                    dbalias=$3

                                    echo "Executing scripts for user: $dbuser"

                                    for file in $scripts; do
                                      if [ ! -s "$file" ]; then
                                        echo "Skipping empty file: $file"
                                        continue
                                      fi

                                      echo "----------------------------------------"
                                      echo "Running $file for user $dbuser..."
                                      echo "----------------------------------------"

                                      # Execute script and show all output in pipeline logs
                                      sqlplus -s "${dbuser}/${dbpass}@${dbalias}" <<SQL
                                  SET DEFINE OFF
                                  SET FEEDBACK ON
                                  SET HEADING ON
                                  SET TERMOUT ON
                                  WHENEVER SQLERROR CONTINUE
                                  PROMPT >>> Starting script: $file
                                  @$file
                                  PROMPT >>> Completed script: $file
                                  EXIT
                                  SQL

                                      if [ $? -ne 0 ]; then
                                        echo "‚ö† Warning: Error executing $file for user $dbuser (continuing)"
                                      fi
                                    done
                                  }

                                  # Run for app user
                                  run_scripts_for_user "$user" "$pass" "$TNS_NAME"

                                  # Run for owner user only if different
                                  if [ "$owner_dbuser" != "$user" ]; then
                                    echo "Owner user ($owner_dbuser) is different from app user ($user). Executing scripts for both."
                                    run_scripts_for_user "$owner_dbuser" "$owner_dbpass" "$TNS_NAME"
                                  else
                                    echo "Owner user and app user are same ($user). Skipping second execution."
                                  fi

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                      condition: <+stage.variables.Database_vendor> == "oracle"
                - step:
                    type: Command
                    name: Execute Pgsql Triggers
                    identifier: Execute_Pgsql_Triggers
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Execute_Pgsql_Triggers
                          name: Execute Pgsql Triggers
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh
                                  set -e  # Exit on script-level errors

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  # Get latest profile and pdir
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"

                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[ERROR] Missing latest_pdir or latest_profile ‚Äî skipping DB cleanup."
                                      exit 1
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir directory: $latest_pdir"
                                  fi

                                  # Source the profile
                                  . "./$latest_profile"

                                  cd "$latest_pdir/sql_scripts/" || exit 1

                                  echo "Listing available scripts (excluding .ora):"
                                  ls -1 | grep -E '\.pgsql$|\.sql$' | grep -v '\.ora$'

                                  # PostgreSQL connection details
                                  DB_HOST="<+stage.variables.DB_server>"
                                  DB_PORT="<+stage.variables.DB_port>"
                                  DB_NAME="<+stage.variables.Database_name>"

                                  if [ -z "$DB_HOST" ] || [ -z "$DB_PORT" ] || [ -z "$DB_NAME" ]; then
                                    echo "‚ùå Error: Database connection details missing"
                                    exit 1
                                  fi

                                  # App user credentials
                                  user="<+stage.variables.Database_user>"
                                  pass="<+stage.variables.Database_password>"

                                  # Owner user credentials
                                  owner_dbuser="<+stage.variables.Owner_dbuser>"
                                  owner_dbpass="<+stage.variables.Owner_dbpassword>"

                                  # Build dynamic list of scripts
                                  scripts=$(ls -1 | grep -E '\.pgsql$|\.sql$' | grep -v '\.ora$')

                                  [ -f producer_cat.sql ] && \
                                  grep -v '^#' producer_cat.sql | grep -v '^#pragma' | grep -v '^[[:space:]]*$' | \
                                  awk '/values/ { if ($0 !~ /;$/) $0=$0";" } /commit/ { if ($0 !~ /;$/) $0=$0";" } { print }' > producer_cat_tmp.sql && \
                                  mv producer_cat_tmp.sql producer_cat.sql

                                  # Function to run scripts for a given user
                                  run_scripts_for_user() {
                                    dbuser=$1
                                    dbpass=$2

                                    echo "Executing scripts for user: $dbuser"

                                    export PGPASSWORD="$dbpass"

                                    for file in $scripts; do
                                      if [ ! -s "$file" ]; then
                                        echo "Skipping empty file: $file"
                                        continue
                                      fi

                                      echo "----------------------------------------"
                                      echo "Running $file for user $dbuser..."
                                      echo "----------------------------------------"

                                      psql -h "$DB_HOST" -p "$DB_PORT" -U "$dbuser" -d "$DB_NAME" -f "$file"

                                      if [ $? -ne 0 ]; then
                                        echo "‚ö† Warning: Error executing $file for user $dbuser (continuing)"
                                      fi
                                    done
                                  }

                                  # Run for app user
                                  run_scripts_for_user "$user" "$pass"

                                  # Run for owner user only if different
                                  if [ "$owner_dbuser" != "$user" ]; then
                                    echo "Owner user ($owner_dbuser) is different from app user ($user). Executing scripts for both."
                                    run_scripts_for_user "$owner_dbuser" "$owner_dbpass"
                                  else
                                    echo "Owner user and app user are same ($user). Skipping second execution."
                                  fi

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                      condition: <+stage.variables.Database_vendor> == "pgsql"
              rollbackSteps:
                - step:
                    type: Email
                    name: App install rollback email
                    identifier: App_install_rollback_email
                    spec:
                      to: <+pipeline.variables.NOTIFY_TO>
                      cc: <+pipeline.variables.NOTIFY_CC>
                      subject: Rollback notification <+pipeline.name>
                      body: |
                        <!DOCTYPE html>
                        <html>
                          <body style="font-family: Arial, sans-serif; background-color: #e9f1f7; padding: 20px; color: #2c3e50;">
                            <div style="max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 10px; padding: 20px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);">
                              <h2 style="color: #d9534f; border-bottom: 2px solid #dc3545; padding-bottom: 10px;">Harness Pipeline Failed</h2>
                              <p>Dear Team,</p>
                              <p>The <strong><+pipeline.name>;</strong> execution encountered a failure at stage <strong><+stage.name>;</strong>.</p>

                              <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Project Name</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><+project.name></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Pipeline Name</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong><+pipeline.name></strong></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Failed Stage</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong><+stage.name></strong></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Status</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong>Failed</strong></td>
                                </tr>
                              </table>

                              <p style="margin-top: 20px;">
                                Failed Pipeline Link: 
                                <a href="<+pipeline.executionUrl>" style="background-color: #dc3545; color: white; padding: 10px 15px; text-decoration: none; border-radius: 5px;">View Pipeline Execution</a>
                              </p>

                              <p style="margin-top: 20px; font-weight: bold; color: #d9534f;">
                                Rollback with previous pdir will be executed.
                              </p>

                              <p style="margin-top: 20px;">Regards,<br/>CICD Team</p>

                              <p style="font-size: 12px; color: #6c757d; margin-top: 30px;">
                                This is an automated email generated by the Harness pipeline. Please do not reply to this email.
                              </p>
                            </div>
                          </body>
                        </html>
                    timeout: 10m
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
                - step:
                    type: HarnessApproval
                    name: Rollback Approval
                    identifier: Rollback_Approval
                    spec:
                      approvalMessage: Please review the following information and approve the pipeline progression
                      includePipelineExecutionHistory: true
                      isAutoRejectEnabled: false
                      approvers:
                        userGroups: <+input>.selectOneFrom(org.SW_Dev_Approvers,org.SW_QC_Approvers)
                        minimumCount: 1
                        disallowPipelineExecutor: false
                      approverInputs: []
                    timeout: 1d
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
                - step:
                    type: Command
                    name: Rollback to previous pdir
                    identifier: Rollback_to_previous_pdir
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables:
                        - name: Restored_profile
                          type: String
                          value: restored_profile
                      commandUnits:
                        - identifier: Rollback
                          name: Rollback
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  set -e

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  INSTALL_DIR="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  BACKUP_VARS="$INSTALL_DIR/backup_vars.env"

                                  export HOME="$INSTALL_DIR"

                                  echo "HOME is set to: $HOME"

                                  # Load backup variables
                                  if [ ! -f "$BACKUP_VARS" ]; then
                                      echo "[ERROR] Backup variables file not found!"
                                      exit 1
                                  fi

                                  . "$BACKUP_VARS"

                                  # Verify backup variables
                                  if [ -z "$BACKUP_DIR" ] || [ -z "$BACKUP_PDIR" ] || [ -z "$BACKUP_PROFILE" ]; then
                                      echo "[ERROR] Backup variables are not set correctly!"
                                      exit 1
                                  fi

                                  # Verify archive
                                  if [ ! -f "$BACKUP_ARCHIVE" ]; then
                                      echo "[ERROR] Backup archive not found!"
                                      exit 1
                                  fi

                                  # Validate archive based on OS
                                  if [ "$(uname)" = "AIX" ]; then
                                      if ! gunzip -c "$BACKUP_ARCHIVE" | tar -tf - >/dev/null; then
                                          echo "[ERROR] Backup archive is corrupt!"
                                          exit 1
                                      fi
                                  else
                                      if ! tar -tzf "$BACKUP_ARCHIVE" >/dev/null; then
                                          echo "[ERROR] Backup archive is corrupt!"
                                          exit 1
                                      fi
                                  fi

                                  # Remove existing files
                                  if [ -d "$INSTALL_DIR/$(basename "$BACKUP_PDIR")" ]; then
                                      echo "[INFO] Removing existing pdir directory: $(basename "$BACKUP_PDIR")"
                                      rm -rf "$INSTALL_DIR/$(basename "$BACKUP_PDIR")"
                                  fi

                                  if [ -f "$INSTALL_DIR/$(basename "$BACKUP_PROFILE")" ]; then
                                      echo "[INFO] Removing existing profile file: $(basename "$BACKUP_PROFILE")"
                                      rm -f "$INSTALL_DIR/$(basename "$BACKUP_PROFILE")"
                                  fi

                                  # Remove prot_dir if it was backed up
                                  if [ -n "$BACKUP_PROT_DIR" ] && [ -d "$INSTALL_DIR/prot_dir" ]; then
                                      echo "[INFO] Removing existing prot_dir directory"
                                      rm -rf "$INSTALL_DIR/prot_dir"
                                  fi

                                  # Extract backup
                                  echo "[INFO] Extracting backup archive..."
                                  if [ "$(uname)" = "AIX" ]; then
                                      gunzip -c "$BACKUP_ARCHIVE" | tar -xvf - -C "$INSTALL_DIR"
                                  else
                                      tar -xzf "$BACKUP_ARCHIVE" -C "$INSTALL_DIR"
                                  fi

                                  restored_profile="$INSTALL_DIR/$(basename "$BACKUP_PROFILE")"

                                  # Verify restoration
                                  if [ ! -d "$INSTALL_DIR/$(basename "$BACKUP_PDIR")" ] || [ ! -f "$restored_profile" ]; then
                                      echo "[ERROR] Rollback verification failed"
                                      exit 1
                                  fi

                                  if [ -n "$BACKUP_PROT_DIR" ] && [ ! -d "$INSTALL_DIR/prot_dir" ]; then
                                      echo "[ERROR] prot_dir restoration failed"
                                      exit 1
                                  fi

                                  echo "[SUCCESS] Restoration completed successfully"

                                  # Write latest_profile to a temporary file
                                  echo "$restored_profile" > output_variable.txt

                                  EOF

                                  # Read latest_profile from the temporary file
                                  restored_profile=$(cat output_variable.txt)
                                  echo "Restored Profile: $restored_profile"
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
                - step:
                    type: Command
                    name: Start Application and Check status
                    identifier: Start_Application_and_Check_status
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Start_Application
                          name: Start Application
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  # Using output variable from last stage
                                  restored_profile="<+pipeline.stages.Pdeploy_Execution.spec.execution.rollbackSteps.Rollback_to_previous_pdir_0.output.outputVariables.Restored_profile>"

                                  echo "Restored profile found: $restored_profile"

                                  . "$restored_profile"

                                  # Start the Switch Application
                                  cd $OPRODUCT_ROOT/bin && ksh iststartup.sh 

                                  EOF
                        - identifier: Check_Application_Status
                          name: Check Application Status
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  # Using output variable from last stage
                                  restored_profile="<+pipeline.stages.Pdeploy_Execution.spec.execution.rollbackSteps.Rollback_to_previous_pdir_0.output.outputVariables.Restored_profile>"

                                  echo "Restored profile found: $restored_profile"

                                  . "$restored_profile"

                                  sleep 25

                                  echo "Checking Application Status....."

                                  # Check the Switch Application stats
                                  cd $OPRODUCT_ROOT/bin && ksh iststatuscheck.sh

                                  chkProcess=`ps -f -u $LOGNAME | grep -w mbtsk | grep -v grep`;

                                  [ -z "$chkProcess" ] && exit 1

                                  EOF

                                  # Capture the exit status 
                                  exit_status=$?

                                  # Exit with the captured status
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
            service:
              useFromStage:
                stage: Set_Up_Environment
          service:
            useFromStage:
              stage: Download_Build_env_and_Override_Installer_files
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: StageRollback
          when:
            pipelineStatus: Success
            condition: <+pipeline.stages.Install_Switch_Application.spec.execution.steps.Run_Build_Env_Script_0.output.outputVariables.Installation_type>=="Install" && <+pipeline.variables.USE_DMKLINK> == "No"
          variables:
            - name: DB_server
              type: String
              description: ""
              required: false
              value: <+input>
            - name: DB_port
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Database_vendor
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Database_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Database_user
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Database_password
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Owner_dbuser
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Owner_dbpassword
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Database_tns_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Nodeagt_keystore_pass
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Nodeagt_key_manager_pass
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Nodeagt_truststore_pass
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_database_vendor
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_database_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_database_user
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_database_password
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_schema_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_owner_dbuser
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_owner_dbpassword
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Ent_database_tns_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_database_vendor
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_database_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_database_user
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_database_password
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_schema_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_owner_dbuser
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_owner_dbpassword
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Tok_database_tns_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_database_vendor
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_database_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_database_user
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_database_password
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_schema_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_owner_dbuser
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_owner_dbpassword
              type: String
              description: ""
              required: false
              value: <+input>
            - name: Klc_database_tns_name
              type: String
              description: ""
              required: false
              value: <+input>
            - name: keystore_password
              type: String
              description: ""
              required: false
              value: <+input>
            - name: oas_user
              type: String
              description: ""
              required: false
              value: <+input>
            - name: oas_pass
              type: String
              description: ""
              required: false
              value: <+input>
      - stage:
          name: Pdeploy DB update Manual
          identifier: Pdeploy_DB_update_Manual
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            service:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Check UDM and Trigger Changes
                    identifier: Check_UDM_and_Trigger_Changes
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables:
                        - name: DIFF_CONTENT
                          type: String
                          value: DIFF_CONTENT
                        - name: DIFF_FOUND
                          type: String
                          value: DIFF_FOUND
                      commandUnits:
                        - identifier: Check_UDM_and_Trigger_Changes
                          name: Check UDM and Trigger Changes
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  eval "$switch_cmd" << 'EOF'

                                  db_vendor="<+pipeline.stages.Pdeploy_Execution.variables.Database_vendor>"
                                  echo "DB Vendor: $db_vendor"

                                  # === Set working directory ===
                                  WORKING_DIR="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  cd "$WORKING_DIR" || { echo "[ERROR] Cannot change to working directory: $WORKING_DIR"; exit 1; }

                                  echo "Current user: $(whoami)"

                                  # === Fetch pipeline variables ===
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="$WORKING_DIR/<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"
                                  FRESH_INSTALLATION="<+pipeline.variables.FRESH_INSTALLATION>"

                                  # === Validate latest variables ===
                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[ERROR] Missing latest_pdir or latest_profile ‚Äî skipping DB scan."
                                      exit 1
                                  fi
                                  echo "Latest profile file: $latest_profile"
                                  echo "Latest pdir directory: $latest_pdir"

                                  # === Source latest profile ===
                                  . "./$latest_profile"

                                  # === Define output files ===
                                  BASELINE="$HOME/baseline_db_files.txt"
                                  POST="$HOME/postinstall_db_files.txt"
                                  DIFF="$HOME/db_diff_report.txt"

                                  # === Cleanup old files ===
                                  for file in "$HOME/output_variable.txt" "$DIFF" "$POST" "$BASELINE" \
                                              "$HOME/baseline_clean.txt" "$HOME/postinstall_clean.txt"; do
                                      [ -f "$file" ] && rm -f "$file"
                                  done

                                  # === Functions ===
                                  scan_after_install() {
                                      echo "[INFO] Running post-install scan in $latest_pdir"
                                      cd "$latest_pdir" || { echo "[ERROR] Cannot access $latest_pdir"; exit 1; }
                                      if [ "$db_vendor" = "oracle" ]; then
                                          {
                                              [ -d sql ] && find sql -type f -name "*.ora" | sed 's|^|[UDM] |'
                                              [ -d sql_scripts ] && find sql_scripts -type f -name "*.ora" | sed 's|^|[TRIGGER] |'
                                          } > "$POST"
                                      elif [ "$db_vendor" = "pgsql" ]; then
                                          {
                                              [ -d sql ] && find sql -type f -name "*.sql" | sed 's|^|[UDM] |'
                                              [ -d sql_scripts ] && find sql_scripts -type f -name "*.sql" | sed 's|^|[TRIGGER] |'
                                          } > "$POST"
                                      else
                                          echo "[ERROR] Unsupported DB vendor: $db_vendor"
                                          exit 1
                                      fi
                                      echo "[INFO] Post-installation scan complete: $POST"
                                  }

                                  scan_baseline_for_install() {
                                      echo "[INFO] Running baseline scan in $second_latest_pdir"
                                      cd "$second_latest_pdir" || { echo "[ERROR] Cannot access $second_latest_pdir"; exit 1; }
                                      if [ "$db_vendor" = "oracle" ]; then
                                          {
                                              [ -d sql ] && find sql -type f -name "*.ora" | sed 's|^|[UDM] |'
                                              [ -d sql_scripts ] && find sql_scripts -type f -name "*.ora" | sed 's|^|[TRIGGER] |'
                                          } > "$BASELINE"
                                      elif [ "$db_vendor" = "pgsql" ]; then
                                          {
                                              [ -d sql ] && find sql -type f -name "*.sql" | sed 's|^|[UDM] |'
                                              [ -d sql_scripts ] && find sql_scripts -type f -name "*.sql" | sed 's|^|[TRIGGER] |'
                                          } > "$BASELINE"
                                      fi
                                  }

                                  scan_baseline_for_update() {
                                      echo "[INFO] Using baseline from $latest_pdir"
                                      cd "$latest_pdir" || { echo "[ERROR] Cannot access $latest_pdir"; exit 1; }
                                      if [ "$db_vendor" = "oracle" ]; then
                                          {
                                              [ -d sql ] && find sql -type f -name "*.ora" | sed 's|^|[UDM] |'
                                              [ -d sql_scripts ] && find sql_scripts -type f -name "*.ora" | sed 's|^|[TRIGGER] |'
                                          } > "$BASELINE"
                                      elif [ "$db_vendor" = "pgsql" ]; then
                                          {
                                              [ -d sql ] && find sql -type f -name "*.sql" | sed 's|^|[UDM] |'
                                              [ -d sql_scripts ] && find sql_scripts -type f -name "*.sql" | sed 's|^|[TRIGGER] |'
                                          } > "$BASELINE"
                                      fi
                                  }

                                  # === Run scans ===
                                  cd "$HOME" || exit 1

                                  if [ "$FRESH_INSTALLATION" = "Yes" ]; then
                                      # Compute second_latest_pdir only for fresh installation
                                      second_latest_pdir=$(ls -td "$WORKING_DIR"/pdir20* 2>/dev/null | sed -n '2p')
                                      if [ -z "$second_latest_pdir" ]; then
                                          echo "[ERROR] No second latest pdir found for baseline scan."
                                          exit 1
                                      fi
                                      echo "Second latest pdir: $second_latest_pdir"
                                      scan_baseline_for_install
                                  else
                                      scan_baseline_for_update
                                  fi

                                  scan_after_install

                                  # === Sort and compare ===
                                  LC_ALL=C sort "$BASELINE" > "$HOME/baseline_clean.txt"
                                  LC_ALL=C sort "$POST" > "$HOME/postinstall_clean.txt"
                                  comm -13 "$HOME/baseline_clean.txt" "$HOME/postinstall_clean.txt" > "$DIFF"

                                  # === Output result ===
                                  if [ -s "$DIFF" ]; then
                                      echo "true" > "$HOME/output_variable.txt"
                                  else
                                      echo "No DB files were added during installation." >> "$DIFF"
                                      echo "false" > "$HOME/output_variable.txt"
                                  fi
                                  EOF

                                  # Capture the exit status
                                  exit_status=$?

                                  # Fail pipeline if subshell failed
                                  if [ $exit_status -ne 0 ]; then
                                      exit $exit_status
                                  fi

                                  # === Read output variables ===
                                  if [ -f output_variable.txt ]; then
                                      DIFF_FOUND=$(cat output_variable.txt)
                                      echo "DB required: $DIFF_FOUND"
                                  fi

                                  if [ -f db_diff_report.txt ]; then
                                      DIFF_CONTENT=$(cat db_diff_report.txt)
                                  fi
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Email
                    name: Pdeploy DB update Notity
                    identifier: Pdeploy_DB_update_Notity
                    spec:
                      to: <+pipeline.variables.NOTIFY_TO>
                      cc: <+pipeline.variables.NOTIFY_CC>
                      subject: Switch Pdeploy DB Update Approval
                      body: |-
                        <!DOCTYPE html>
                        <html>
                          <head>
                            <meta charset="UTF-8">
                            <title>Manual Approval Required</title>
                          </head>
                          <body style="margin: 0; padding: 0; background-color: #e0f7f1; font-family: Arial, sans-serif; color: #2c3e50;">
                            <div style="max-width: 600px; margin: 40px auto; background-color: #ffffff; border-radius: 10px; padding: 20px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);">
                              
                              <!-- Header -->
                              <h2 style="margin: 0; padding: 15px; background-color: #007bff; color: #ffffff; border-radius: 8px 8px 0 0; text-align: center; font-size: 20px;">
                                Action Required: Run UDM and Trigger Scripts with Pdeploy
                              </h2>
                              
                              <!-- Message -->
                              <p style="margin-top: 20px;">Hi Team,</p>
                              <p>The Harness pipeline has reached a manual approval stage for the <strong>Pdeploy DB Update</strong>. To proceed, please log into the target server and run the required <strong>UDM and Trigger scripts using Pdeploy</strong> manually.</p>

                              <!-- Table -->
                              <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
                                <tr style="background-color: #e6fff5;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Project Name</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;">IST SWITCH</td>
                                </tr>
                                <tr style="background-color: #ffffff;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Pipeline Name</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;"><strong><+pipeline.name></strong></td>
                                </tr>
                                <tr style="background-color: #e6fff5;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Artifact Name</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName></td>
                                </tr>
                                <tr style="background-color: #ffffff;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Server Detail</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.variables.TARGET_SERVER></td>
                                </tr>
                                <tr style="background-color: #e6fff5;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Server User Account</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.variables.USER_ACCOUNT></td>
                                </tr>
                                 <tr style="background-color: #e6fff5;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Profile Path</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile></td>
                                </tr>
                                <tr style="background-color: #ffffff;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">DB Scripts (UDM & Trigger)</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.stages.Pdeploy_DB_update_Manual.spec.execution.steps.Check_UDM_and_Trigger_Changes_0.output.outputVariables.DIFF_CONTENT></td>
                                </tr>
                                <tr style="background-color: #e6fff5;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Triggered By</th>
                                  <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.triggeredBy.name></td>
                                </tr>
                              </table>

                              <!-- Reminder -->
                              <p style="margin-top: 20px; font-weight: bold; color: #d9534f;">Reminder: This step must be completed manually on the target server before the pipeline can continue.</p>

                              <!-- CTA Button -->
                              <p style="margin-top: 20px; text-align: center;">
                                <a href="<+pipeline.executionUrl>" style="background-color: #007bff; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; display: inline-blocknter;">
                                This is an automated email generated by the Harness pipeline. Please do not reply to this email.
                              </p>
                            </div>
                          </body>
                        </html>
                    timeout: 10m
                    when:
                      stageStatus: Success
                      condition: |
                        <+pipeline.stages.Pdeploy_DB_update_Manual.spec.execution.steps.Check_UDM_and_Trigger_Changes_0.output.outputVariables.DIFF_FOUND>=="true"
                - step:
                    type: HarnessApproval
                    name: Pdeploy DB update Manual Approval
                    identifier: Pdeploy_DB_update_Manual_Approval
                    spec:
                      approvalMessage: Please review the following information and approve the pipeline progression
                      includePipelineExecutionHistory: true
                      isAutoRejectEnabled: false
                      approvers:
                        userGroups: <+input>.selectOneFrom(org.SW_Dev_Approvers,org.SW_QC_Approvers)
                        minimumCount: 1
                        disallowPipelineExecutor: false
                      approverInputs: []
                    timeout: 1d
                    when:
                      stageStatus: Success
                      condition: |
                        <+pipeline.stages.Pdeploy_DB_update_Manual.spec.execution.steps.Check_UDM_and_Trigger_Changes_0.output.outputVariables.DIFF_FOUND>=="true"
              rollbackSteps: []
          tags: {}
          when:
            pipelineStatus: Success
            condition: (     <+pipeline.variables.FRESH_INSTALLATION> == "No" &&     <+pipeline.triggerType> == "MANUAL"   ) || (     <+pipeline.variables.FRESH_INSTALLATION> == "Yes" &&     <+pipeline.triggerType> == "MANUAL" &&     <+pipeline.variables.USE_DMKLINK> == "Yes"   )
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: MarkAsFailure
      - stage:
          name: Start Application
          identifier: Start_Application
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Start Application
                    identifier: Start_Application
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Start_Application
                          name: Start Application
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  WORKING_DIR="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  cd $WORKING_DIR

                                  echo "Current user: $(whoami)"

                                  # Find the latest pdir directory
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"
                                  latest_pdir="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_pdir>"

                                  if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
                                      echo "[WARNING] No pdir or profile found"
                                  else
                                      echo "Latest profile file: $latest_profile"
                                      echo "Latest pdir directory: $latest_pdir"
                                  fi

                                  #Source the profile
                                  . "./$latest_profile" 

                                  INSTALL_TYPE="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Run_Build_Env_Script_0.output.outputVariables.Installation_type>"
                                  LICENSE_SETUP="<+pipeline.variables.LICENSE_SETUP>"
                                  TARGET_SERVER="<+pipeline.variables.TARGET_SERVER>"

                                  # Running klc_init_master when install type equals to install
                                  if [ "$INSTALL_TYPE" == "Install" ]; then
                                      echo "Installation type is Install. Running klc_init_master..."
                                      klc_init_master

                                  #Rename apm_org.cfg file into apm.src
                                  cd $OSITE_ROOT/cfg/

                                    if [ -f apm_org.cfg ] && [ ! -e apm.src ]; then
                                      mv apm_org.cfg apm.src
                                      echo "Renamed apm_org.cfg to apm.src"
                                    fi

                                  #Clean istparam.cfg if contains ^M
                                  if [ "$(tr -d '\r' < istparam.cfg | wc -c)" -ne "$(wc -c < istparam.cfg)" ]; then
                                      tr -d '\r' < istparam.cfg > istparam_clean.cfg
                                      mv istparam_clean.cfg istparam.cfg
                                      echo "Cleaned istparam.cfg"
                                  else
                                      echo "No ^M characters found. No cleanup needed."
                                  fi

                                  if [ "$LICENSE_SETUP" = "Yes" ]; then
                                      echo "License setup is enabled. Copying license file..."

                                      filename="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"
                                      echo "Switch artifact file name: $filename"

                                      # Extract the two-digit version number after 'SW' and before '0SP' using awk
                                      version="$(echo "$filename" | awk -F'SW' '{split($2, v, "0SP"); print v[1]}')"

                                      echo "Fetched Switch Version: $version"
                                      # Construct source path dynamically
                                      license_dir="$WORKING_DIR/license"
                                      src_path="$license_dir/lservrc_$version"
                                      echo "Looking for license file: $src_path"

                                      # Check if license directory exists
                                      if [ ! -d "$license_dir" ]; then
                                          echo "ERROR: License directory '$license_dir' does not exist."
                                          exit 1
                                      fi

                                      # Check if license file exists
                                      if [ ! -f "$src_path" ]; then
                                          echo "ERROR: License file '$src_path' not found for version '$version'."
                                          exit 1
                                      fi

                                      # Copy the license file and fail if the copy fails
                                      cp "$src_path" "$OSITE_ROOT/cfg/lservrc" || {
                                          echo "ERROR: Failed to copy license file from $src_path"
                                          exit 1
                                      }

                                      
                                      echo "License file copied successfully to $OSITE_ROOT/cfg/lservrc."
                                      

                                  else
                                      echo "License setup is not enabled. Skipping license configuration."
                                  fi


                                  else
                                      echo "Installation type is not Install. Skipping klc_init_master."
                                  fi

                                  export LOGNAME=$(whoami)

                                  echo "Cleaning IPC resources for key: $LOGNAME"

                                  # Remove shared memory segments
                                  for id in $(ipcs -m | grep "$LOGNAME" | awk '{print $2}'); do
                                      echo "Removing shared memory segment ID: $id"
                                      ipcrm -m $id
                                  done

                                  # Remove semaphores
                                  for id in $(ipcs -s | grep "$LOGNAME" | awk '{print $2}'); do
                                      echo "Removing semaphore ID: $id"
                                      ipcrm -s $id
                                  done

                                  # Remove message queues
                                  for id in $(ipcs -q | grep "$LOGNAME" | awk '{print $2}'); do
                                      echo "Removing message queue ID: $id"
                                      ipcrm -q $id
                                  done

                                  echo "Cleanup complete."

                                  echo "-----------------------------------------------"

                                  echo "Starting Switch Application..."

                                  # Start the Switch Application
                                  cd $OPRODUCT_ROOT/bin && ksh iststartup.sh 

                                  EOF

                                  # Capture the exit status
                                  exit_status=$?

                                  # Fail pipeline if subshell failed
                                  if [ $exit_status -ne 0 ]; then
                                      exit $exit_status
                                  fi
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Wait
                    name: Waiting For Application to start
                    identifier: Waiting_For_Application_to_start
                    spec:
                      duration: 30s
                - step:
                    type: Command
                    name: Check Application Status
                    identifier: Check_Application_Status
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Check_status_for_start
                          name: Check status for start
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  # Using output variable from last stage
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"

                                  echo "Latest profile found: $latest_profile"

                                  . "./$latest_profile"

                                  echo "Checking Application Status....."

                                  export LOGNAME=$(whoami)

                                  # Check the Switch Application stats
                                  cd $OPRODUCT_ROOT/bin && ksh iststatuscheck.sh

                                  chkProcess=`ps -f -u $LOGNAME | grep -w mbtsk | grep -v grep`;

                                  if [ -z "$chkProcess" ]; then
                                      exit 1
                                  fi

                                  EOF

                                  # Capture the exit status 
                                  exit_status=$?

                                  # Exit with the captured status
                                  exit $exit_status
                    timeout: 5m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                - step:
                    type: Command
                    name: Run Klcutil
                    identifier: Run_Klcutil
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Run_Klcutil
                          name: Run Klcutil
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  # Using output variable from last stage
                                  latest_profile="<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile>"

                                  echo "Application profile found: $latest_profile"

                                  #Source the profile
                                  . "./$latest_profile"

                                  echo "Installation type is Install. Running klcutil commands..."

                                      for cmd in \
                                          "klcutil -g 10 -U F -A 0" \
                                          "klcutil -g 10 -U D -A 0" \
                                          "klcutil -g 10 -U P -A 0"
                                          
                                      do
                                          echo "Executing: $cmd"
                                          eval "$cmd"
                                          if [ $? -ne 0 ]; then
                                              echo "Warning: Command '$cmd' failed, but continuing..."
                                          fi
                                      done

                                      echo "klcutil command sequence completed."

                                  EOF
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: Success
                      condition: <+pipeline.stages.Install_Switch_Application.spec.execution.steps.Run_Build_Env_Script_0.output.outputVariables.Installation_type> == "Install" || <+pipeline.stages.Install_Switch_Application.spec.execution.steps.Run_Build_Env_Script_0.output.outputVariables.Installation_type> == "Install_With_DMKLINK"
              rollbackSteps:
                - step:
                    type: Email
                    name: App install rollback email
                    identifier: App_install_rollback_email
                    spec:
                      to: <+pipeline.variables.NOTIFY_TO>
                      cc: <+pipeline.variables.NOTIFY_CC>
                      subject: Rollback notification <+pipeline.name>
                      body: |
                        <!DOCTYPE html>
                        <html>
                          <body style="font-family: Arial, sans-serif; background-color: #e9f1f7; padding: 20px; color: #2c3e50;">
                            <div style="max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 10px; padding: 20px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);">
                              <h2 style="color: #d9534f; border-bottom: 2px solid #dc3545; padding-bottom: 10px;">Harness Pipeline Failed</h2>
                              <p>Dear Team,</p>
                              <p>The <strong><+pipeline.name>;</strong> execution encountered a failure at stage <strong><+stage.name>;</strong>.</p>

                              <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Project Name</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><+project.name></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Pipeline Name</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong><+pipeline.name></strong></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Failed Stage</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong><+stage.name></strong></td>
                                </tr>
                                <tr style="background-color: #f8d7da;">
                                  <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Status</th>
                                  <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong>Failed</strong></td>
                                </tr>
                              </table>

                              <p style="margin-top: 20px;">
                                Failed Pipeline Link: 
                                <a href="<+pipeline.executionUrl>" style="background-color: #dc3545; color: white; padding: 10px 15px; text-decoration: none; border-radius: 5px;">View Pipeline Execution</a>
                              </p>

                              <p style="margin-top: 20px; font-weight: bold; color: #d9534f;">
                                Rollback with previous pdir will be executed.
                              </p>

                              <p style="margin-top: 20px;">Regards,<br/>CICD Team</p>

                              <p style="font-size: 12px; color: #6c757d; margin-top: 30px;">
                                This is an automated email generated by the Harness pipeline. Please do not reply to this email.
                              </p>
                            </div>
                          </body>
                        </html>
                    timeout: 10m
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
                - step:
                    type: HarnessApproval
                    name: Rollback Approval
                    identifier: Rollback_Approval
                    spec:
                      approvalMessage: Please review the following information and approve the pipeline progression
                      includePipelineExecutionHistory: true
                      isAutoRejectEnabled: false
                      approvers:
                        userGroups: <+input>.selectOneFrom(org.SW_Dev_Approvers,org.SW_QC_Approvers)
                        minimumCount: 1
                        disallowPipelineExecutor: false
                      approverInputs: []
                    timeout: 1d
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
                - step:
                    type: Command
                    name: Rollback to Previous Pdir
                    identifier: Rollback_to_Previous_Pdir
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables:
                        - name: Restored_profile
                          type: String
                          value: restored_profile
                      commandUnits:
                        - identifier: Rollback
                          name: Rollback
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  set -e

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  INSTALL_DIR="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
                                  BACKUP_VARS="$INSTALL_DIR/backup_vars.env"

                                  export HOME="$INSTALL_DIR"

                                  echo "HOME is set to: $HOME"

                                  # Load backup variables
                                  if [ ! -f "$BACKUP_VARS" ]; then
                                      echo "[ERROR] Backup variables file not found!"
                                      exit 1
                                  fi

                                  . "$BACKUP_VARS"

                                  # Verify backup variables
                                  if [ -z "$BACKUP_DIR" ] || [ -z "$BACKUP_PDIR" ] || [ -z "$BACKUP_PROFILE" ]; then
                                      echo "[ERROR] Backup variables are not set correctly!"
                                      exit 1
                                  fi

                                  # Verify archive
                                  if [ ! -f "$BACKUP_ARCHIVE" ]; then
                                      echo "[ERROR] Backup archive not found!"
                                      exit 1
                                  fi

                                  # Validate archive based on OS
                                  if [ "$(uname)" = "AIX" ]; then
                                      if ! gunzip -c "$BACKUP_ARCHIVE" | tar -tf - >/dev/null; then
                                          echo "[ERROR] Backup archive is corrupt!"
                                          exit 1
                                      fi
                                  else
                                      if ! tar -tzf "$BACKUP_ARCHIVE" >/dev/null; then
                                          echo "[ERROR] Backup archive is corrupt!"
                                          exit 1
                                      fi
                                  fi

                                  # Remove existing files
                                  if [ -d "$INSTALL_DIR/$(basename "$BACKUP_PDIR")" ]; then
                                      echo "[INFO] Removing existing pdir directory: $(basename "$BACKUP_PDIR")"
                                      rm -rf "$INSTALL_DIR/$(basename "$BACKUP_PDIR")"
                                  fi

                                  if [ -f "$INSTALL_DIR/$(basename "$BACKUP_PROFILE")" ]; then
                                      echo "[INFO] Removing existing profile file: $(basename "$BACKUP_PROFILE")"
                                      rm -f "$INSTALL_DIR/$(basename "$BACKUP_PROFILE")"
                                  fi

                                  # Remove prot_dir if it was backed up
                                  if [ -n "$BACKUP_PROT_DIR" ] && [ -d "$INSTALL_DIR/prot_dir" ]; then
                                      echo "[INFO] Removing existing prot_dir directory"
                                      rm -rf "$INSTALL_DIR/prot_dir"
                                  fi

                                  # Extract backup
                                  echo "[INFO] Extracting backup archive..."
                                  if [ "$(uname)" = "AIX" ]; then
                                      gunzip -c "$BACKUP_ARCHIVE" | tar -xvf - -C "$INSTALL_DIR"
                                  else
                                      tar -xzf "$BACKUP_ARCHIVE" -C "$INSTALL_DIR"
                                  fi

                                  restored_profile="$INSTALL_DIR/$(basename "$BACKUP_PROFILE")"

                                  # Verify restoration
                                  if [ ! -d "$INSTALL_DIR/$(basename "$BACKUP_PDIR")" ] || [ ! -f "$restored_profile" ]; then
                                      echo "[ERROR] Rollback verification failed"
                                      exit 1
                                  fi

                                  if [ -n "$BACKUP_PROT_DIR" ] && [ ! -d "$INSTALL_DIR/prot_dir" ]; then
                                      echo "[ERROR] prot_dir restoration failed"
                                      exit 1
                                  fi

                                  echo "[SUCCESS] Restoration completed successfully"

                                  # Write latest_profile to a temporary file
                                  echo "$restored_profile" > output_variable.txt

                                  EOF

                                  # Read latest_profile from the temporary file
                                  restored_profile=$(cat output_variable.txt)
                                  echo "Restored Profile: $restored_profile"
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
                - step:
                    type: Command
                    name: Start Application and Check status
                    identifier: Start_Application_and_Check_status
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Start_Application
                          name: Start Application
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  # Using output variable from last stage
                                  restored_profile="<+pipeline.stages.Start_Application.spec.execution.rollbackSteps.Rollback_to_Previous_Pdir_0.output.outputVariables.Restored_profile>"

                                  echo "Restored profile found: $restored_profile"

                                  . "$restored_profile"

                                  # Start the Switch Application
                                  cd $OPRODUCT_ROOT/bin && ksh iststartup.sh 

                                  EOF
                        - identifier: Check_Application_Status
                          name: Check Application Status
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |
                                  #!/bin/sh

                                  echo "Current user: $(whoami)"

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"

                                  export HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

                                  echo "HOME is set to: $HOME"

                                  # Using output variable from last stage
                                  restored_profile="<+pipeline.stages.Start_Application.spec.execution.rollbackSteps.Rollback_to_Previous_Pdir_0.output.outputVariables.Restored_profile>"

                                  echo "Restored profile found: $restored_profile"

                                  . "$restored_profile"

                                  sleep 25

                                  echo "Checking Application Status....."

                                  # Check the Switch Application stats
                                  cd $OPRODUCT_ROOT/bin && ksh iststatuscheck.sh

                                  chkProcess=`ps -f -u $LOGNAME | grep -w mbtsk | grep -v grep`;

                                  [ -z "$chkProcess" ] && exit 1

                                  EOF

                                  # Capture the exit status 
                                  exit_status=$?

                                  # Exit with the captured status
                                  exit $exit_status
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
                    when:
                      stageStatus: All
                      condition: <+pipeline.stages.Backup.spec.execution.steps.Backup_0.output.outputVariables.BACKUP_TAKEN> == "Yes" && <+pipeline.variables.FRESH_INSTALLATION> == "No"
            service:
              useFromStage:
                stage: Set_Up_Environment
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: StageRollback
          when:
            pipelineStatus: Success
      - stage:
          name: Notification to Team
          identifier: Notification_to_Team
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - parallel:
                    - step:
                        type: Email
                        name: Notify on Success
                        identifier: Notify_on_Success
                        spec:
                          to: <+pipeline.variables.NOTIFY_TO>
                          cc: <+pipeline.variables.NOTIFY_CC>
                          subject: Harness <+pipeline.name> Pipeline Status
                          body: |2-
                                  <!DOCTYPE html>
                                    <html>
                                      <body style="font-family: Arial, sans-serif; background-color: #e9f1f7; padding: 20px; color: #2c3e50;">
                                        <div style="max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 10px; padding: 20px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);">
                                          <h2 style="color: #0056b3; border-bottom: 2px solid #007bff; padding-bottom: 10px;">Harness Pipeline Completed</h2>
                                          <p>Hi Team,</p>
                                          <p>The Harness pipeline has been successfully completed.</p>

                                          <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Project Name</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><+project.name></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Pipeline Name</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><strong><+pipeline.name></strong></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Status</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><strong>Success</strong></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Artifact Name</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Server Detail</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.variables.TARGET_SERVER></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Server User Account</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.variables.USER_ACCOUNT></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Database Vendor</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.stages.Pdeploy_Execution.variables.Database_vendor></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Profile Path</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/<+pipeline.stages.Install_Switch_Application.spec.execution.steps.Check_Installation_Status_0.output.outputVariables.latest_profile></td>
                                            </tr>
                                            <tr style="background-color: #f0f8ff;">
                                              <th style="text-align: left; padding: 12px; border: 1px solid #cce5ff; color: #004085;">Triggered By</th>
                                              <td style="padding: 12px; border: 1px solid #cce5ff;"><+pipeline.triggeredBy.name></td>
                                            </tr>
                                          </table>

                                          <p style="margin-top: 20px; font-weight: bold; color: #28a745;">Up-to-date</p>

                                          <p style="margin-top: 20px;">
                                            <a href="<+pipeline.executionUrl>" style="background-color: #007bff; color: white; padding: 10px 15px; text-decoration: none; border-radius: 5px;">View Pipeline Execution</a>
                                          </p>

                                          <p style="font-size: 12px; color: #6c757d; margin-top: 30px;">
                                            This is an automated email generated by the Harness pipeline. Please do not reply to this email.
                                          </p>
                                        </div>
                                      </body>
                                    </html>
                        timeout: 10m
                        strategy:
                          repeat:
                            items: <+stage.output.hosts>
                        when:
                          stageStatus: Success
                          condition: <+pipeline.stages.Start_Application.spec.execution.steps.Check_Application_Status_0.status> == "SUCCEEDED"
                    - step:
                        type: Email
                        name: Notify on Failure
                        identifier: Notify_on_Failure
                        spec:
                          to: <+pipeline.variables.NOTIFY_TO>
                          cc: <+pipeline.variables.NOTIFY_CC>
                          subject: Harness <+pipeline.name> Pipeline Status
                          body: |
                            <!DOCTYPE html>
                            <html>
                              <body style="font-family: Arial, sans-serif; background-color: #fbeaea; padding: 20px; color: #2c3e50;">
                                <div style="max-width: 600px; margin: auto; background-color: #ffffff; border-radius: 10px; padding: 20px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);">
                                  <h2 style="color: #b30000; border-bottom: 2px solid #ff4d4d; padding-bottom: 10px;">Harness Pipeline Failed</h2>
                                  <p>Hi Team,</p>
                                  <p>The Harness pipeline execution has failed. Please review the details below and take necessary action.</p>

                                  <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Project Name</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><+project.name></td>
                                    </tr>
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Pipeline Name</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong><+pipeline.name></strong></td>
                                    </tr>
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Status</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><strong style="color: #dc3545;">Failed</strong></td>
                                    </tr>
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Artifact Name</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName></td>
                                    </tr>
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Server Detail</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><+pipeline.variables.TARGET_SERVER></td>
                                    </tr>
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Server User Account</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><+pipeline.variables.USER_ACCOUNT></td>
                                    </tr>
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Working Directory</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory></td>
                                    </tr>
                                    <tr style="background-color: #ffecec;">
                                      <th style="text-align: left; padding: 12px; border: 1px solid #f5c6cb; color: #721c24;">Triggered By</th>
                                      <td style="padding: 12px; border: 1px solid #f5c6cb;"><+pipeline.triggeredBy.name></td>
                                    </tr>
                                  </table>

                                  <p style="margin-top: 20px; font-weight: bold; color: #dc3545;">Action Required</p>

                                  <p style="margin-top: 20px;">
                                    <a href="<+pipeline.executionUrl>" style="background-color: #dc3545; color: white; padding: 10px 15px; text-decoration: none; border-radius: 5px;">View Pipeline Execution</a>
                                  </p>

                                  <p style="font-size: 12px; color: #6c757d; margin-top: 30px;">
                                    This is an automated email generated by the Harness pipeline. Please do not reply to this email.
                                  </p>
                                </div>
                              </body>
                            </html>
                        timeout: 10m
                        strategy:
                          repeat:
                            items: <+stage.output.hosts>
                        when:
                          stageStatus: Success
                          condition: <+pipeline.stages.Start_Application.spec.execution.steps.Check_Application_Status_0.status> != "SUCCEEDED"
              rollbackSteps: []
            service:
              useFromStage:
                stage: Set_Up_Environment
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: MarkAsFailure
          when:
            pipelineStatus: All
      - stage:
          name: Workspace Clean
          identifier: Workspace_Clean
          description: ""
          type: Deployment
          spec:
            deploymentType: Ssh
            environment:
              useFromStage:
                stage: Set_Up_Environment
            execution:
              steps:
                - step:
                    type: Command
                    name: Clean up old pdir backup profile
                    identifier: Clean_up_old_pdir_backup_profile
                    spec:
                      onDelegate: false
                      environmentVariables: []
                      outputVariables: []
                      commandUnits:
                        - identifier: Clean_up_old_pdir_backup_profile
                          name: Clean up old pdir backup profile
                          type: Script
                          spec:
                            workingDirectory: <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
                            shell: Bash
                            source:
                              type: Inline
                              spec:
                                script: |-
                                  #!/bin/sh

                                  selected_user="<+pipeline.variables.USER_ACCOUNT>"

                                  # Determine the switch command based on OS
                                  if [ "$(uname)" = "Linux" ]; then
                                    switch_cmd="dzdo su - $selected_user"
                                  else
                                    switch_cmd="su $selected_user -s /bin/sh"
                                  fi

                                  # Use eval with a quoted command and unquoted here-document
                                  eval "$switch_cmd" << 'EOF'

                                  cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

                                  echo "Current user: $(whoami)"
                                  echo "Cleaning old files and directories..."

                                  # Remove temporary and backup files if they exist
                                  for file in output_variable.txt backup_vars.env backup_status.env \
                                              postinstall_db_files.txt baseline_clean.txt DBclean.sql \
                                              baseline_db_files.txt postinstall_clean.txt db_diff_report.txt; do
                                      [ -f "$file" ] && rm "$file"
                                  done

                                  # Set to "true" to simulate deletions without actually removing files
                                  DRY_RUN=false

                                  # Detect OS inside the session
                                  OS_TYPE=$(uname)
                                  USE_MAXDEPTH=true
                                  if [ "$OS_TYPE" = "AIX" ]; then
                                      USE_MAXDEPTH=false
                                  fi

                                  # Function to delete all but the newest matching item if all are older than 3 days
                                  delete_old_files_and_dirs() {
                                      pattern=$1
                                      type=$2

                                      echo "Checking $type(s) matching pattern: $pattern"

                                      if [ "$USE_MAXDEPTH" = true ]; then
                                          if [ "$type" = "file" ]; then
                                              all_matches=$(find . -maxdepth 1 -type f -name "$pattern" 2>/dev/null)
                                              old_matches=$(find . -maxdepth 1 -type f -name "$pattern" -mtime +3 2>/dev/null)
                                          elif [ "$type" = "dir" ]; then
                                              all_matches=$(find . -maxdepth 1 -type d -name "$pattern" 2>/dev/null)
                                              old_matches=$(find . -maxdepth 1 -type d -name "$pattern" -mtime +3 2>/dev/null)
                                          fi
                                      else
                                          if [ "$type" = "file" ]; then
                                              all_matches=$(find . -type f -name "$pattern" 2>/dev/null | grep '^./[^/]*$')
                                              old_matches=$(find . -type f -name "$pattern" -mtime +3 2>/dev/null | grep '^./[^/]*$')
                                          elif [ "$type" = "dir" ]; then
                                              all_matches=$(find . -type d -name "$pattern" 2>/dev/null | grep '^./[^/]*$')
                                              old_matches=$(find . -type d -name "$pattern" -mtime +3 2>/dev/null | grep '^./[^/]*$')
                                          fi
                                      fi

                                      total_count=$(echo "$all_matches" | grep -c .)
                                      old_count=$(echo "$old_matches" | grep -c .)

                                      if [ "$old_count" -eq 0 ]; then
                                          echo "No $type(s) older than 3 days found. Nothing to delete."
                                          return
                                      fi

                                      if [ "$old_count" -eq "$total_count" ]; then
                                          echo "All $type(s) are older than 3 days. Keeping the newest one and deleting the rest."
                                          newest=$(echo "$old_matches" | xargs ls -1td 2>/dev/null | head -n 1)
                                          echo "Keeping: $newest"
                                          echo "$old_matches" | while read item; do
                                              if [ "$item" != "$newest" ]; then
                                                  if [ "$DRY_RUN" = true ]; then
                                                      echo "[DRY RUN] Would delete: $item"
                                                  else
                                                      echo "Deleting: $item"
                                                      rm -rf "$item"
                                                  fi
                                              fi
                                          done
                                      else
                                          echo "Some $type(s) are newer than 3 days. Deleting only the older ones."
                                          echo "$old_matches" | while read item; do
                                              if [ "$DRY_RUN" = true ]; then
                                                  echo "[DRY RUN] Would delete: $item"
                                              else
                                                  echo "Deleting: $item"
                                                  rm -rf "$item"
                                              fi
                                          done
                                      fi
                                  }

                                  # Clean up files and directories older than 3 days
                                  delete_old_files_and_dirs "profile*" "file"
                                  delete_old_files_and_dirs "pdir*" "dir"
                                  delete_old_files_and_dirs "prot_dir_*" "dir"

                                  # Pattern to match backup folders with timestamp
                                  for folder in backup_20*; do
                                      if [ -d "$folder" ]; then
                                          echo "Removing backup folder: $folder"
                                          rm -rf "$folder"
                                      fi
                                  done

                                  echo "Cleanup complete. Remaining files and directories:"
                                  ls -lt
                                  pwd

                                  EOF
                    timeout: 10m
                    strategy:
                      repeat:
                        items: <+stage.output.hosts>
              rollbackSteps: []
            service:
              useFromStage:
                stage: Set_Up_Environment
          tags: {}
          failureStrategies:
            - onFailure:
                errors:
                  - AllErrors
                action:
                  type: MarkAsFailure
          when:
            pipelineStatus: All
      - stage:
          name: OTS-PreTest
          identifier: OTSPreTest
          tags: {}
          template:
            templateRef: org.OTSPreTest
            versionLabel: V1
            templateInputs:
              type: Deployment
              variables:
                - name: Owner_dbuser
                  type: String
                  value: <+input>
                - name: Owner_dbpassword
                  type: String
                  value: <+input>
                - name: Database_name
                  type: String
                  value: <+input>
                - name: Run_DB_Queries
                  type: String
                  value: <+input>.selectOneFrom(true,false)
                - name: mcport
                  type: String
                  value: <+input>
                - name: visaport
                  type: String
                  value: <+input>
                - name: mcportname
                  type: String
                  value: <+input>
                - name: visaportname
                  type: String
                  value: <+input>
                - name: ISSUER_BIN
                  type: String
                  value: <+input>
                - name: ACQUIRER_BIN
                  type: String
                  value: <+input>
                - name: mcportname2
                  type: String
                  value: <+input>
                - name: visaportname2
                  type: String
                  value: <+input>
                - name: mcport2
                  type: String
                  value: <+input>
                - name: visaport2
                  type: String
                  value: <+input>
                - name: DB_server
                  type: String
                  value: <+input>
                - name: DB_port
                  type: String
                  value: <+input>
                - name: klc_db_user
                  type: String
                  value: <+input>
                - name: klc_db_password
                  type: String
                  value: <+input>
                - name: LM2PORT
                  type: String
                  value: <+input>
                - name: pg_db_user
                  type: String
                  value: <+input>
                - name: pg_db_pwd
                  type: String
                  value: <+input>
                - name: pg_db_server
                  type: String
                  value: <+input>
                - name: pg_db_port
                  type: String
                  value: <+input>
                - name: pg_db_name
                  type: String
                  value: <+input>
      - stage:
          name: OTS-Transaction
          identifier: OTSTransaction
          tags: {}
          template:
            templateRef: org.OTSTransaction
            versionLabel: V2
            templateInputs:
              type: Deployment
              spec:
                execution:
                  steps:
                    - parallel:
                        - step:
                            identifier: clear_queue
                            type: ShellScript
                            spec:
                              executionTarget:
                                connectorRef: <+input>
                    - step:
                        identifier: debug_archive
                        type: ShellScript
                        spec:
                          executionTarget:
                            connectorRef: <+input>
                    - step:
                        identifier: cleanup_archive
                        type: ShellScript
                        spec:
                          executionTarget:
                            connectorRef: <+input>
              variables:
                - name: mcXtsPath
                  type: String
                  value: <+input>.selectOneFrom(C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4\Projects\Mastercard Dual Message System Acquirer Processor 25Q4 09_26_25\Mastercard Dual Message System Acquirer Processor 25Q4 09_26_25.xts,C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4\Projects\Mastercard Dual Message System Acquirer Processor RHEL9\Mastercard Dual Message System Acquirer Processor 25Q4 09_26_25.xts,C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4\Projects\Mastercard Dual Message System Acquirer Processor AIX7.3\Mastercard Dual Message System Acquirer Processor 25Q4 09_26_25.xts)
                - name: visaXtsPath
                  type: String
                  value: <+input>.selectOneFrom(C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025\Projects\VisaNet Authorization-Only Issuer Processor Apr 2025 09_26_25\VisaNet Authorization-Only Issuer Processor Apr 2025 09_26_25.xts,C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025\Projects\VisaNet Authorization-Only Issuer Processor Apr 2025 09_26_25 RHEL9\VisaNet Authorization-Only Issuer Processor Apr 2025 09_26_25.xts,C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025\Projects\VisaNet Authorization-Only Issuer Processor Apr 2025 09_26_25 AIX7.3\VisaNet Authorization-Only Issuer Processor Apr 2025 09_26_25.xts)
                - name: mcXtsPath_visaPath
                  type: String
                  value: <+input>.selectOneFrom(C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4 oct12th\Projects\Mastercard Dual Message System Issuer Processor 25Q4 oct12th\Mastercard Dual Message System Issuer Processor 25Q4 oct12th.xts,C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4 oct12th\Projects\Mastercard Dual Message System Issuer Processor 25Q4 oct12th RHEL9\Mastercard Dual Message System Issuer Processor 25Q4 oct12th.xts,C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4 oct12th\Projects\Mastercard Dual Message System Issuer Processor 25Q4 oct12th AIX7.3\Mastercard Dual Message System Issuer Processor 25Q4 oct12th.xts)
                - name: visaXtsPath_visaPath
                  type: String
                  value: <+input>.selectOneFrom(C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025 oct12th\Projects\VisaNet Authorization-Only Acquirer Processor Apr 2025 oct12th\VisaNet Authorization-Only Acquirer Processor Apr 2025 oct12th.xts,C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025 oct12th\Projects\VisaNet Authorization-Only Acquirer Processor Apr 2025 oct12th RHEL9\VisaNet Authorization-Only Acquirer Processor Apr 2025 oct12th.xts,C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025 oct12th\Projects\VisaNet Authorization-Only Acquirer Processor Apr 2025 oct12th AIX7.3\VisaNet Authorization-Only Acquirer Processor Apr 2025 oct12th.xts)
                - name: runReverseValidation
                  type: String
                  value: <+input>.selectOneFrom(true,false)
                - name: hostname
                  type: String
                  value: <+input>.selectOneFrom(vlmazistdev102.fidev.local,vlmazistqc100.fidev.local,maa5afiistap04.fnfi.com,maa5afiistap06.fnfi.com)
    variables:
      - name: TARGET_SERVER
        type: String
        description: Choose the target server for deployment or update.
        required: true
        value: <+input>
      - name: USER_ACCOUNT
        type: String
        description: Select the user account to perform the deployment.
        required: true
        value: <+input>
      - name: ARTIFACT_TOOL_URL
        type: String
        description: URL path to download the `build_env` and `overriding_option_installer` scripts based on OS type.
        required: false
        value: https://artifactory.fi.dev/artifactory/emeaistswitch-generic-release/rel_tgz/tools/
      - name: CONTINUE_SP_FO
        type: String
        description: Continue with Service Packs for FO (0 for No, 1 for Yes)
        required: true
        value: "yes"
      - name: CONTINUE_SP_SW
        type: String
        description: Continue with Service Packs for SW (0 for No, 1 for Yes)
        required: true
        value: "yes"
      - name: CONFIRM_INSTALL
        type: String
        description: " Enter whether to confirm the installation 0 for Yes, 1 for No"
        required: true
        value: "yes"
      - name: FRESH_INSTALLATION
        type: String
        description: Select 'Yes' to perform a fresh installation, or select 'No' to proceed with an update.
        required: true
        value: <+input>.selectOneFrom(Yes,No)
      - name: JFROG_USER
        type: Secret
        description: Artifactory username for JFrog access.
        required: true
        value: <+input>
      - name: JFROG_PASS
        type: Secret
        description: Artifactory password for JFrog access.
        required: true
        value: <+input>
      - name: LICENSE_SETUP
        type: String
        description: |-
          A flag to indicate whether license setup should be executed during the deployment process.

          Yes: Run license setup steps.
          No: Skip license setup steps.
        required: true
        value: <+input>.default(No).selectOneFrom(Yes,No)
      - name: Deployment_Env
        type: String
        description: Provide the Deployment Environment
        required: true
        value: <+input>.selectOneFrom(dev,qc)
      - name: ISTPARAMS_JFROG
        type: String
        description: Istparam.cgf jfrog url
        required: true
        value: <+input>.default(https://artifactory.fi.dev/artifactory/emeaistswitch-generic-snapshot-local/rel_zip/release/istparam.cfg)
      - name: NOTIFY_TO
        type: String
        description: Primary recipient email address for pipeline notifications.
        required: true
        value: <+input>
      - name: NOTIFY_CC
        type: String
        description: Optional CC email address for pipeline notifications.
        required: false
        value: <+input>
      - name: USE_DMKLINK
        type: String
        description: Yes, for install without clean DB
        required: true
        value: <+input>.default(No).selectOneFrom(Yes,No)
      - name: HOME_PATH
        type: String
        description: Specify the HOME PATH for deployment. If left blank, the pipeline automatically sets it based on user_account and env.
        required: false
        value: <+input>
    allowStageExecutions: true
    delegateSelectors:
      - mcp-useast2lev1-dev
    timeout: 1d
    notificationRules: []
  identifier: ISTSWITCHNBTemplate
  versionLabel: Version1
  description: |-
    Project: IST-SWITCH
    Pipelines: IST-Switch-QC-NB and IST-Switch-Dev-NB Deployment Pipelines
  tags: {}

----------------------rcc pipeline download stage reference-------------------------------------------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'

cd <+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>
echo "Current user: $(whoami)"

current_user=$(whoami)
os_type=$(uname)

# # Set PATH for specific users regardless of OS
# if [ "$current_user" = "iswtqa1" ] || [ "$current_user" = "iswtqa3" ]; then
#   export PATH="/ist_qa/iswtqa1/lib:$PATH"
# fi
# Set proxy only for AIX users
if [ "$os_type" = "AIX" ]; then
  export http_proxy="http://10.236.163.21:8080/"
  export https_proxy="http://10.236.163.21:8080/"
fi

# Make scripts executable
chmod +x build_env
chmod +x overriding_option_installer

#LABEL_SELECTOR="<+pipeline.variables.LABEL_SELECTOR>"
LABEL_SELECTOR="<+pipeline.variables.LABEL_SELECTOR>"
BLOCK_SELECTION="<+pipeline.variables.BLOCK_SELECTION>"
OS_FLAVOR="<+pipeline.variables.SERVER_FLAVOR>"
COMPONENTS_NAME="<+pipeline.variables.COMPONENTS_NAME>"
OS_TYPE="<+pipeline.variables.OS_TYPE>"
DB="<+pipeline.variables.DB>"
OUTPUT_DIR="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Artifact_Download_directory>"
#OUTPUT_DIR=/ist_qa/iswtqa1/INT/harness/qa/switch/tgz
JFROG_URL="<+pipeline.variables.JFROG_URL>"

# Detect actual OS flavor
actual_os_flavor=$(uname)
echo "osflavor is: $actual_os_flavor"

case "$actual_os_flavor" in
  Linux) actual_flavor="LIN" ;;
  AIX) actual_flavor="AIX" ;;
  *) echo "Unsupported OS: $actual_os_flavor"; exit 1 ;;
esac

# Extract prefix from OS_FLAVOR (e.g., LIN from LIN-4180-i686-64)
pipeline_flavor_prefix=$(echo "$OS_FLAVOR" | cut -d'-' -f1)

echo "Pipeline OS_FLAVOR: $OS_FLAVOR"
echo "Extracted pipeline flavor: $pipeline_flavor_prefix"
echo "Actual server flavor: $actual_flavor"

# Compare and act
if [ "$pipeline_flavor_prefix" != "$actual_flavor" ]; then
  echo "Mismatch between pipeline OS_FLAVOR ($OS_FLAVOR) and actual server OS ($actual_flavor). Skipping artifact download."
  exit 1
fi

echo "OS flavor matches. Proceeding with artifact download..."



export BLOCK_SELECTION_RAW="$BLOCK_SELECTION"
export COMPONENTS_NAME_RAW="$COMPONENTS_NAME"

#export BLOCK_SELECTION="${BLOCK_SELECTION_RAW//,/ }"
#export COMPONENTS_NAME="${COMPONENTS_NAME_RAW//,/ }"

BLOCK_SELECTION=$(echo "$BLOCK_SELECTION_RAW" | sed 's/,/ /g')
COMPONENTS_NAME=$(echo "$COMPONENTS_NAME_RAW" | sed 's/,/ /g')
export BLOCK_SELECTION
export COMPONENTS_NAME



#echo "BLOCK_SELECTION=$BLOCK_SELECTION"
#echo "COMPONENTS_NAME=$COMPONENTS_NAME"

artifact_scv_acc="<+secrets.getValue('org.hcv_artifactory_username')>"
artifact_svc_pass="<+secrets.getValue('org.hcv_artifactory_pass')>"

file_content2="<+fileStore.getAsString('org:/<+pipeline.stages.Download_Build_env_and_Override_Installer_files.spec.configFiles.configfile.gitFiles[0].fileContent>')>"

echo "Dynamic content: $file_content2"
echo "$file_content2" > "$LABEL_SELECTOR"

cd "$OUTPUT_DIR" || { echo "Failed to change directory to $OUTPUT_DIR"; exit 1; }

echo "$file_content2" > "$LABEL_SELECTOR"  # [MOVED AFTER cd] [ADDED]

echo "Checking if LABEL_SELECTOR file exists: $LABEL_SELECTOR"  # [ADDED]
ls -l "$LABEL_SELECTOR" || echo "File not found!"  # [ADDED]
cat "$LABEL_SELECTOR" || echo "File is empty or unreadable!"  # [ADDED]


for block in $BLOCK_SELECTION; do
    echo "Extracting and transforming block: $block"

    awk -v blk="$block" -v flavor="$OS_FLAVOR" -v db="$DB" '
    index($0, blk ": [") {
        print blk ": ["
        in_block = 1
        next
    }
    in_block {
        if ($0 ~ /]/) {
            print "]"
            in_block = 0
            next
        }
        gsub(/_OS_/, "_" flavor "_")
        if ($0 ~ /_DB(_P0[0-9])?/) {
            suffix = ""
            if ($0 ~ /_DB_P0[0-9]/) {
                match($0, /_DB_P0[0-9]/)
                suffix = substr($0, RSTART + 3, RLENGTH - 3)
            }
            sub(/_DB(_P0[0-9])?/, "_" db suffix)
        }
        gsub(/,?[[:space:]]*$/, ".tgz,")
        print $0
    }
    ' "$LABEL_SELECTOR" | sed '$s/,\]$/\]/' > "${OUTPUT_DIR}/${block}.txt"

    if [ -s "${OUTPUT_DIR}/${block}.txt" ]; then
        echo "Saved transformed block '$block' to ${OUTPUT_DIR}/${block}.txt"
    else
        echo "Block '$block' not found or empty in $LABEL_SELECTOR"
        rm -f "${OUTPUT_DIR}/${block}.txt"
    fi
done

RELEASE_LIST_FILE="${OUTPUT_DIR}/releaselist.txt"
> "$RELEASE_LIST_FILE"

for block in $BLOCK_SELECTION; do
    BLOCK_FILE="${OUTPUT_DIR}/${block}.txt"
    if [ -f "$BLOCK_FILE" ]; then
        echo "Checking components in $BLOCK_FILE"
        while IFS= read -r line; do
            clean_line=$(echo "$line" | sed 's/^[[:space:]]*//;s/[[:space:]]*,[[:space:]]*$//')

            echo "$clean_line" | grep -qE "^FO_[0-9]+\.[0-9]+\.[0-9]+.*\.tgz$" && echo "$clean_line" >> "$RELEASE_LIST_FILE" && continue
            echo "$clean_line" | grep -qE "^(SW_|MA_|CL_).*(BASE|SEGMENT|ZCLOPTMZD)(_P0[1-9])?\.tgz$" && echo "$clean_line" >> "$RELEASE_LIST_FILE" && continue

            for component in $COMPONENTS_NAME; do
                echo "$clean_line" | grep -qE "${OS_FLAVOR}.*_${component}(_P0[0-9]+)?\.tgz$" && echo "$clean_line" >> "$RELEASE_LIST_FILE" && break
            done
        done < "$BLOCK_FILE"
    fi
done

if [ -s "$RELEASE_LIST_FILE" ]; then
    echo "Release list created at: $RELEASE_LIST_FILE"
else
    echo "No matching components found for: $COMPONENTS_NAME"
fi

PRODUCT_VERSION=""
while IFS= read -r line; do
    echo "$line" | grep -E "^(SW|MA|CL)_[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+_${OS_FLAVOR}" >/dev/null 2>&1
    if [ $? -eq 0 ]; then
        PRODUCT_VERSION=$(echo "$line" | cut -d'_' -f2)
        export PRODUCT_VERSION
        echo "Extracted PRODUCT_VERSION: $PRODUCT_VERSION"
        break
    fi
done < "$RELEASE_LIST_FILE"


files=""
while IFS= read -r line; do
  files="$files $line"
done < "$RELEASE_LIST_FILE"

#BASE_URL="https://artifactory.fi.dev/artifactory/emeaistswitch-generic-release-local/rel_tgz/release/${OS_TYPE}/"
BASE_URL="${JFROG_URL}"
echo "base url is:$BASE_URL"

downloaded_files=""

for FILE in $files; do
  OUTPUT_FILE="${OUTPUT_DIR}/${FILE}"
  HTTP_STATUS=$(curl -u "$artifact_scv_acc:$artifact_svc_pass" -o "${OUTPUT_FILE}" -w "%{http_code}" "${BASE_URL}${FILE}")
  if [ "$HTTP_STATUS" -ne 200 ]; then
    echo "Error downloading: ${FILE} (HTTP Status: $HTTP_STATUS)"
    rm -f "${OUTPUT_FILE}"
    exit 1
  fi
  echo "Downloaded: ${FILE}"
  downloaded_files="$downloaded_files $FILE"
done

echo "Files downloaded:"
for FILE in $downloaded_files; do
  echo "$FILE"
done

echo "Artifacts downloaded successfully"
ls -l

------------------------prepare regression excel config-----------------------------------------selenium-------------------------------

   

# Enable verbose mode
$VerboseMode = $true
$logFile = "<+stage.variables.Driversheetlogfile>"

function Write-Log {
    param ([string]$message)
    $timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
    $logMessage = "$timestamp - $message"
    Add-Content -Path $logFile -Value $logMessage
    if ($VerboseMode) { Write-Output $logMessage }
}

Write-Log "üöÄ Script started."

# Get OS flavor from Harness output
$osFlavor = "<+pipeline.stages.CLRSeleniumtesting.spec.execution.steps.Selenium_PreTesting_0.output.outputVariables.os_flavor>"

$clrAppVersion = "<+stage.variables.ClrAppVersion>"
$originalExcelPath = "<+stage.variables.TestingType>\MiniRegressionDriverExcel.xlsx"

###Getting Xlsx file with flavoured OS

# Getting Xlsx file with flavoured OS
$flavoredXlsxName = "<+stage.variables.UserInputExcel>_${clrAppVersion}_${osFlavor}.xlsx"
$CLRDriverSheetXlsxFilePath = "<+stage.variables.DestinationExcel>\${flavoredXlsxName}"       #$TestingType = "D:\Harness\ExcelDriverSheet\Full_Regression_Testing" "D:\Harness\ExcelDriverSheet\Full_Regression_Testing\MiniRegressionDriver_MultiInst_MAS1.4_OJA_PH4.xlsx"
# Copy and Rename the file into destination folder
Copy-Item -Path $originalExcelPath -Destination $CLRDriverSheetXlsxFilePath -Force
Write-Output "‚úÖ Excel file copied and renamed to: $CLRDriverSheetXlsxFilePath"


## Getting Xls file with flavoured OS
$flavoredXlsName = "<+stage.variables.UserInputExcel>_${clrAppVersion}_${osFlavor}.xls"
$CLRDriverSheetXlsFilePath = "<+stage.variables.DestinationExcel>\${flavoredXlsName}"
# Copy and Rename the file into destination folder
Copy-Item -Path $originalExcelPath -Destination $CLRDriverSheetXlsFilePath -Force
Write-Output "‚úÖ Excel file copied and renamed to: $CLRDriverSheetXlsFilePath"

Write-Log "‚úÖ Working with Excel file: $CLRDriverSheetXlsxFilePath"

try {
    # Runtime inputs
    $profilePath = ". <+pipeline.stages.CLRSeleniumtesting.spec.execution.steps.Selenium_PreTesting_0.output.outputVariables.Profile_path>"       
    $fileLocation = "<+pipeline.stages.CLRSeleniumtesting.spec.execution.steps.Selenium_PreTesting_0.output.outputVariables.HOME>"  
    Write-Output "Home path is $fileLocation"  
    Write-Output "profile path is $profilePath" 


    # Kill any running Excel processes
    try {
      Get-Process -Name "EXCEL" -ErrorAction SilentlyContinue | Stop-Process -Force
      Write-Log "üßπ Killed existing Excel processes to avoid file lock issues."
    } catch {
      Write-Log "‚ö†Ô∏è Failed to kill Excel processes: $_"
    }

    # Open Excel package
    $pkg = Open-ExcelPackage -Path $CLRDriverSheetXlsxFilePath
    $regSheet = $pkg.Workbook.Worksheets["REGTestData"]
    $serverSheet = $pkg.Workbook.Worksheets | Where-Object { $_.Name.Trim() -eq "ServerBoxDetails" }

    # Update REGTestData sheet
    for ($row = 1; $row -le $regSheet.Dimension.Rows; $row++) {
        for ($col = 1; $col -le $regSheet.Dimension.Columns; $col++) {
            $cell = $regSheet.Cells[$row, $col]
            if ($cell.Text -like "*Mini_Regression_Files*") {
                $oldValue = $cell.Text
                $cell.Value = "$fileLocation/Mini_Regression_Files/<+stage.variables.subFolder>"
                Write-Log "üîÑ Updated REGTestData [$row,$col] from '$oldValue' to '$($cell.Value)'"
            }
        }
    }

    Write-Log "Starting update ServerBoxDetails..."
    $userAccount = "<+pipeline.variables.USER_ACCOUNT>"

    # Calculate last row dynamically
    $lastRow = ($serverSheet.Cells | ForEach-Object { $_.Start.Row } | Measure-Object -Maximum).Maximum
    Write-Log "üìê ServerBoxDetails last row: $lastRow"

    # Check if userAccount exists
    $existingRow = $null
    for ($row = 2; $row -le $lastRow; $row++) {  # Start from 2 to skip header
        $boxName = $serverSheet.Cells[$row, 2].Text.Trim()
        Write-Log "Row ${row}: BoxName='$boxName'"
        if ($boxName.ToLower() -eq $userAccount.ToLower()) {
            $existingRow = $row
            break
        }
    }

    if ($existingRow) {
        # Update existing row
        $oldPath = $serverSheet.Cells[$existingRow, 3].Text
        $serverSheet.Cells[$existingRow, 3].Value = $profilePath
        Write-Log "‚úÖ Updated ServerBoxDetails [$existingRow,3] from '$oldPath' to '$profilePath'"
    } else {
        # Insert new row
        $newRow = $lastRow + 1
        $serverSheet.Cells[$newRow, 1].Value = $newRow - 1  # RowNum
        $serverSheet.Cells[$newRow, 2].Value = $userAccount
        $serverSheet.Cells[$newRow, 3].Value = $profilePath
        Write-Log "‚úÖ Added new row ${newRow}: RowNum='${newRow - 1}', UserName='$userAccount', ProfilePath='$profilePath'"
    }

    # Save and close Excel package
    Close-ExcelPackage -ExcelPackage $pkg
    Write-Log "‚úÖ Excel file updated and saved."

} catch {
    Write-Log "‚ùå Unexpected error during Excel update: $_"
}

# Delay to ensure file handles are released
Start-Sleep -Seconds 2

try {
    # Convert .xlsx to .xls using the JAR tool via cmd.exe
    $jarPath = "<+stage.variables.ConversionJarPath>"
    $inputFile = "$CLRDriverSheetXlsxFilePath"
    $outputFile = "$CLRDriverSheetXlsFilePath"

    Write-Log "üöÄ Starting XLSX to XLS conversion using cmd.exe..."

    $cmd = "java -jar `"$jarPath`" `"$inputFile`" `"$outputFile`""
    Start-Process -FilePath "cmd.exe" `
        -ArgumentList "/c $cmd" `
        -WorkingDirectory "D:\Conversion" `
        -NoNewWindow -Wait

    Write-Log "‚úÖ Conversion completed from Xlsx to Xls using cmd.exe."

} catch {
    Write-Log "‚ùå Conversion failed: $_"
}


Write-Log "üèÅ Script completed."
Write-Log "üìä Summary:"
Write-Log "‚û° Edited file: $CLRDriverSheetXlsxFilePath"
Write-Log "‚úÖ REGTestData and ServerBoxDetails updated successfully"
Write-Log "‚úÖ Script completed successfully with ExitCode 0"


-----------------------------------------------------------prepare workspace seleniu server------------------------------

# Runtime inputs from Harness
$repoName = "<+stage.variables.repoName>"                            
$branchName = "<+stage.variables.SeliniumBranch>"   
$workspaceName = "<+pipeline.variables.USER_ACCOUNT>"        
$userName = "<+stage.variables.BBSvcAcc>"

Write-Output "git user name: $userName"
$password = "<+stage.variables.BBSvcAccPwd>"
Write-Output "git user passwd: $password"
$clrAppVersion = "<+stage.variables.ClrAppVersion>"   

# Clearing application credentials
$CLRUnixBox = "<+stage.variables.TARGET_SERVER_IP>"       
$ClearingVersion = "<+stage.variables.ClearingVersion>"           
$CLRStaffUserName = "<+pipeline.variables.USER_ACCOUNT>"        
$CLRStaffPassword = "<+stage.variables.Appuserpassword>"                
$CLRUnixUserName = "<+pipeline.variables.USER_ACCOUNT>"                                   
$CLRUnixPassword = "<+stage.variables.Appuserpassword>"  

# DB credentials
$CLRDBType = "<+pipeline.stages.Pdeploy_Execution.variables.Database_vendor>"
$CLRDBIP = "<+pipeline.stages.Pdeploy_Execution.variables.DB_server>"                       
$CLRDBPort = "<+pipeline.stages.Pdeploy_Execution.variables.DB_port>"
$CLRDBService = "<+pipeline.stages.Pdeploy_Execution.variables.Database_tns_name>"
$CLRDBUserName = "<+pipeline.stages.Pdeploy_Execution.variables.Owner_dbuser>"      
$CLRDBPassword = "<+pipeline.stages.Pdeploy_Execution.variables.Owner_dbpassword>"
$CLRDBTypeValue = "<+stage.variables.DBType>"
$CLRDBName = "<+stage.variables.DBName>"

$osFlavor = "<+pipeline.stages.CLRSeleniumtesting.spec.execution.steps.Selenium_PreTesting_0.output.outputVariables.os_flavor>"

$CLRDriverSheetFilePath = "<+stage.variables.DestinationExcelDoubleslash>\\<+stage.variables.UserInputExcel>_${clrAppVersion}_${osFlavor}.xls"
$CLRDriverSheetName = "<+stage.variables.UserInputExcel>_${clrAppVersion}_${osFlavor}.xls" 

# Paths
$clonePath = "<+stage.variables.CloningPath>" 
$targetPath = "<+stage.variables.TargetPath>"  

# Check and delete subfolders under $targetPath\$workspaceName
$workspaceNamePath = Join-Path $targetPath $workspaceName           #D:\Harness\SeleniumRegression\strauss1
$workspaceFolderPath = Join-Path $workspaceNamePath $repoName       #D:\Harness\SeleniumRegression\strauss1\clearing25

foreach ($path in @($workspaceFolderPath, $workspaceNamePath)) {
    if (Test-Path $path) {
        Remove-Item -Path $path -Recurse -Force
        Write-Output "Deleted existing folder: $path"
    }
}

# Disable Git credential helper to avoid wincredman error
git config --global credential.helper ""

# Encode password to handle special characters
Add-Type -AssemblyName System.Web
$encodedPassword = [System.Web.HttpUtility]::UrlEncode($password)

# Construct repo URL
$repoUrl = "https://${userName}:${encodedPassword}@bitbucket.fi.dev/scm/istqatools/${repoName}.git"
Write-Output "Repo URL: $repoUrl"


# Optional: Remove branch if not set
if (-not $branchName) {
    Write-Output "Branch name not provided. Defaulting to main branch."
}

# Retry logic
$maxAttempts = 3
$attempt = 1
$success = $false

while (-not $success -and $attempt -le $maxAttempts) {
    Write-Output "Clone attempt $attempt of $maxAttempts..."

    try {
        # Create clone path if it doesn't exist
        if (-not (Test-Path $clonePath -PathType Container)) {
            New-Item -Path $clonePath -ItemType Directory | Out-Null
        }

        # Clean up previous contents
        Get-ChildItem -Path $clonePath -Recurse -Force | Remove-Item -Recurse -Force
        Write-Output "Cleaned up existing contents in: $clonePath"

        # Set location and clone
        Set-Location -Path $clonePath
        Write-Output "Current directory: $(Get-Location)"

        git clone -b $branchName $repoUrl
        
        if ($LASTEXITCODE -eq 0) {
            $success = $true
            Write-Output "Clone successful!"
        } else {
            throw "Git clone returned exit code $LASTEXITCODE"
        }

    } catch {
        Write-Output "Attempt $attempt failed: $_"
        if ($attempt -eq $maxAttempts) {
            Write-Output "Failed all clone attempts: $_"
            exit 1
        }
        Start-Sleep -Seconds 5
        $attempt++
    }
}


# Check contents of clone path before copying
Write-Output "Checking contents of ${clonePath}:"
if (Test-Path $clonePath) {
    $items = Get-ChildItem -Path $clonePath
    if ($items.Count -eq 0) {
        Write-Output "‚ö†Ô∏è No files found in ${clonePath}. Clone might have failed or repo is empty."
    } else {
        Write-Output "‚úÖ Found $($items.Count) items in ${clonePath}:"
        $items | ForEach-Object { Write-Output $_.FullName }
    }
} else {
    Write-Output "‚ùå Clone path does not exist: ${clonePath}"
}

# Create workspace folder inside target path
$workspaceFolder = Join-Path $targetPath $workspaceName                       #D:\Harness\SeleniumRegression\           eftpos4
if (-Not (Test-Path $workspaceFolder)) {
    New-Item -Path $workspaceFolder -ItemType Directory | Out-Null
    Write-Output "Created workspace folder: $workspaceFolder"                 #D:\Harness\SeleniumRegression\eftpos4
} else {
    Write-Output "Workspace folder already exists: $workspaceFolder"
}

# Copy contents from cloned repo to workspace folder
Write-Output "Copying contents from ${clonePath} to ${workspaceFolder}..."
Copy-Item -Path "$clonePath\*" -Destination $workspaceFolder -Recurse -Force

# Confirm copy
Write-Output "‚úÖ Copied repo contents to: ${workspaceFolder}"
Write-Output "Listing contents of ${workspaceFolder}:"
Get-ChildItem -Path $workspaceFolder | ForEach-Object { Write-Output $_.FullName }

# Update MiniSSHManager.java with dynamic CLRDriverSheetFilePath
$miniSSHManagerFile = "$workspaceFolder\$repoName\Clearing_Selenium_Workspace\$clrAppVersion\src\test\java\com\fi\global\common\utilities\MiniSSHManager.java"

if (Test-Path $miniSSHManagerFile) {
    Write-Output "Updating MiniSSHManager.java with dynamic DriverSheet path..."
    (Get-Content $miniSSHManagerFile) `
        -replace 'D:\\\\Harness\\\\ExcelDriverSheet\\\\MiniRegressionDriver_MultiInst_OJA_PH4.xls', $CLRDriverSheetFilePath |
        Set-Content $miniSSHManagerFile
    Write-Output "‚úÖ Updated MiniSSHManager.java successfully."
} else {
    Write-Output "‚ùå MiniSSHManager.java not found at: $miniSSHManagerFile"
}

# Path to MiniEnvironment.properties
$propertiesFile = "$workspaceFolder\$repoName\Clearing_Selenium_Workspace\$clrAppVersion\src\test\resources\Properties\MiniEnvironment.properties"
$regressionPath = "$workspaceFolder\$repoName\Clearing_Selenium_Workspace\$clrAppVersion"  #TO use it in next stage for testing
$env:RegressionPath = $regressionPath


# Generate DB URLs based on DB type
switch ($CLRDBType.ToLower()) {
    "oracle" {
        $CLRDBURL = "DBURL=jdbc:oracle:thin:@//${CLRDBIP}:${CLRDBPort}/${CLRDBService}"
        $PostgresDBURL = "#PostgresDBURL=jdbc:postgresql://<placeholder>"
    }
    "mysql" {
        $CLRDBURL = "DBURL=jdbc:mysql://${CLRSDBIP}:${CLRDBPort}/${CLRDBService}"
        $PostgresDBURL = "#PostgresDBURL=jdbc:postgresql://<placeholder>"
    }
    "pgsql" {
        $CLRDBURL = "#DBURL=jdbc:oracle:thin:@//<placeholder>"
        $PostgresHost = "<+stage.variables.DBhostFullName>"
        $PostgresDBURL = "PostgresDBURL=jdbc:postgresql://${CLRDBIP}:${CLRDBPort}/${CLRDBName}"
    }
    default {
        Write-Output "Unsupported DB type: $CLRDBType"
        exit 1
    }
}


# Update MiniEnvironment.properties
if (Test-Path $propertiesFile) {
    (Get-Content $propertiesFile) |
        ForEach-Object {
            $_ -replace '^UnixBox=.*', "UnixBox=$CLRUnixBox" |
            % { $_ -replace '^StaffUserName=.*', "StaffUserName=$CLRStaffUserName" } |
            % { $_ -replace '^StaffPassword=.*', "StaffPassword=$CLRStaffPassword" } |
            % { $_ -replace '^UnixUserName=.*', "UnixUserName=$CLRUnixUserName" } |
            % { $_ -replace '^UnixPassword=.*', "UnixPassword=$CLRUnixPassword" } |
            % { $_ -replace '^ClearingVersion=.*', "ClearingVersion=$ClearingVersion" } |
            % { $_ -replace '^DBType=.*', "DBType=$CLRDBTypeValue" } |
            % { $_ -replace '^DBURL=.*', $CLRDBURL } |
            % {
                if ($CLRDBType.ToLower() -eq "pgsql") {
                    $_ -replace '^DBUserName=.*', "#DBUserName=$CLRDBUserName"
                } else {
                    $_ -replace '^DBUserName=.*', "DBUserName=$CLRDBUserName"
                }
            } |
            % {
                if ($CLRDBType.ToLower() -eq "pgsql") {
                    $_ -replace '^DBPassword=.*', "#DBPassword=$CLRDBPassword"
                } else {
                    $_ -replace '^DBPassword=.*', "DBPassword=$CLRDBPassword"
                }
            } |
            % {
                if ($CLRDBType.ToLower() -eq "oracle" -or $CLRDBType.ToLower() -eq "mysql") {
                    $_ -replace '^PostgresDBUserName=.*', "#PostgresDBUserName=$CLRDBUserName"
                } else {
                    $_ -replace '^PostgresDBUserName=.*', "PostgresDBUserName=$CLRDBUserName"
                }
            } |
            % {
                if ($CLRDBType.ToLower() -eq "oracle" -or $CLRDBType.ToLower() -eq "mysql") {
                    $_ -replace '^PostgresDBPassword=.*', "#PostgresDBPassword=$CLRDBPassword"
                } else {
                    $_ -replace '^PostgresDBPassword=.*', "PostgresDBPassword=$CLRDBPassword"
                }
            } |
            % { $_ -replace '^DriverSheetPath=.*', "DriverSheetPath=$CLRDriverSheetFilePath" } |
            % { $_ -replace '^DriveSheetName=.*', "DriveSheetName=$CLRDriverSheetName" }
        } | Set-Content $propertiesFile

    # Add PostgresDBURL line (active or commented)
    if (-not (Select-String -Path $propertiesFile -Pattern '^PostgresDBURL')) {
        Add-Content -Path $propertiesFile -Value $PostgresDBURL
    } else {
        (Get-Content $propertiesFile) |
            ForEach-Object { $_ -replace '^PostgresDBURL=.*', $PostgresDBURL } |
            Set-Content $propertiesFile
    }

    Write-Output "‚úÖ Updated MiniEnvironment.properties"
} else {
    Write-Output "‚ùå Properties file not found: $propertiesFile"
    exit 1
}


Write-Output "Workspace preparation complete: $workspaceFolder"


----------------------------------------------------------selenium regression testing----------------------------------


$timestamp = Get-Date -Format "yyyyMMdd_HHmmss"
$regressionPath = "<+pipeline.stages.CLRSeleniumtesting.spec.execution.steps.Prepare_Workspace_Selenium_Server.output.outputVariables.RegressionPath>"
Write-Output "$regressionPath"

$sourceHtml = "$regressionPath\target\surefire-reports\emailable-report.html"
$sourceExcelReportFolder = "<+stage.variables.sourceExcelReportFolder>"              
$backupFolder = "<+stage.variables.BackupFolder>"

# Get OS flavor from Harness output
$osFlavor = "<+pipeline.stages.CLRSeleniumtesting.spec.execution.steps.Selenium_PreTesting_0.output.outputVariables.os_flavor>"

# Running As a Service account User

$whoami = whoami

Write-Output "$whoami"

# Change directory to the location of your project

Set-Location -Path $regressionPath

# Run Maven Test
mvn clean

Write-Output "Maven testing starts"

mvn test -e

# Check the exit code of the Maven command

if ($LASTEXITCODE -ne 0) {

    Write-Host "Maven command failed with exit code $LASTEXITCODE"

    exit 1

}

Write-Host "Maven build successful. Waiting 20 seconds for report file to be generated..."

Start-Sleep -Seconds 5

# Ensure backup folder exists
if (-not (Test-Path $backupFolder)) {
    New-Item -Path $backupFolder -ItemType Directory
    Write-Output "Backup folder created."
} else {
    Write-Output "Backup folder already exists."
}

# Backup HTML report
$destinationHtml = Join-Path $backupFolder "emailable-report_$timestamp.html"   #D:\Harness\ReportsBackup\emailable-report_$timestamp.html
Copy-Item -Path $sourceHtml -Destination $destinationHtml -Force                #D:\Harness\SeleniumRegression\strauss1\mas14\MAS_Selenium_Workspace\MAS1.4\target\surefire-reports\emailable-report.html    into   D:\Harness\ReportsBackup  
Write-Output "HTML report backed up to: $destinationHtml"


# Kill any running Excel processes
try {
    Get-Process -Name "EXCEL" -ErrorAction SilentlyContinue | Stop-Process -Force
    Write-Output "üßπ Killed existing Excel processes to avoid file lock issues."
    Start-Sleep -Seconds 5  # Allow OS to release file locks
} catch {
    Write-Output "‚ö†Ô∏è Failed to kill Excel processes: $_"
}

# Backup latest Excel report
$latestExcel = Get-ChildItem -Path $sourceExcelReportFolder -Filter "ResultSummary_*.xls" -File |
               Sort-Object LastWriteTime -Descending |
               Select-Object -First 1

if ($latestExcel) {
    $destinationExcel = Join-Path $backupFolder ("ResultSummary_$timestamp.xls")
    try {
        Move-Item -Path $latestExcel.FullName -Destination $destinationExcel -Force
        Write-Output "Excel report backed up to: $destinationExcel"
    } catch {
        Write-Output "Failed to back up Excel report. Error: $_"
    }
} else {
    Write-Output "No Excel report found in: $sourceExcelReportFolder"
}

# Parse HTML report
[xml]$htmlContent = Get-Content $destinationHtml
$rows = $htmlContent.getElementsByTagName("tr")
$summary = @()
Write-Output "Parsing HTML report for test summary..."

foreach ($row in $rows) {
    $cells = $row.getElementsByTagName("td")
    if ($cells.Count -ge 5) {
        $summaryItem = [PSCustomObject]@{
            Test    = $cells[0].InnerText
            Passed  = [int]$cells[1].InnerText
            Skipped = [int]$cells[2].InnerText
            Retried = [int]$cells[3].InnerText
            Failed  = [int]$cells[4].InnerText
        }
        $summary += $summaryItem
        Write-Output "Parsed row: $($summaryItem.Test) | Passed: $($summaryItem.Passed), Skipped: $($summaryItem.Skipped), Retried: $($summaryItem.Retried), Failed: $($summaryItem.Failed)"
    }
}

# Summarize test results
$totalTests = ($summary | Measure-Object).Count
$passedTests = ($summary | Measure-Object -Property Passed -Sum).Sum
$failedTests = ($summary | Measure-Object -Property Failed -Sum).Sum
$skippedTests = ($summary | Measure-Object -Property Skipped -Sum).Sum

# Export output variables for Harness
Write-Output "Exporting output variables for Harness..."
echo "tests=$totalTests" >> $env:HARNESS_OUTPUT_PATH
echo "passed=$passedTests" >> $env:HARNESS_OUTPUT_PATH
echo "failures=$failedTests" >> $env:HARNESS_OUTPUT_PATH
echo "errors=$skippedTests" >> $env:HARNESS_OUTPUT_PATH

# Email setup
$Subject = "Selenium Test Results - <+stage.variables.ClrAppVersion>"
$SMTPServer = "<+stage.variables.SMTPServer>"                       
$Port = 25
$EmailFrom = "<+stage.variables.EmailFrom>"                                    
$EmailTo = "<+stage.variables.EmailTo>"  

# Collect attachments
$Attachments = @()
$Attachments += $destinationHtml

# Attach only the latest Excel file
$latestExcelBackup = Get-ChildItem -Path $backupFolder -Filter *.xls -File |
                     Sort-Object LastWriteTime -Descending |
                     Select-Object -First 1

if ($latestExcelBackup) {
    $Attachments += $latestExcelBackup.FullName
}


# Compose email body
$Body = @"
<html>
<body>
<h2>Selenium Test Results Summary</h2>
<p><strong>Total Tests:</strong> $totalTests</p>
<p><strong>Passed:</strong> $passedTests</p>
<p><strong>Failed:</strong> $failedTests</p>
<p><strong>Skipped:</strong> $skippedTests</p>
<p><strong>Running on OS:</strong> $osFlavor</p>
<p>Reports are attached and also backed up at: <br><code>$backupFolder</code></p>
<p><strong>Harness Pipeline URL:</strong><br><a href="<+pipeline.executionUrl>">View Execution</a></p>
</body>
</html>
"@

# Send email
try {
    Send-MailMessage -From $EmailFrom -To $EmailTo -SmtpServer $SMTPServer -Port $Port `
        -Subject $Subject -Body $Body -Attachments $Attachments -BodyAsHtml
    Write-Host "‚úÖ Email sent successfully to $EmailTo"
} catch {
    Write-Host "‚ùå Failed to send email: $_"
    exit 1
}

-----------------------------------------------ots insert db---------------------------------------------------------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'

echo "Switched to user: $(whoami)"


# Step 1: Dynamically create .tnsnames.ora using Harness stage variables

HOME="<+pipeline.stages.OTSPreTest.spec.execution.steps.Set_Up_Environment.output.outputVariables.Working_Directory>"
NODE="<+pipeline.stages.OTSPreTest.spec.execution.steps.Set_Up_Environment.output.outputVariables.NODE>"

cd "$HOME"
if [ $? -ne 0 ]; then
    echo "[ERROR] Failed to change to HOME directory: $HOME"
    exit 1
fi

pwd

tnsnames_content="<+stage.variables.Database_name> =
  (DESCRIPTION =
    (ADDRESS = (PROTOCOL = TCP)(HOST = <+stage.variables.DB_server>)(PORT = <+stage.variables.DB_port>))
    (CONNECT_DATA =
      (SERVER = DEDICATED)
      (SERVICE_NAME = <+stage.variables.Database_name>)
    )
  )"

echo "$tnsnames_content" > .tnsnames.ora
chmod 755 .tnsnames.ora
export TNS_ADMIN=$(pwd)
echo "‚úÖ .tnsnames.ora file has been created and content inserted."

# Step 3: Get TNS name
TNS_NAME="<+stage.variables.Database_name>"

if [ -z "$TNS_NAME" ]; then
  echo "‚ùå Error: TNS name not set in environment ($TNS_NAME)"
  exit 1
fi

# # Check if Database_vendor is oracle
# if [ "<+stage.variables.Database_vendor>" = "oracle" ]; then
#   # Define the content to be inserted into the .tnsnames.ora file
#   tnsnames_content="<+stage.variables.Database_name> =
#     (DESCRIPTION =
#       (ADDRESS = (PROTOCOL = TCP)(HOST = <+stage.variables.DB_server>)(PORT = <+stage.variables.DB_port>))
#       (CONNECT_DATA =
#         (SERVER = DEDICATED)
#         (SERVICE_NAME = <+stage.variables.Database_name>)
#       )
#     )"

#   # Create the .tnsnames.ora file and insert the content
#   echo "$tnsnames_content" > .tnsnames.ora

#   # Set permissions
#   chmod 755 .tnsnames.ora

#   # Export TNS_ADMIN to current directory
#   export TNS_ADMIN=$(pwd)

#   # Print a success message
#   echo "‚úÖ .tnsnames.ora file has been created and content inserted."

#   # Step 3: Get TNS name
#   TNS_NAME="<+stage.variables.Database_name>"

#   if [ -z "$TNS_NAME" ]; then
#     echo "‚ùå Error: TNS name not set in environment ($TNS_NAME)"
#     exit 1
#   fi
# else
#   echo "Database vendor is not Oracle. Skipping .tnsnames.ora creation."
# fi




# export HOME="$working"
# export ORACLE_HOME="$oracle"
# #export PATH=$ORACLE_HOME/bin:$PATH
# export JAVA_HOME="$java"
# export NODE="$NODE"

# fi
# echo "HOME is set to: $HOME"
# echo "ORACLE_HOME is set to: $ORACLE_HOME"
# echo "JAVA_HOME is set to: $JAVA_HOME"
# echo "NODE is set to: $NODE"


# ---------------------------------------
# Locate latest pdir and profile
# ---------------------------------------
latest_pdir=$(ls -td pdir20* 2>/dev/null | head -1)
latest_profile=$(ls -td profile20* 2>/dev/null | head -1)

if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
    echo "[WARNING] No pdir or profile found"
else
    echo "Latest profile file: $latest_profile"
    echo "Latest pdir directory: $latest_pdir"
fi

# Source the profile if present (provides NODE, etc.)
if [ -n "$latest_profile" ]; then
  . "./$latest_profile"
fi

# ---------------------------------------
# Variables common
# ---------------------------------------
ISSUER_BIN="<+stage.variables.ISSUER_BIN>"
ACQUIRER_BIN="<+stage.variables.ACQUIRER_BIN>"
mcportname="<+stage.variables.mcportname>"
visaportname="<+stage.variables.visaportname>"
mcportname2="<+stage.variables.mcportname2>"
visaportname2="<+stage.variables.visaportname2>"
run_db_queries="<+stage.variables.Run_DB_Queries>"

# Oracle creds
DB_USER="<+stage.variables.Owner_dbuser>"
DB_PASS="<+stage.variables.Owner_dbpassword>"
DB_NAME="<+stage.variables.Database_name>"

# Postgres creds
PG_DB_USER="<+stage.variables.pg_db_user>"
PG_DB_PWD="<+stage.variables.pg_db_pwd>"
PG_DB_SERVER="<+stage.variables.pg_db_server>"
PG_DB_PORT="<+stage.variables.pg_db_port>"
PG_DB_NAME="<+stage.variables.pg_db_name>"

# Cleanup creds (Oracle/PG)
KLCDB_USER="<+stage.variables.klc_db_user>"
KLCDB_PASS="<+stage.variables.klc_db_password>"

if [ "$run_db_queries" != "true" ]; then
  echo "[INFO] Skipping DB inserts as per configuration."
  exit 0
fi

echo "Executing DB inserts..."
echo "üîÑ Running one-time DB inserts for Mastercard ‚Üî Visa and Visa ‚Üî Mastercard setup"

# ---------------------------------------
# Detect DB type from TGZ_state.info
# ---------------------------------------
tgz_file="$latest_pdir/TGZ_state.info"
if [ ! -f "$tgz_file" ]; then
  echo "‚ùå TGZ_state.info not found in $latest_pdir"
  exit 1
fi

if grep -qi "ora" "$tgz_file"; then
  echo "üîé Detected Oracle DB from TGZ_state.info"
  db_type="oracle"
elif grep -qi "pgsql" "$tgz_file"; then
  echo "üîé Detected Postgres DB from TGZ_state.info"
  db_type="postgres"
else
  echo "‚ùå Could not detect DB type in TGZ_state.info ‚Äî must contain 'oracle' or 'pgsql'"
  exit 1
fi

# ---------------------------------------
# Build SQL files and execute per DB type
# ---------------------------------------
if [ "$db_type" = "oracle" ]; then
  # --------------------------
  # Oracle: MC ‚Üí VISA
  # --------------------------
  cat <<EOF_SQL > mctovisa_runtime.sql
-- ISS_PROFILE (MC ‚Üí VISA)
INSERT INTO ISS_PROFILE (
  TXNSRC, TXNDEST, ENTITY_ID, CARDPRODUCT, MSGTYPE, DEVICETYPE, PCODE, HASPIN,
  ISS_INST_ID, ISS_USERBIN_ID, PRIORITY, NODE, ROUTING_BIN, ROUTING_INST_ID, ADD_CONDITION
) VALUES (
  '05', '04', '*', '${mcportname}', '*', '*', '*', '*',
  '1', '${ISSUER_BIN}', 0, '${NODE}', NULL, NULL, NULL
);
-- Verification
SELECT * FROM ISS_PROFILE WHERE ISS_USERBIN_ID = '${ISSUER_BIN}';
SELECT * FROM ACQ_PROFILE WHERE ACQ_USERBIN_ID = '${ACQUIRER_BIN}';
SELECT * FROM SHCEXTBINDB WHERE CARDPRODUCT = '${mcportname}';
SELECT * FROM INST_PROFILE WHERE USERBIN_ID IN ('${ACQUIRER_BIN}', '${ISSUER_BIN}');
SELECT * FROM SHCBIN WHERE USERBINID IN ('${ISSUER_BIN}');
SELECT * FROM BINROUTE WHERE USERBINID IN ('${ISSUER_BIN}');

exit;
EOF_SQL
cat <<EOF_SQL2 > visatomc_runtime.sql
-- VISA ‚Üí MASTERCARD inserts

INSERT INTO ISS_PROFILE (
  TXNSRC, TXNDEST, ENTITY_ID, CARDPRODUCT, MSGTYPE, DEVICETYPE, PCODE, HASPIN,
  ISS_INST_ID, ISS_USERBIN_ID, PRIORITY, NODE, ROUTING_BIN, ROUTING_INST_ID, ADD_CONDITION
) VALUES (
  '04', '05', '*                                                           ', 'Visa_MC                                                     ',
  '*                                       ', '*  ', '*                                                                               ', '*',
  '1         ', '1314', NULL, NULL, NULL, NULL, NULL
);
-- Verification
SELECT * FROM ISS_PROFILE WHERE USERBIN_ID IN ('1314', '1413') AND TXNSRC = '04' AND TXNDEST = '05';
SELECT * FROM ACQ_PROFILE WHERE ACQ_USERBIN_ID = '1413' AND TXNSRC = '04' AND TXNDEST = '05';
SELECT * FROM SHCEXTBINDB WHERE CARDPRODUCT = 'Visa_MC' AND DESTINATION = '05';
SELECT * FROM INST_PROFILE WHERE USERBIN_ID IN ('1314', '1413') AND TXNSRC = '04' AND TXNDEST = '05';
SELECT * FROM SHCBIN WHERE USERBINID IN ('1314', '1413') AND NETWORKID IN ('1314', '1413');
SELECT * FROM BINROUTE WHERE USERBINID IN ('1314', '1413') AND NODE = '${NODE}';

exit;
EOF_SQL2

  echo "‚úÖ mctovisa_runtime.sql file has been created."
  echo "‚úÖ visatomc_runtime.sql file has been created"

  # Execute Oracle SQL
  sqlplus -s "${DB_USER}/${DB_PASS}@${TNS_NAME}" @mctovisa_runtime.sql
  if [ $? -ne 0 ]; then
    echo "‚ùå Failed to execute mctovisa_runtime.sql (Oracle)"
    exit 1
  fi

  sqlplus -s "${DB_USER}/${DB_PASS}@${TNS_NAME}" @visatomc_runtime.sql
  if [ $? -ne 0 ]; then
    echo "‚ùå Failed to execute visatomc_runtime.sql (Oracle)"
    exit 1
  fi

  # Cleanup (Oracle)
  cat <<EOF_SQL3 > cleanup.sql
WHENEVER SQLERROR EXIT SQL.SQLCODE
DELETE FROM MASTER_KEY_COMPONENTS;
COMMIT;
EXIT;
EOF_SQL3

  echo "Connecting as ${KLCDB_USER}@${TNS_NAME}"
  sqlplus -s "${KLCDB_USER}/${KLCDB_PASS}@${TNS_NAME}" @cleanup.sql
  if [ $? -ne 0 ]; then
      echo "‚ùå Failed to execute MASTER_KEY_COMPONENTS cleanup (Oracle)"
      exit 1
  fi
  echo "‚úÖ MASTER_KEY_COMPONENTS cleanup completed successfully"

  # Clean up temp files
  rm -f mctovisa_runtime.sql visatomc_runtime.sql cleanup.sql
  echo "‚úÖ Oracle DB inserts completed successfully."

elif [ "$db_type" = "postgres" ]; then
  # --------------------------
  # Postgres: MC ‚Üí VISA
  # --------------------------
  cat <<EOF_SQL > mctovisa_runtime.sql
-- ISS_PROFILE (MC ‚Üí VISA)
INSERT INTO ${PG_DB_USER}.iss_profile (
  txnsrc, txndest, entity_id, cardproduct, msgtype, devicetype, pcode, haspin,
  iss_inst_id, iss_userbin_id, priority, node, routing_bin, routing_inst_id, add_condition
) VALUES (
  '05', '04', '*', '${mcportname}', '*', '*', '*', '*',
  '1', '${ISSUER_BIN}', 0, '${NODE}', NULL, NULL, NULL
) ON CONFLICT DO NOTHING;

-- Verification
SELECT * FROM ${PG_DB_USER}.iss_profile WHERE iss_userbin_id = '${ISSUER_BIN}';
SELECT * FROM ${PG_DB_USER}.acq_profile WHERE acq_userbin_id = '${ACQUIRER_BIN}';
SELECT * FROM ${PG_DB_USER}.shcextbindb WHERE cardproduct = '${mcportname}';
SELECT * FROM ${PG_DB_USER}.inst_profile WHERE userbin_id IN ('${ACQUIRER_BIN}', '${ISSUER_BIN}');
SELECT * FROM ${PG_DB_USER}.shcbin WHERE userbinid IN ('${ISSUER_BIN}');
SELECT * FROM ${PG_DB_USER}.binroute WHERE userbinid IN ('${ISSUER_BIN}');
EOF_SQL

  # --------------------------
  # Postgres: VISA ‚Üí MC
  # --------------------------
  cat <<EOF_SQL2 > visatomc_runtime.sql
  
  echo "‚úÖ mctovisa_runtime.sql file has been created."
  echo "‚úÖ visatomc_runtime.sql file has been created"

  # Execute Postgres SQL
  PGPASSWORD="${PG_DB_PWD}" psql -v ON_ERROR_STOP=1 -U "${PG_DB_USER}" -h "${PG_DB_SERVER}" -p "${PG_DB_PORT}" -d "${PG_DB_NAME}" -f mctovisa_runtime.sql
  if [ $? -ne 0 ]; then
    echo "‚ùå Failed to execute mctovisa_runtime.sql (Postgres)"
    exit 1
  fi
  PGPASSWORD="${PG_DB_PWD}" psql -v ON_ERROR_STOP=1 -U "${PG_DB_USER}" -h "${PG_DB_SERVER}" -p "${PG_DB_PORT}" -d "${PG_DB_NAME}" -f visatomc_runtime.sql
  if [ $? -ne 0 ]; then
    echo "‚ùå Failed to execute visatomc_runtime.sql (Postgres)"
    exit 1
  fi

  # Cleanup (Postgres)
  cat <<EOF_PG3 > cleanup.sql
DELETE FROM ${PG_DB_USER}.master_key_components;
COMMIT;
EOF_PG3

  PGPASSWORD="${KLCDB_PASS}" psql -v ON_ERROR_STOP=1 -U "${KLCDB_USER}" -h "${PG_DB_SERVER}" -p "${PG_DB_PORT}" -d "${PG_DB_NAME}" -f cleanup.sql
  if [ $? -ne 0 ]; then
      echo "‚ùå Failed to execute MASTER_KEY_COMPONENTS cleanup (Postgres)"
      exit 1
  fi
  echo "‚úÖ MASTER_KEY_COMPONENTS cleanup completed successfully"

  # Clean up temp files
  rm -f mctovisa_runtime.sql visatomc_runtime.sql cleanup.sql
  echo "‚úÖ Postgres DB inserts completed successfully."
fi

EOF


-----------------------------------------------------------------------------setup env reference-------------------------------------------------
#!/bin/sh

# --- Step: Set environment variables based on Product_name or Pipeline name ---
product_name="<+pipeline.variables.product_name>"
pipeline_name="<+pipeline.name>"

# Condition 1: product_name = switch for RCC
if [ "$product_name" = "switch" ]; then
    export working="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
    export oracle="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.ORACLE_HOME>"
    export java="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.JAVA_HOME>"
    export NODE="<+pipeline.stages.setup_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Node_name>"
    echo "HOME is set to: $HOME"
    echo "ORACLE_HOME is set to: $ORACLE_HOME"
    echo "JAVA_HOME is set to: $JAVA_HOME"
    echo "NODE is set to : $NODE"
    echo "[INFO] Environment variables set from Harness for product: $product_name"

# Condition 2: pipeline_name = switch_dev for dev and qc NB pipelines
elif [ "$pipeline_name" = "IST-Switch-QC-NB" ]; then
    export working="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
    export oracle="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.ORACLE_HOME>"
    export java="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.JAVA_HOME>"
    export NODE="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Node_name>"
    echo "HOME is set to: $HOME"
    echo "ORACLE_HOME is set to: $ORACLE_HOME"
    echo "JAVA_HOME is set to: $JAVA_HOME"
    echo "NODE is set to : $NODE"
    echo "[INFO] Environment variables set from Harness for pipeline: $pipeline_name"
else
    server_name="<+pipeline.variables.TARGET_SERVER>"
    user_account="<+pipeline.variables.USER_ACCOUNT>"
    env="<+pipeline.variables.ENVIRONMENT>"
    echo "servername is: $server_name"
    echo "useraccount is: $user_account"
    echo "environment is $env"

case "$server_name" in
    "vlmazistqc100RHEL8")
        case "$user_account" in
            "strauss1")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/apps/$user_account/oracle/lin64_ora_199"
                java="/etc/java/jdk-17.0.13"
                NODE="Node7"
                ;;
            "eftpos4")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/apps/strauss1/oracle/lin64_ora_199"
                java="/etc/java/jdk-17.0.13"
                NODE="Node3"
                ;;
            "eftpos1")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/apps/strauss1/oracle/lin64_ora_199"
                java="/etc/java/jdk-17.0.13"
                NODE="node1"
                ;;
            "eftpos2")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/apps/strauss1/oracle/lin64_ora_199"
                java="/etc/java/jdk-17.0.13"
                NODE="node09"
                ;;
            "eftpos3")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/apps/strauss1/oracle/lin64_ora_199"
                java="/etc/java/jdk-17.0.13"
                NODE="Node2"
                ;;
            "pnsiso1")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/apps/strauss1/oracle/lin64_ora_199"
                java="/etc/java/jdk-17.0.13"
                NODE="node5"
                ;;
            "strauss3")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/apps/$user_account/oracle/lin64_ora_199"
                java="/etc/java/jdk-17.0.13"
                NODE="Balancer1"
                ;;
            *)
                echo "Unknown user for server: $server_name"
                ;;
        esac
        ;;

    "maa5afiistap06AIX")
        case "$user_account" in
            "iswtqa1")
                working="/ist_qa/$user_account/harness/$env/switch"
                oracle="/fitools/u01/app/oracle/product/12.2.0.1/client_64"
                java="/usr/java8_64"
                NODE="Node13"
                ;;
            "iswtqa3")
                working="/ist_qa/$user_account/harness/$env/switch"
                oracle="/fitools/u01/app/oracle/product/12.2.0.1/client_64"
                java="/usr/java8_64"
                NODE="Node15"
                ;;
            *)
                echo "Unknown user for server: $server_name"
                ;;
        esac
        ;;

    "vlmazistdev102RHEL9")
        case "$user_account" in
            "rpa_swdev1")
                working="/apps/$user_account/harness/$env/switch"
                oracle="/usr/lib/oracle/19.27/client64/lib/"
                java="/usr/lib/jvm/java-17-openjdk-17.0.16.0.8-2.el9.x86_64"
                NODE="Node17"
                ;;
            *)
                echo "Unknown user for server: $server_name"
                ;;
        esac
        ;;

    "maa5afiistap04AIX73")
        case "$user_account" in
            "imasqa1")
                working="/ist_qa/$user_account/harness/$env/switch"
                oracle="/fitools/u01/app/oracle/product/client64/19c"
                java="/opt/jdk-17.0.12+7"
                NODE="Node19"
                ;;
            *)
                echo "Unknown user for server: $server_name"
                ;;
        esac
        ;;

    *)
        echo "Unknown server name: $server_name"
        ;;
esac

export HOME="$working"
export ORACLE_HOME="$oracle"
export JAVA_HOME="$java"
export NODE="$NODE"
fi
echo "HOME is set to: $HOME"
echo "ORACLE_HOME is set to: $ORACLE_HOME"
echo "JAVA_HOME is set to: $JAVA_HOME"
echo "NODE is set to: $NODE"
-----------------------------ots powershell reference-------------------------------------------------
# ----------------------------------------
# Set working directory
# ----------------------------------------
Set-Location -Path "C:\Users\svcacct-istqa"

# ----------------------------------------
# Define simulator paths
# ----------------------------------------
$mcCotpPath   = "C:\Program Files (x86)\fi\Mastercard Dual Message System - 25Q4\Bin\cotp.exe"
$visaCotpPath = "C:\Program Files (x86)\fi\VisaNet Authorization-Only - Apr 2025\Bin\cotp.exe"

# ----------------------------------------
# Define project paths
# ----------------------------------------
$mcXtsPath        = "<+stage.variables.mcXtsPath>"
$visaXtsPath      = "<+stage.variables.visaXtsPath>"
$mcXts_visaPath   = "<+stage.variables.mcXtsPath_visaPath>"
$visaXts_visaPath = "<+stage.variables.visaXtsPath_visaPath>"


# ----------------------------------------
# Function: Convert .xts path to TestCases folder
# ----------------------------------------
function Get-TestCaseFolder($xtsPath) {
    $folderPath = Split-Path $xtsPath -Parent
    return "$folderPath\TestCases"
}

# ----------------------------------------
# Output: Derived TestCase folder paths
# ----------------------------------------
$mcTestCaseFolder        = Get-TestCaseFolder $mcXtsPath
$visaTestCaseFolder      = Get-TestCaseFolder $visaXtsPath
$mcTestCaseFolder_visa   = Get-TestCaseFolder $mcXts_visaPath
$visaTestCaseFolder_visa = Get-TestCaseFolder $visaXts_visaPath

# ----------------------------------------
# Display results
# ----------------------------------------
Write-Host "`nDerived TestCase Paths:"
Write-Host "mc->visa TestCase Folder        : $mcTestCaseFolder"
Write-Host "mc->visa TestCase Folder      : $visaTestCaseFolder"
Write-Host "visa->mc TestCase Folder   : $mcTestCaseFolder_visa"
Write-Host "visa->mc TestCase Folder   : $visaTestCaseFolder_visa"


# # ----------------------------------------
# # Define test case folders
# # ----------------------------------------
# $mcTestCaseFolder        = "C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4\Projects\Mastercard Dual Message System Acquirer Processor 25Q4 09_26_25\TestCases"
# $visaTestCaseFolder      = "C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025\Projects\VisaNet Authorization-Only Issuer Processor Apr 2025 09_26_25\TestCases"
# $mcTestCaseFolder_visa   = "C:\Users\svcacct-istqa\Documents\fi\Mastercard Dual Message System - 25Q4 oct12th\Projects\Mastercard Dual Message System Issuer Processor 25Q4 oct12th\TestCases"
# $visaTestCaseFolder_visa = "C:\Users\svcacct-istqa\Documents\fi\VisaNet Authorization-Only - Apr 2025 oct12th\Projects\VisaNet Authorization-Only Acquirer Processor Apr 2025 oct12th\TestCases"

# ----------------------------------------
# Harness expressions for file names and content
# ----------------------------------------
$fileName0 = "<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[0].filePath>"
$fileContent0 = @"
<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[0].fileContent>
"@

$fileName1 = "<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[1].filePath>"
$fileContent1 = @"
<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[1].fileContent>
"@

# ----------------------------------------
# Build full paths
# ----------------------------------------
$filePath0 = Join-Path -Path $mcTestCaseFolder -ChildPath $fileName0
$filePath1 = Join-Path -Path $visaTestCaseFolder_visa -ChildPath $fileName1

# ----------------------------------------
# Write content using UTF-8 without BOM
# ----------------------------------------
$utf8NoBom = New-Object System.Text.UTF8Encoding($false)

[System.IO.File]::WriteAllText($filePath0, $fileContent0, $utf8NoBom)
Write-Host "‚úÖ File 0 written to: $filePath0"

[System.IO.File]::WriteAllText($filePath1, $fileContent1, $utf8NoBom)
Write-Host "‚úÖ File 1 written to: $filePath1"

# ----------------------------------------
# Generate dynamic campaign names
# ----------------------------------------
$mcCampaign   = "MC_Campaign_01"
$visaCampaign = "Visa_Campaign_01"

# ----------------------------------------
# Launch Visa simulator
# ----------------------------------------
Write-Host "Launching Visa simulator..."
Start-Process -FilePath $visaCotpPath -ArgumentList "`"$visaXts_visaPath`"" -WindowStyle Normal

$visaReady = $false
for ($i = 0; $i -lt 15; $i += 2) {
    $proc = Get-Process -Name "cotp" -ErrorAction SilentlyContinue | Where-Object { $_.Path -eq $visaCotpPath }
    if ($proc) {
        Write-Host "Visa simulator is running."
        $visaReady = $true
        break
    }
    Start-Sleep -Seconds 2
}
if (-not $visaReady) {
    Write-Host "‚ùå ERROR: Visa simulator did not start."
    exit 1
}

# ----------------------------------------
# Launch MasterCard simulator
# ----------------------------------------
Write-Host "Launching MasterCard simulator..."
Start-Process -FilePath $mcCotpPath -ArgumentList "`"$mcXtsPath`"" -WindowStyle Normal

$mcReady = $false
for ($i = 0; $i -lt 15; $i += 2) {
    $proc = Get-Process -Name "cotp" -ErrorAction SilentlyContinue | Where-Object { $_.Path -eq $mcCotpPath }
    if ($proc) {
        Write-Host "MasterCard simulator is running."
        $mcReady = $true
        break
    }
    Start-Sleep -Seconds 2
}
if (-not $mcReady) {
    Write-Host "‚ùå ERROR: MasterCard simulator did not start."
    exit 1
}

# ----------------------------------------
# Run MasterCard test case
# ----------------------------------------
Write-Host "Running MasterCard test case..."
$mcCmd = "`"$mcCotpPath`" `"$mcXtsPath`" --testlibrary=`"$filePath0`" --sequential --simwait=100 --verbose --campaign=$mcCampaign"
cmd /c $mcCmd

Start-Sleep 10

# ----------------------------------------
# Run Visa test case
# ----------------------------------------
Write-Host "Running Visa test case..."
$visaCmd = "`"$visaCotpPath`" `"$visaXts_visaPath`" --testlibrary=`"$filePath1`" --sequential --simwait=100 --verbose --campaign=$visaCampaign"
cmd /c $visaCmd

# ----------------------------------------
# Post-execution: Parse XTSS and generate report
# ----------------------------------------
$projectFolder = Split-Path -Path $mcXtsPath -Parent
$mccampaignpath = Join-Path -Path $projectFolder -ChildPath "Campaigns\$mcCampaign"
Write-Host "Resolved MasterCard campaign path: $mccampaignpath"

$latestFolder = Get-ChildItem -Path $mccampaignpath -Directory | Sort-Object Name -Descending | Select-Object -First 1
$mcXtssFile = Join-Path $latestFolder.FullName "$($latestFolder.Name).XTSS"

$visaProjectFolder = Split-Path -Path $visaXts_visaPath -Parent
$visacampaignpath = Join-Path -Path $visaProjectFolder -ChildPath "Campaigns\$visaCampaign"
Write-Host "Resolved Visa campaign path: $visacampaignpath"

$visaLatestFolder = Get-ChildItem -Path $visacampaignpath -Directory | Sort-Object Name -Descending | Select-Object -First 1
$visaXtssFile = Join-Path $visaLatestFolder.FullName "$($visaLatestFolder.Name).XTSS"

if (Test-Path $mcXtssFile) {
    Write-Host "‚úÖ Found MasterCard XTSS file: $mcXtssFile"
} else {
    Write-Host "‚ùå MasterCard XTSS file not found in: $($latestFolder.FullName)"
}

if (Test-Path $visaXtssFile) {
    Write-Host "‚úÖ Found Visa XTSS file: $visaXtssFile"
} else {
    Write-Host "‚ùå Visa XTSS file not found in: $($visaLatestFolder.FullName)"
}

$env:mccampaignpath = $mccampaignpath
$env:visacampaignpath = $visacampaignpath
$env:mcXtssFile = $mcXtssFile
$env:visaXtssFile = $visaXtssFile

# ----------------------------------------
# Generate Combined HTML Report
# ----------------------------------------
function Generate-TestReportHtml($xtssPath, $title) {
    [xml]$xml = Get-Content $xtssPath
    $nsMgr = New-Object System.Xml.XmlNamespaceManager($xml.NameTable)
    $nsMgr.AddNamespace("ns", "http://www.integri.com/schemas/OTF/TestSuite80.xsd")
    $tests = $xml.SelectNodes("//ns:TestRun/ns:Test", $nsMgr)

    $summary = @{ Passed = 0; Inconclusive = 0; Failed = 0 }
    $lines = @()
    $lines += "<h2 style='color:#2E86C1;'>$title</h2><ul>"

    foreach ($test in $tests) {
        $name = $test.testCase
        $verdict = $test.verdict
        switch ($verdict) {
            "Passed"       { $color = "#27AE60" }
            "Failed"       { $color = "#E74C3C" }
            "Inconclusive" { $color = "#F39C12" }
            default        { $color = "#3498DB" }
        }
        $lines += "<li><strong>${name}</strong>: <span style='color:${color}; font-weight:bold;'>${verdict}</span></li>"
        if ($summary.ContainsKey($verdict)) { $summary[$verdict]++ } else { $summary[$verdict] = 1 }
    }

    $lines += "</ul><h3 style='margin-top:20px;'>Summary Totals:</h3><ul>"
    foreach ($key in $summary.Keys) {
        switch ($key) {
            "Passed"       { $color = "#27AE60" }
            "Failed"       { $color = "#E74C3C" }
            "Inconclusive" { $color = "#F39C12" }
            default        { $color = "#3498DB" }
        }
        $lines += "<li><span style='color:${color}; font-weight:bold;'>${key}:</span> $($summary[$key])</li>"
    }
    $lines += "</ul>"
    return $lines -join "`n"
}

$subject = "IST Test Execution Report - Mastercard & Visa Summary"
$mcReport = Generate-TestReportHtml -xtssPath $mcXtssFile -title "MasterCard Test Execution Summary"
$visaReport = Generate-TestReportHtml -xtssPath $visaXtssFile -title "Visa Test Execution Summary"

$body = @"
<html>
<head>
  <title>$subject</title>
  <style>
    body { font-family: Arial, sans-serif; color: #333; }
    ul { padding-left: 20px; }
    li { margin-bottom: 6px; }
    h2 { margin-top: 30px; }
  </style>
</head>
<body>
<p>Dear Team,</p>
<p>Please find below the <strong>combined OTS Test Execution Report</strong> for your review:</p>
$mcReport
<hr>
$visaReport
"@


# Set to $false to skip reversal flows
#$runReverseValidation = $true  

$runReverseValidation = "<+stage.variables.runReverseValidation>" -eq "true"



if ($runReverseValidation) {
    Write-Host "üîÅ Reverse validation flow enabled..."

    # ----------------------------------------
    # Phase 2A: Visa to Mastercard using response script
    # ----------------------------------------

    $visaReverseFileName = "<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[2].filePath>"
    $visaReverseFilePath = Join-Path -Path $visaTestCaseFolder -ChildPath $visaReverseFileName

    $visaReverseContent = @"
<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[2].fileContent>
"@



    [System.IO.File]::WriteAllText($visaReverseFilePath, $visaReverseContent, $utf8NoBom)
    Write-Host "‚úÖ Visa reverse test case written to: $visaReverseFilePath"

    $visaReverseCampaign = "Visa_Reverse_Campaign_01"
    $visaReverseCmd = "`"$visaCotpPath`" `"$visaXtsPath`" --testlibrary=`"$visaReverseFilePath`" --sequential --simwait=100 --verbose --campaign=$visaReverseCampaign"
    cmd /c $visaReverseCmd

    $visaProjectFolder = Split-Path -Path $visaXtsPath -Parent
    $visaReverseCampaignPath = Join-Path -Path $visaProjectFolder -ChildPath "Campaigns\$visaReverseCampaign"
    $visaReverseLatestFolder = Get-ChildItem -Path $visaReverseCampaignPath -Directory | Sort-Object Name -Descending | Select-Object -First 1
    $visaReverseXtssFile = Join-Path $visaReverseLatestFolder.FullName "$($visaReverseLatestFolder.Name).XTSS"


    if (Test-Path $visaReverseXtssFile) {
        Write-Host "‚úÖ Visa XTSS for Visa-to-MC reverse flow: $visaReverseXtssFile"
        $reverseVisaReport = Generate-TestReportHtml -xtssPath $visaReverseXtssFile -title "Reverse Flow: Visa to Mastercard Summary"
        $body += "`n<hr>`n$reverseVisaReport"
    } else {
        Write-Host "‚ùå Visa XTSS not found for Visa-to-MC reverse flow."
    }


    # ----------------------------------------
    # Phase 2B: Mastercard to Visa re-initiation
    # ----------------------------------------

    $mcReCampaign = "MC_Reinit_Campaign_01"
    $mcReCmd = "`"$mcCotpPath`" `"$mcXtsPath`" --testlibrary=`"$filePath0`" --sequential --simwait=100 --verbose --campaign=$mcReCampaign"
    Write-Host "üöÄ Running Mastercard re-initiation test case..."
    cmd /c $mcReCmd


    # Mastercard is initiator ‚Üí XTSS will be in Mastercard's campaign folder
    $mcProjectFolder = Split-Path -Path $mcXtsPath -Parent
    $mcReCampaignPath = Join-Path -Path $mcProjectFolder -ChildPath "Campaigns\$mcReCampaign"
    $mcReLatestFolder = Get-ChildItem -Path $mcReCampaignPath -Directory | Sort-Object Name -Descending | Select-Object -First 1
    $mcReXtssFile = Join-Path $mcReLatestFolder.FullName "$($mcReLatestFolder.Name).XTSS"

    # Generate report
    if (Test-Path $mcReXtssFile) {
        Write-Host "‚úÖ Mastercard XTSS for re-initiation: $mcReXtssFile"
        $reinitMcReport = Generate-TestReportHtml -xtssPath $mcReXtssFile -title "Re-initiation: Mastercard to Visa Summary"
        $body += "`n<hr>`n$reinitMcReport"
    } else {
        Write-Host "‚ùå Mastercard XTSS not found for re-initiation."
    }
    
    # ----------------------------------------
    # Prepare Mastercard response script for Visa-to-MC reversal
    # ----------------------------------------

    $mcReverseFileName = "<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[3].filePath>"
    $mcReverseFilePath = Join-Path -Path $mcTestCaseFolder -ChildPath $mcReverseFileName

    $mcReverseContent = @"
<+pipeline.stages.otstransaction.spec.configFiles.ots_config.gitFiles[3].fileContent>
"@

    [System.IO.File]::WriteAllText($mcReverseFilePath, $mcReverseContent, $utf8NoBom)
    Write-Host "‚úÖ Mastercard reverse test case written to: $mcReverseFilePath"
    
    # ----------------------------------------
    # Phase 3A: Mastercard to Visa reverse flow (Oct12 workspace)
    # ----------------------------------------

    # $mcReverseCampaign = "MC_Reverse_Campaign_01"
    # $mcReverseCmd = "`"$mcCotpPath`" `"$mcXts_visaPath`" --testlibrary=`"$mcReverseFilePath`" --sequential --simwait=100 --verbose --campaign=$mcReverseCampaign"
    # Write-Host "üöÄ Running Mastercard reverse test case..."
    # cmd /c $mcReverseCmd

    # Start-Sleep 10

    # # XTSS will be generated in Mastercard's Oct12 workspace
    # $mcProjectFolder = Split-Path -Path $mcXts_visaPath -Parent
    # $mcReverseCampaignPath = Join-Path -Path $mcProjectFolder -ChildPath "Campaigns\$mcReverseCampaign"
    # $mcReverseLatestFolder = Get-ChildItem -Path $mcReverseCampaignPath -Directory | Sort-Object Name -Descending | Select-Object -First 1
    # $mcReverseXtssFile = Join-Path $mcReverseLatestFolder.FullName "$($mcReverseLatestFolder.Name).XTSS"

    # # Generate report
    # if (Test-Path $mcReverseXtssFile) {
    #     Write-Host "‚úÖ Mastercard XTSS for reverse flow: $mcReverseXtssFile"
    #     $reverseMcReport = Generate-TestReportHtml -xtssPath $mcReverseXtssFile -title "Reverse Flow: Mastercard to Visa"
    #     $body += "`n<hr>`n$reverseMcReport"
    # } else {
    #     Write-Host "‚ùå Mastercard XTSS not found for reverse flow."
    # }

    # ----------------------------------------
    # Phase 3B: Visa to Mastercard re-initiation (Oct12 workspace)
    # ----------------------------------------

    $visaReinitCampaign = "Visa_Reinit_Campaign_01"
    $visaReinitCmd = "`"$visaCotpPath`" `"$visaXts_visaPath`" --testlibrary=`"$filePath1`" --sequential --simwait=100 --verbose --campaign=$visaReinitCampaign"
    Write-Host "üöÄ Running Visa re-initiation test case..."
    cmd /c $visaReinitCmd

    Start-Sleep 10

    # XTSS will be generated in Visa's Oct12 workspace
    $visaProjectFolder = Split-Path -Path $visaXts_visaPath -Parent
    $visaReinitCampaignPath = Join-Path -Path $visaProjectFolder -ChildPath "Campaigns\$visaReinitCampaign"
    $visaReinitLatestFolder = Get-ChildItem -Path $visaReinitCampaignPath -Directory | Sort-Object Name -Descending | Select-Object -First 1
    $visaReinitXtssFile = Join-Path $visaReinitLatestFolder.FullName "$($visaReinitLatestFolder.Name).XTSS"

    # Generate report
    if (Test-Path $visaReinitXtssFile) {
        Write-Host "‚úÖ Visa XTSS for re-initiation: $visaReinitXtssFile"
        $reinitVisaReport = Generate-TestReportHtml -xtssPath $visaReinitXtssFile -title "Re-initiation: Visa to Mastercard Summary"
        $body += "`n<hr>`n$reinitVisaReport"
    } else {
        Write-Host "‚ùå Visa XTSS not found for re-initiation."
    }
  
}
else {
    Write-Host "üö´ Reverse validation flow skipped (flag is false)"
}

$env:visaReverseCampaignPath = $visaReverseCampaignPath
$env:mcReCampaignPath = $mcReCampaignPath
$env:visaReverseXtssFile = $visaReverseXtssFile
$env:mcReXtssFile = $mcReXtssFile

$env:mcReverseCampaignPath = $mcReverseCampaignPath
$env:visaReinitCampaignPath = $visaReinitCampaignPath
$env:mcReverseXtssFile = $mcReverseXtssFile
$env:visaReinitXtssFile = $visaReinitXtssFile



# ----------------------------------------
# Step 3: Finalize and export email content
# ----------------------------------------

$body += @"
<p>Regards,<br><strong>IST QA Team</strong></p>
</body>
</html>
"@

$env:EMAIL_SUBJECT = $subject
$env:EMAIL_BODY = $body

----------------------------------------debug-archive referencebash script------------------------------------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'


echo "Switched to user: $(whoami)"

# Pick up WORKING_DIR from environment
HOME="<+pipeline.stages.otstransaction.spec.execution.steps.Set_Up_Environment_0.output.outputVariables.Working_Directory>"

cd "$HOME"
if [ $? -ne 0 ]; then
    echo "[ERROR] Failed to change to HOME directory: $HOME"
    exit 1
fi

export HOME="$HOME"

echo "HOME is set to: $HOME"

pwd

# Find the latest pdir directory (without suffix)
latest_pdir=$(ls -td pdir20* 2>/dev/null | head -1)
latest_profile=$(ls -td profile20* 2>/dev/null | head -1)

if [ -z "$latest_pdir" ] || [ -z "$latest_profile" ]; then
    echo "[WARNING] No pdir or profile found"
else
    echo "Latest profile file: $latest_profile"
    echo "Latest pdir directory: $latest_pdir"
fi

#Source the profile
. "./$latest_profile"

# --- Step: Archive Debug Files ---
FILES="mcnormaldump.debug mcnormal.debug shc.debug shcdump.debug visa.debug visadump.debug"
DEBUG_DIR="$HOME/$latest_pdir/log/debug"
ARCHIVE_BASE="$HOME/debug_archive"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
ARCHIVE_DIR="$ARCHIVE_BASE/debugs_$TIMESTAMP"
mkdir -p "$ARCHIVE_DIR"

for file in $FILES; do
    if [ -f "$DEBUG_DIR/$file" ]; then
        cp "$DEBUG_DIR/$file" "$ARCHIVE_DIR/"
        echo "[INFO] Archived: $file"
    else
        echo "[WARN] File not found: $file"
    fi
done

echo -e "\n‚úÖ Debugs archived at: $ARCHIVE_DIR"

# export ARCHIVE_DIR="$ARCHIVE_DIR"
# echo "ARCHIVE_DIR is set to: $ARCHIVE_DIR"
# inside heredoc

#echo "ARCHIVE_DIR=$ARCHIVE_DIR"

export DEBUG_DIR="$DEBUG_DIR"
export ARCHIVE_BASE="$ARCHIVE_BASE"
export TIMESTAMP="$TIMESTAMP"
export ARCHIVE_DIR="$ARCHIVE_DIR"

echo "DEBUG_DIR is set to: $DEBUG_DIR"
echo "ARCHIVE_BASE is set to: $ARCHIVE_BASE"
echo "TIMESTAMP is set to: $TIMESTAMP"
echo "ARCHIVE_DIR is set to: $ARCHIVE_DIR"

echo "$ARCHIVE_DIR" > "$HOME/archive.txt"

EOF

ARCHIVE_DIR=$(cat "<+pipeline.stages.otstransaction.spec.execution.steps.Set_Up_Environment_0.output.outputVariables.Working_Directory>/archive.txt")
echo "archive_dir is: $ARCHIVE_DIR"




-------------------------------------------cleanup archive bash------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'


echo "Switched to user: $(whoami)"

# Pick up WORKING_DIR from environment
HOME="<+pipeline.stages.otstransaction.spec.execution.steps.Set_Up_Environment_0.output.outputVariables.Working_Directory>"

cd "$HOME"
if [ $? -ne 0 ]; then
    echo "[ERROR] Failed to change to HOME directory: $HOME"
    exit 1
fi

export HOME="$HOME"

echo "HOME is set to: $HOME"

pwd


# Base archive directory
ARCHIVE_BASE="$HOME/debug_archive"

echo "üßπ Cleaning up old debug archives in: $ARCHIVE_BASE"

# List all archive directories sorted by modification time (newest first)
archives=$(ls -td "$ARCHIVE_BASE"/debugs_* 2>/dev/null)

# If no archives found, exit gracefully
if [ -z "$archives" ]; then
    echo "[INFO] No archives found to clean up."
    exit 0
fi

# Extract the latest archive (first in sorted list)
latest=$(echo "$archives" | head -1)

echo "[INFO] Latest archive retained: $latest"

# Remove all other archives except the latest
echo "$archives" | tail -n +2 | while read old; do
    if [ -n "$old" ]; then
        rm -rf "$old"
        echo "[INFO] Removed old archive: $old"
    fi
done

echo "‚úÖ Cleanup complete. Only latest archive retained."

EOF


-------------------------------------backup script reference-----------------------------------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
  is_aix=false
else
  switch_cmd="su $selected_user -s /bin/sh"
  is_aix=true
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'

# -----------------------------
# Set up working directory
# -----------------------------
Working_Directory="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
cd $Working_Directory

# Get the last folder name from Working_Directory (basename)
last_folder=$(basename "$Working_Directory")
cd "$Working_Directory/.." && [ -d "$last_folder" ] && chmod 777 "$last_folder" && cd "$Working_Directory"

pwd
ls -ltr

echo "Current user: $(whoami)"

INSTALL_DIR="$Working_Directory"
echo "Installed dir is: $INSTALL_DIR"
BACKUP_DIR="$INSTALL_DIR/backup_$(date +%Y%m%d_%H%M%S)"
BACKUP_ARCHIVE="$BACKUP_DIR/backup.tar.gz"

# Find the latest pdir and profile
latest_pdir=$(ls -td "$INSTALL_DIR"/pdir20* 2>/dev/null | head -1)
latest_profile=$(ls -td "$INSTALL_DIR"/profile20* 2>/dev/null | head -1)

# Write latest_profile to a temporary file
echo "$latest_profile" > output_variable.txt

filename="<+pipeline.stages.Set_Up_Environment.spec.artifacts.primary.metadata.fileName>"

# Extract TriggerType
TriggerType="$(echo "$filename" | awk '{
  if (match($0, /(FullTrigger|PartialTrigger)/)) {
    print substr($0, RSTART, RLENGTH)
  }
}')"

echo "Artifact Type Selected: $TriggerType"

# Pipeline variables
FRESH_INSTALLATION="<+pipeline.variables.FRESH_INSTALLATION>"
USE_DMKLINK="<+pipeline.variables.USE_DMKLINK>"

# -----------------------------
# Function to create tar archive
# -----------------------------
create_backup() {
    if [ "$(uname)" = "AIX" ]; then
        tar -cf "$BACKUP_DIR/backup.tar" -C "$INSTALL_DIR" "$@"
        gzip "$BACKUP_DIR/backup.tar"
    else
        tar -czf "$BACKUP_ARCHIVE" -C "$INSTALL_DIR" "$@"
    fi
}

# -----------------------------
# Backup Logic
# -----------------------------
if [ "$FRESH_INSTALLATION" = "Yes" ] && [ "$USE_DMKLINK" = "No" ]; then
    echo "[INFO] Fresh installation with clean DB (USE_DMKLINK=No). Backing up pdir and profile."
    if [ -d "$latest_pdir" ] && [ -f "$latest_profile" ]; then
        mkdir -p "$BACKUP_DIR"
        create_backup "$(basename "$latest_pdir")" "$(basename "$latest_profile")"
    else
        echo "[WARNING] Required items missing. Skipping backup."
        rm -rf "$BACKUP_DIR"
    fi
elif [ "$FRESH_INSTALLATION" = "Yes" ] && [ "$USE_DMKLINK" = "Yes" ]; then
    echo "[INFO] Fresh installation without clean DB (USE_DMKLINK=Yes). No backup required."
elif [ "$FRESH_INSTALLATION" = "No" ]; then
    echo "[INFO] Update scenario. Backing up pdir and profile."
    if [ -d "$latest_pdir" ] && [ -f "$latest_profile" ]; then
        mkdir -p "$BACKUP_DIR"
        create_backup "$(basename "$latest_pdir")" "$(basename "$latest_profile")"
    else
        echo "[WARNING] Required items missing. Skipping backup."
        rm -rf "$BACKUP_DIR"
    fi
else
    echo "[INFO] Unknown scenario. No backup performed."
fi

# -----------------------------
# Verify backup archive
# -----------------------------
if [ -f "$BACKUP_ARCHIVE" ]; then
    if ! gunzip -c "$BACKUP_ARCHIVE" | tar -tf - >/dev/null; then
        echo "[WARNING] Backup verification failed - corrupt archive"
        rm -rf "$BACKUP_DIR"
    else
        echo "[SUCCESS] Backup archive created at: $BACKUP_ARCHIVE"
        ls -l "$BACKUP_ARCHIVE"

        # Save backup metadata
        echo "BACKUP_DIR=$BACKUP_DIR" > "$INSTALL_DIR/backup_vars.env"
        echo "BACKUP_PDIR=$latest_pdir" >> "$INSTALL_DIR/backup_vars.env"
        echo "BACKUP_PROFILE=$latest_profile" >> "$INSTALL_DIR/backup_vars.env"
        echo "BACKUP_ARCHIVE=$BACKUP_ARCHIVE" >> "$INSTALL_DIR/backup_vars.env"
    fi
else
    echo "[INFO] No backup archive was created due to missing files or skipped backup."
fi

# -----------------------------
# Write backup status
# -----------------------------
if [ -f "$BACKUP_ARCHIVE" ]; then
    BACKUP_TAKEN=Yes
    echo "$BACKUP_TAKEN" > backup_status.env
else
    BACKUP_TAKEN=No
    echo "$BACKUP_TAKEN" > backup_status.env
fi

EOF

# Read latest_profile from the temporary file
latest_profile=$(cat output_variable.txt)
echo "Latest profile: $latest_profile"

BACKUP_TAKEN=$(cat backup_status.env)
echo "Backup taken status: $BACKUP_TAKEN"

-------------------------------------------ansible cloud clone bb------

#!/bin/bash

set -euo pipefail  # Exit on error, unset vars, and pipe failures

# Fetch secrets from Harness
export BB_svc_acc="<+secrets.getValue('org.SVC-ACC-BB')>"
export BB_svc_pass="<+secrets.getValue('org.IST-BB-Pass')>"
export BRANCH_NAME_DEV="<+stage.variables.BRANCH_NAME_DEV>"
export REPO_DEV_URL="<+stage.variables.REPO_DEV_URL>"
export WORKING_DIRECTORY="<+stage.variables.WORKING_DIRECTORY>"
# Fetch credentials from Harness secrets
export AF_USER="<+secrets.getValue('org.JFROG-USER')>"
export AF_KEY="<+secrets.getValue('org.JFROG-PASS')>"

echo "[INFO] Repo URL: $REPO_DEV_URL"
echo "[INFO] Branch: $BRANCH_NAME_DEV"

# Function to inject submodule credentials and init
init_submodule() {
  echo "[INFO] Initializing submodule with credentials..."
  git config -f .gitmodules submodule.ist-ansible-scripts.url \
    "https://${BB_svc_acc}:${BB_svc_pass}@bitbucket.fi.dev/scm/istdevops/ist-ansible-scripts.git"
  git submodule sync
  git submodule update --init --recursive
}

# Function to clone fresh repo
clone_repo() {
  echo "[WARN] Cleaning up existing repo due to conflicts..."
  rm -rf ist-ansible-scripts-dev
  echo "[INFO] Cloning fresh repo..."
  git clone --branch "$BRANCH_NAME_DEV" "$REPO_DEV_URL" ist-ansible-scripts-dev
  cd ist-ansible-scripts-dev
  init_submodule
}

# Check main repo
if [ -d "ist-ansible-scripts-dev/.git" ]; then
  echo "[INFO] Repo already exists. Checking for local changes..."
  cd ist-ansible-scripts-dev

  if ! git diff --quiet || ! git diff --cached --quiet; then
    echo "[WARN] Uncommitted changes in main repo. Re-cloning..."
    cd ..
    clone_repo
  else
    echo "[INFO] No local changes in main repo. Updating..."
    git fetch origin
    git checkout "$BRANCH_NAME_DEV" || git checkout -b "$BRANCH_NAME_DEV" origin/"$BRANCH_NAME_DEV"
    git pull --rebase
  fi
else
  clone_repo
fi

# Handle submodule
cd ist-ansible-scripts
git fetch origin

if ! git diff --quiet || ! git diff --cached --quiet; then
  echo "[WARN] Uncommitted changes in submodule. Re-cloning main repo..."
  cd ../..
  clone_repo
  cd ist-ansible-scripts-dev/ist-ansible-scripts
fi

# Checkout submodule branch
git checkout "$BRANCH_NAME_DEV" || git checkout -b "$BRANCH_NAME_DEV" origin/"$BRANCH_NAME_DEV"
git pull --rebase

# Debug info
echo "[INFO] Submodule branch: $(git rev-parse --abbrev-ref HEAD)"
echo "[INFO] Submodule HEAD: $(git rev-parse HEAD)"



# Dynamically expand HOME-based paths
export SCRIPT_DIR="<+pipeline.stages.Ansible_Enviornment_Setup.variables.SCRIPT_DIR>"
export IST_ANS_WORKSPACE_ROOT="<+pipeline.stages.Ansible_Enviornment_Setup.variables.IST_ANS_WORKSPACE_ROOT>"

# Run CA fetch script

cd "$SCRIPT_DIR" || {
    echo "Failed to navigate to $SCRIPT_DIR"
    exit 1
}

if ./001-fetch-local-ca-for-artifactory.sh; then
    echo "Successfully ran 001-fetch-local-ca-for-artifactory.sh"
else
    echo "Error running 001-fetch-local-ca-for-artifactory.sh"
    exit 1
fi

# Step 1: Set Workspace and Environment Variables if not already set
if [ -z "$IST_ANS_WORKSPACE_ROOT" ]; then
    export IST_ANS_WORKSPACE_ROOT="<+pipeline.stages.Ansible_Enviornment_Setup.variables.IST_ANS_WORKSPACE_ROOT>"
    echo "IST_ANS_WORKSPACE_ROOT set to $IST_ANS_WORKSPACE_ROOT"
else
    echo "IST_ANS_WORKSPACE_ROOT already set to $IST_ANS_WORKSPACE_ROOT"
fi

if [ -z "$IST_ANS_ENV" ]; then
    export IST_ANS_ENV="<+pipeline.stages.Ansible_Enviornment_Setup.variables.IST_ANS_ENV>"
    echo "IST_ANS_ENV set to $IST_ANS_ENV"
else
    echo "IST_ANS_ENV already set to $IST_ANS_ENV"
fi


# Parse inventory.yml and export host variables
INVENTORY_PATH="$IST_ANS_WORKSPACE_ROOT/$IST_ANS_ENV/inventory.yml"

if [[ ! -f "$INVENTORY_PATH" ]]; then
  echo "Error: Inventory file not found at $INVENTORY_PATH"
  exit 1
fi

while IFS= read -r line; do
  if [[ "$line" =~ ^[[:space:]]*([a-zA-Z0-9_]+):[[:space:]]*$ ]]; then
    current_host="${BASH_REMATCH[1]}"
  elif [[ "$line" =~ ^[[:space:]]*ansible_host:[[:space:]]*(.*)$ ]]; then
    host_value="${BASH_REMATCH[1]}"
    export "$current_host"="$host_value"
    echo "Exported $current_host=$host_value"
  fi
done < "$INVENTORY_PATH"


----------------------------------------api--------------------------------
api download bash reference-----------------------------------------


#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'
cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
#cd /apps/eftpos4/harness/dev/apitest/tgz
#cd /ist_qa/iswtqa1/harness/dev/api/tgz


echo "Current user: $(whoami)"

selected_user="<+pipeline.variables.USER_ACCOUNT>"

export JAVA_HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.JAVA_HOME>"
export PATH=$JAVA_HOME/bin:$PATH
echo $JAVA_HOME

os_type=$(uname)

# Set proxy only for AIX users
if [ "$os_type" = "AIX" ]; then
  export http_proxy="http://10.236.163.21:8080/"
  export https_proxy="http://10.236.163.21:8080/"
fi



zip_artifact_url="<+artifact.metadata.url>"

artifact_file_name="<+pipeline.stages.Dowload_Artifacts.spec.artifacts.primary.metadata.fileName>"

# Determine OS type
os_type=$(uname)

# Function to download zip artifact
download_zip_artifact() {
  echo "Downloading zip artifact from URL: $zip_artifact_url"
  if ! curl -u "<+secrets.getValue('<+pipeline.variables.JFROG_USER>')>:<+secrets.getValue('<+pipeline.variables.JFROG_PASS>')>" -O "$zip_artifact_url" ; then
    echo "Failed to download zip artifact from $zip_artifact_url"
    exit 1
  fi
}

# Download zip artifact if specified
if [ -n "$zip_artifact_url" ]; then
  download_zip_artifact
fi
ls -l

chmod 777 $artifact_file_name


gunzip -f "$artifact_file_name"
file_name="${artifact_file_name%.tgz}.tar"
echo "gunzip file is: $file_name"
tar -xvf "$file_name"


export basename_without_tgz=$(basename "<+pipeline.stages.Dowload_Artifacts.spec.artifacts.primary.metadata.fileName>" .tgz)
echo "$basename_without_tgz" > output_variable_basename.txt



#copy cert files to config dir
source_cert_path="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.source_cert_path>"


# Target config directory inside extracted artifact
target_config_path="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/$basename_without_tgz/config"

# Validate target directory
if [ ! -d "$target_config_path" ]; then
    echo "‚ùå Target config directory not found: $target_config_path"
    exit 2
fi

# List of certificate files to copy (space-separated for POSIX compatibility)
cert_files="apihttps.crt ca.crt ca.csr ca.p12 root.crt root.p12 server.crt server.csr server.p12 server_trust.p12 wso2.crt"

echo "üìÅ Copying certificate files from $source_cert_path to $target_config_path"

for file in $cert_files; do
    if [ -f "$source_cert_path/$file" ]; then
        cp "$source_cert_path/$file" "$target_config_path/"
        echo "‚úÖ Copied: $file"
    else
        echo "‚ö†Ô∏è Missing: $file in $source_cert_path"
    fi
done

echo "‚úÖ Certificate files copied successfully."


EOF

basename_without_tgz=$(cat <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/output_variable_basename.txt)
echo "basename_without_tgz: $basename_without_tgz"

# cert_changed=$(cat <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/cert_status.txt)
# echo "cert_changed value: $cert_changed"


# Capture the exit status of the dzdo su - strauss1 command
EXIT_STATUS=$?

# Check if the command inside the su block failed
if [ $EXIT_STATUS -ne 0 ]; then
  echo "The script inside the $selected_user block failed. Exiting with status $EXIT_STATUS."
  exit $EXIT_STATUS
fi


-------------------------------------------backup api folder-----------------------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
  is_aix=false
else
  switch_cmd="su $selected_user -s /bin/sh"
  is_aix=true
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'

Working_Directory="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"
cd $Working_Directory

# Set working directory
INSTALL_DIR="$Working_Directory"
echo "Install dir: $INSTALL_DIR"

# List available folders for debug
echo "[INFO] Available folders in api:"
ls -ltr "$INSTALL_DIR"

# Detect latest versioned folder (directory only) under INSTALL_DIR
#LATEST_API_FOLDER=$(ls -td "$INSTALL_DIR"/ist-api-services* 2>/dev/null | head -n 1 || true)

# Detect latest versioned folder (directory only)
LATEST_API_FOLDER=""
for d in "$INSTALL_DIR"/ist-api-services*; do
  if [ -d "$d" ]; then
    LATEST_API_FOLDER="$d"
  fi
done

# Check if folder was found
if [ -z "$LATEST_API_FOLDER" ]; then
  echo "[ERROR] No versioned API folder found in $INSTALL_DIR"
  echo "api_taken=no" > api_backup_status.env
  exit 0
fi

API_FOLDER=$(basename "$LATEST_API_FOLDER")
echo "[INFO] Detected latest API folder: $API_FOLDER"

# Timestamp for backup
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# Backup directory and archive
API_BACKUP_DIR="$INSTALL_DIR/api_backup_$TIMESTAMP"
API_ARCHIVE="$API_BACKUP_DIR/api_backup.tar.gz"

# Create backup directory
mkdir -p "$API_BACKUP_DIR"

# Backup function
backup_folder() {
  folder_path="$1"
  backup_dir="$2"
  archive_path="$3"
  folder_label="$4"

  echo "[INFO] Backing up $folder_label..."

  # Check if folder exists
  if [ ! -d "$INSTALL_DIR/$folder_path" ]; then
    echo "[ERROR] $folder_label folder does not exist: $folder_path"
    echo "${folder_label}_taken=no" > "${folder_label}_backup_status.env"
    return
  fi

  # Create archive
  if [ "$(uname)" = "AIX" ]; then
    tar -cf "$backup_dir/temp.tar" -C "$INSTALL_DIR" "$folder_path"
    gzip "$backup_dir/temp.tar"
    mv "$backup_dir/temp.tar.gz" "$archive_path"
  else
    tar -czf "$archive_path" -C "$INSTALL_DIR" "$folder_path"
  fi

  # Verify archive content
  if [ -f "$archive_path" ]; then
    if ! gunzip -c "$archive_path" | tar -tf - | grep -q .; then
      echo "[WARNING] $folder_label backup archive is empty or invalid"
      rm -rf "$backup_dir"
      echo "${folder_label}_taken=no" > "${folder_label}_backup_status.env"
    else
      echo "[SUCCESS] $folder_label backup created at: $archive_path"
      echo "${folder_label}_taken=yes" > "${folder_label}_backup_status.env"
    fi
  else
    echo "[INFO] No archive created for $folder_label"
    echo "${folder_label}_taken=no" > "${folder_label}_backup_status.env"
  fi
}

# Run backup for detected API folder
backup_folder "$API_FOLDER" "$API_BACKUP_DIR" "$API_ARCHIVE" "api"

EOF

# Read and print backup status
API_BACKUP_STATUS=$(grep api_taken api_backup_status.env | cut -d= -f2)
echo "api_backup_taken=$API_BACKUP_STATUS"







-------------------------disk space-----------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'

cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>

# Input: server name from pipeline
server_name="<+pipeline.variables.TARGET_SERVER>"

# Set mount point based on server
case "$server_name" in
 "vlmazistqc100RHEL8"|"vlmazistdev102RHEL9")
    mount_point="/apps"
    ;;
  "maa5afiistap06AIX"|"maa5afiistap04AIX73")
    mount_point="/ist_qa"
    ;;
  "maa5afiistap03AIX73")
    mount_point="/ist_dev"
    ;;
  *)
    echo "Error: Invalid server name."
    exit 1
    ;;
esac

OS_TYPE=$(uname)

# Get disk usage for the mount point
if [ "$OS_TYPE" = "Linux" ]; then
    USAGE="$(df -P "$mount_point" | awk 'NR==2 {gsub("%","",$5); print $5}')"
elif [ "$OS_TYPE" = "AIX" ]; then
    USAGE="$(df -k "$mount_point" | awk 'NR==2 {gsub("%","",$5); print $5}')"
else
    echo "Unsupported OS: $OS_TYPE"
    exit 1
fi

# Check if usage exceeds threshold
THRESHOLD=96
if [ -z "$USAGE" ]; then
    echo "Could not determine disk usage for $mount_point"
    exit 1
fi

if [ "$USAGE" -ge "$THRESHOLD" ]; then
    echo "CRITICAL: $mount_point is ${USAGE}% full. Please take action!"
    #exit 1
else
    echo "OK: $mount_point usage is ${USAGE}%"
fi

EOF

# Capture the exit status 
exit_status=$?

# Exit with the captured status
exit $exit_status

------------------------------------------------api installation jar-------------------------


#!/usr/bin/bash
selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'
working_dir="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>"

cd $working_dir

echo "Current user: $(whoami)"
basename_without_tgz="<+pipeline.stages.Dowload_Artifacts.spec.execution.steps.Download_Artifacts_0.output.outputVariables.basename_without_tgz>"


# if echo "$basename_without_tgz" | grep -q "ist-api-services-mas"; then
#   export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.462.b08-2.el8.x86_64"
#   export PATH=$JAVA_HOME/bin:$PATH
#   echo "Using JDK 8 for ist-api-services-mas"
#   echo $JAVA_HOME
# else
export JAVA_HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.JAVA_HOME>"
export PATH=$JAVA_HOME/bin:$PATH
echo $JAVA_HOME
#fi

cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/$basename_without_tgz/config

if [ ! -f server.enc ]; then
  touch server.enc
  echo "Created empty server.enc file"
fi

chmod -x server.enc

echo "Resolved basename_without_tgz: $basename_without_tgz"
echo "Resolved JAR path: ../$basename_without_tgz.jar"
echo "Resolved Working Directory: $(pwd)"

echo "generating passwords in server.enc file"
# Store passwords into server.p12 using PwdSetter2
java -Dloader.main=com.fi.ist.security.PwdSetter2 -jar ../$basename_without_tgz.jar ../config/server.p12 datasource.main.password  - - srvpw11  - "<+pipeline.variables.db_password>"

java -Dloader.main=com.fi.ist.security.PwdSetter2 -jar ../$basename_without_tgz.jar ../config/server.p12 common_truststore_wachtwoord  - - srvpw11 - srvtrpw11

java -Dloader.main=com.fi.ist.security.PwdSetter2 -jar ../$basename_without_tgz.jar ../config/server.p12 datasource.mas.password  - - srvpw11  - "<+pipeline.variables.db_password>"

java -Dloader.main=com.fi.ist.security.PwdSetter2 -jar ../$basename_without_tgz.jar ../config/server.p12 datasource.audit.password  - - srvpw11  - "<+pipeline.variables.db_password>"

java -Dloader.main=com.fi.ist.security.PwdSetter2 -jar ../$basename_without_tgz.jar ../config/server.p12 datasource.clearing.password  - - srvpw11  - "<+pipeline.variables.db_password>"

#below cmd is to run obfuscated password in ist-api.properties file
java -Dloader.main=com.fi.ist.security.KeyStoreObfuscate -jar ../$basename_without_tgz.jar ../config/ist-api.properties keystore-wachtwoord srvpw11


# Detect OS type
OS_TYPE=$(uname)

# Function to safely replace lines using sed
safe_sed_replace() {
  local pattern="$1"
  local file="$2"

  if [[ "$OS_TYPE" == "AIX" ]]; then
    # AIX: no -i support, use temp file
    sed "$pattern" "$file" > "${file}.tmp" && mv "${file}.tmp" "$file"
  else
    # RHEL and others: use -i
    sed -i "$pattern" "$file"
  fi
}

PROP_FILE="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/$basename_without_tgz/config/ist-api.properties"
LOGPROP_FILE="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/$basename_without_tgz/config/log.ist.properties"

# Debug: print resolved paths
echo "PROP_FILE: $PROP_FILE"
echo "LOGPROP_FILE: $LOGPROP_FILE"

# Validate PROP_FILE
if [[ -z "$PROP_FILE" || ! -f "$PROP_FILE" ]]; then
  echo "[ERROR] PROP_FILE is not set or does not exist: '$PROP_FILE'"
  exit 1
fi

# Validate LOGPROP_FILE
if [[ -z "$LOGPROP_FILE" || ! -f "$LOGPROP_FILE" ]]; then
  echo "[ERROR] LOGPROP_FILE is not set or does not exist: '$LOGPROP_FILE'"
  exit 1
fi

# Backup original files
cp "$PROP_FILE" "$PROP_FILE.bak"
cp "$LOGPROP_FILE" "$LOGPROP_FILE.bak"

# Update ist-api.properties
safe_sed_replace 's|^datasource.main.url=.*|datasource.main.url=jdbc:oracle:thin:@//<+pipeline.variables.db_server>/<+pipeline.variables.db_name>|' "$PROP_FILE"
safe_sed_replace 's|^datasource.main.user=.*|datasource.main.user=<+pipeline.variables.db_user>|' "$PROP_FILE"
safe_sed_replace 's|^datasource.audit.url=.*|datasource.audit.url=jdbc:oracle:thin:@//<+pipeline.variables.db_server>/<+pipeline.variables.db_name>|' "$PROP_FILE"
safe_sed_replace 's|^datasource.audit.user=.*|datasource.audit.user=<+pipeline.variables.db_user>|' "$PROP_FILE"
safe_sed_replace 's|^datasource.mas.url=.*|datasource.mas.url=jdbc:oracle:thin:@//<+pipeline.variables.db_server>/<+pipeline.variables.db_name>|' "$PROP_FILE"
safe_sed_replace 's|^datasource.mas.user=.*|datasource.mas.user=<+pipeline.variables.db_user>|' "$PROP_FILE"
safe_sed_replace 's|^datasource.clearing.url=.*|datasource.clearing.url=jdbc:oracle:thin:@//<+pipeline.variables.db_server>/<+pipeline.variables.db_name>|' "$PROP_FILE"
safe_sed_replace 's|^datasource.clearing.user=.*|datasource.clearing.user=<+pipeline.variables.db_user>|' "$PROP_FILE"
safe_sed_replace 's|^api_switch_link.host=.*|api_switch_link.host=<+pipeline.variables.api_switch_link_host>|' "$PROP_FILE"
safe_sed_replace 's|^api_switch_link.port=.*|api_switch_link.port=<+pipeline.variables.api_switch_link_port>|' "$PROP_FILE"
safe_sed_replace 's|^api_switch_link.secondary_host=.*|api_switch_link.secondary_host=<+pipeline.variables.api_switch_link_secondary_host>|' "$PROP_FILE"
safe_sed_replace 's|^api_switch_link.secondary_port=.*|api_switch_link.secondary_port=<+pipeline.variables.api_switch_link_secondary_port>|' "$PROP_FILE"
safe_sed_replace 's|^server.port=.*|server.port=<+pipeline.variables.server_port>|' "$PROP_FILE"
safe_sed_replace 's|^api_switch_link.use_ssl=.*|api_switch_link.use_ssl=<+pipeline.variables.use_ssl>|' "$PROP_FILE"


echo "ist-api.properties has been updated successfully."

# Update log.ist.properties
safe_sed_replace 's|^log.level.com.fi.ist=.*|log.level.com.fi.ist=DEBUG|' "$LOGPROP_FILE"
safe_sed_replace 's|^#\?log.level.org.springframework.integration=.*|log.level.org.springframework.integration=DEBUG|' "$LOGPROP_FILE"


FILE="$LOGPROP_FILE"
LINE="log.level.org.springframework.integration=DEBUG"

# Step 2: If the line is still missing, append it and echo confirmation
if ! grep -Eq '^#?\s*log.level.org.springframework.integration=' "$FILE"; then
  echo "$LINE" >> "$FILE"
  echo "Added missing line: $LINE"
fi


echo "log.ist.properties has been updated successfully."

# -----------------------------------------------
# üîß Define ports to check and clean
# -----------------------------------------------
apiport="<+pipeline.variables.server_port>"
switchport="<+pipeline.variables.api_switch_link_port>"
mcport="<+pipeline.variables.mcport>"
visaport="<+pipeline.variables.visaport>"
ports="$apiport $switchport $mcport $visaport"

# -----------------------------------------------
# üîç Check each port
# -----------------------------------------------
output_file="$working_dir/active_ports.txt"
rm -f "$output_file" 2>/dev/null

# -----------------------------------------------
# üîç Function to check if a port is active and capture PID(s)
# -----------------------------------------------
check_port() {
    port=$1
    echo "[DEBUG] Checking port: $port"

    os_type=$(uname)

    if command -v lsof >/dev/null 2>&1; then
        # Linux: use lsof
        pids=$(lsof -i :"$port" 2>/dev/null | awk 'NR>1 {print $2}' | sort -u)
        [ -n "$pids" ] && echo "$port:$(echo "$pids" | tr ' ' ',')" >> "$output_file" && echo "[ACTIVE] Port $port active with PID(s): $pids"

    elif [ "$os_type" = "AIX" ]; then
        # AIX: use netstat + rmsock
        socket_ids=$(netstat -Aan 2>/dev/null | grep "\.${port}" | grep LISTEN | awk '{print $1}')
        pids=""
        for sid in $socket_ids; do
            echo "[DEBUG] Found socket: $sid"
            pid=$(rmsock "$sid" tcpcb 2>/dev/null | awk '/held by proccess/ {print $(NF-1)}')
            if echo "$pid" | grep -qE '^[0-9]+$'; then
                pids="${pids:+$pids }$pid"
            fi
        done
        unique_pids=$(echo "$pids" | tr ' ' '\n' | sort -u)
        if [ -n "$unique_pids" ]; then
           pid_line=$(echo "$unique_pids" | tr '\n' ',' | sed 's/,$//')
           echo "$port:$pid_line" >> "$output_file"
           echo "[ACTIVE] Port $port active with PID(s): $pid_line"
        fi


    elif command -v ss >/dev/null 2>&1; then
        # Linux fallback: use ss
        pids=$(ss -ltnp 2>/dev/null | grep ":$port " | awk -F 'pid=' '{print $2}' | cut -d',' -f1 | sort -u)
        [ -n "$pids" ] && echo "$port:$(echo "$pids" | tr ' ' ',')" >> "$output_file" && echo "[ACTIVE] Port $port active with PID(s): $pids"

    else
        echo "[WARN] No supported method to check port $port"
    fi
}


for port in $ports; do
    check_port "$port"
done

# üõë Kill processes if any ports are active
if [ -s "$output_file" ]; then
    echo "[NOTICE] Active ports detected. Pausing for 1 minute before cleanup..."
    sleep 60

    while IFS=: read port pids; do
        echo "$pids" | tr ',' '\n' | while read pid; do
            if echo "$pid" | grep -qE '^[0-9]+$'; then
                echo "[ACTION] Killing PID $pid on port $port..."
                kill -9 "$pid" && echo "[SUCCESS] Killed PID $pid" || echo "[ERROR] Failed to kill PID $pid"
            else
                echo "[WARNING] Invalid PID '$pid' for port $port"
            fi
        done
    done < "$output_file"
else
    echo "[INFO] No active ports found. No cleanup needed."
fi

echo "[DONE] Port check and cleanup completed."


cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/$basename_without_tgz/

ls -ltr
jar_file="${basename_without_tgz}.jar"

# -----------------------------------------------
# üßπ Clear IST API log before installation
# -----------------------------------------------

LOGFILE="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/$basename_without_tgz/logs/ist-api-services.log"

echo "[INFO] Preparing to clear IST API log file: $LOGFILE"

if [ -f "$LOGFILE" ]; then
  echo "[INFO] Log file exists. Truncating..."
  : > "$LOGFILE"
  echo "[SUCCESS] Log file cleared: $LOGFILE"
else
  echo "[WARNING] Log file not found: $LOGFILE. Skipping clear step."
fi

pwd
ls -ltr
if [ -n "$jar_file" ]; then
  echo "Running JAR file: $jar_file"
  echo "Changed directory to: $(pwd)"
  #nohup java -jar "$jar_file" &
  nohup java -jar "$jar_file" > nohup.out 2>&1 &
  echo "IST API Server started with nohup."
  #LOGFILE="/apps/eftpos4/harness/dev/apitest/tgz/$basename_without_tgz/logs/ist-api-services.log"
  LOGFILE="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/$basename_without_tgz/logs/ist-api-services.log"
  #LOGFILE="/ist_qa/iswtqa1/harness/dev/api/tgz/$basename_without_tgz/logs/ist-api-services.log"
  echo "istlog file is: $LOGFILE"
  echo "Checking installation status in $LOGFILE..." 
# Retry loop to wait for "TRAFFIC" to appear
  max_attempts=35
  attempt=1
  found=""
  # Give the app time to start writing logs
  sleep 10
  while [ $attempt -le $max_attempts ]; do
    echo "$(date): Attempt $attempt: checking for 'ACCEPTING_TRAFFIC'..."
    found=$(grep -i "ACCEPTING_TRAFFIC" "$LOGFILE" | tail -n 1)
    if [ -n "$found" ]; then
      echo "Matched Line: $found"
      echo "Installation successful"
      echo "Installation successful" > <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/deployment_status.txt
      echo "$found" >> <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/deployment_status.txt
      grep -i "port $apiport" "$LOGFILE" | tail -n 10
      os_type=$(uname)
      if [ "$os_type" = "AIX" ]; then
        port_check=$(netstat -Aan 2>/dev/null | grep "\.${apiport}" | grep LISTEN)
      else
        port_check=$(netstat -tulpn 2>/dev/null | grep ":$apiport")
      fi
      if [ -n "$port_check" ]; then
        echo "‚úÖ Port $apiport is listening"
      else
        echo "‚ùå Port $apiport is NOT listening ‚Äî deployment failed"
        exit 1
      fi
      break
    fi
    sleep 5
    attempt=$((attempt + 1))
  done
  if [ -z "$found" ]; then
      echo "No matching line found after $max_attempts attempts"
      echo "Installation failed"
      echo "Installation failed" > <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/deployment_status.txt
      echo "Reason: 'ACCEPTING_TRAFFIC' not found in log" >> <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/deployment_status.txt
      echo "üîç Showing last 10 lines of the log:"
      #tail -n 10 "$LOGFILE"
      grep -i "port $apiport" "$LOGFILE" | tail -n 10
      exit 1
  fi
else
  echo "No JAR file found"
  exit 1
fi

EOF

deployment_status=$(cat <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/deployment_status.txt)
echo "deployment_status: $deployment_status"

# Capture the exit status of the dzdo su - strauss1 command
EXIT_STATUS=$?

# Check if the command inside the su block failed
if [ $EXIT_STATUS -ne 0 ]; then
  echo "The script inside the $selected_user block failed. Exiting with status $EXIT_STATUS."
  exit $EXIT_STATUS
fi


-----------------------------wso2----------------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"
server_name="<+pipeline.variables.TARGET_SERVER>"


# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

eval "$switch_cmd" << 'EOF'

echo "Current user: $(whoami)"

selected_user="<+pipeline.variables.USER_ACCOUNT>"
server_name="<+pipeline.variables.TARGET_SERVER>"

# # ============================
# # SET WORK DIR
# # ============================
# if [ "$(uname)" = "Linux" ]; then
#   cd /apps/eftpos4/harness/dev/wso2apitest/wso2am-4.5.0/bin || { echo "Failed to enter Linux bin directory"; exit 1; }
# else
#   cd /ist_dev/iclrqa04/harness/dev/wso2/wso2am-4.5.0/bin || { echo "Failed to enter AIX bin directory"; exit 1; }
# fi

cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.wso2_path>


# ============================
# JAVA ENV
# ============================
export JAVA_HOME="<+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.JAVA_HOME>"
export PATH=$JAVA_HOME/bin:$PATH
echo "JAVA_HOME is set to: $JAVA_HOME"

chmod +x api-manager.sh
sleep 5

PORT="<+pipeline.variables.wso2_port>"
MAX_ATTEMPTS=30
SLEEP_INTERVAL=5
pid=""

echo "[INFO] Checking if port $PORT is active..."

# Detect if port is active
if [ "$(uname)" = "AIX" ]; then
  pid=$(netstat -Aan | grep LISTEN | grep "\.$PORT " | awk '{print $NF}')
else
  pid=$(netstat -tulnp 2>/dev/null | grep ":$PORT" | awk '{print $7}' | cut -d'/' -f1)
fi

# ============================
# START WSO2 IF NOT ACTIVE
# ============================
if [ -n "$pid" ]; then
  echo "[INFO] Port $PORT already active. PID: $pid"
else
  echo "[INFO] Starting WSO2 API Manager..."
  ./api-manager.sh start || { echo "Failed to start API Manager"; exit 1; }

  echo "[INFO] Waiting for port to become active..."
  for attempt in $(seq 1 $MAX_ATTEMPTS); do
    if [ "$(uname)" = "AIX" ]; then
      pid=$(netstat -Aan | grep LISTEN | grep "\.$PORT " | awk '{print $NF}')
    else
      pid=$(netstat -tulnp 2>/dev/null | grep ":$PORT" | awk '{print $7}' | cut -d'/' -f1)
    fi

    if [ -n "$pid" ]; then
      echo "[SUCCESS] Port $PORT is active. PID: $pid"
      break
    fi

    echo "[Attempt $attempt] Waiting..."
    sleep $SLEEP_INTERVAL
  done
fi

# ============================
# ENDPOINT CHECKS
# ============================
echo "Validating Devportal..."
for i in {1..10}; do
  devportal_status=$(curl -k -L -s -o /dev/null -w "%{http_code}" "https://<+pipeline.variables.api_switch_link_host>:$PORT/devportal")
  [ "$devportal_status" -eq 200 ] && break
  sleep 5
done

echo "Validating Publisher..."
for i in {1..10}; do
  publisher_status=$(curl -k -L -s -o /dev/null -w "%{http_code}" "https://<+pipeline.variables.api_switch_link_host>:$PORT/publisher")
  [ "$publisher_status" -eq 200 ] && break
  sleep 5
done

echo "Devportal: $devportal_status"
echo "Publisher: $publisher_status"

if [ "$devportal_status" -ne 200 ] || [ "$publisher_status" -ne 200 ]; then
  echo "Endpoint validation failed."
  exit 1
fi

---------------------------accesstoken fetch - bash-----------------

#!/bin/bash

product_name="<+pipeline.variables.PRODUCT_NAME>"
echo "product_name is $product_name"
device="123"   # FIX: set required device value

echo "Requesting access token from WSO2..."

token_url="https://<+pipeline.variables.api_switch_link_host>:<+pipeline.variables.wso2_port>/oauth2/token"

# Build scope based on product
if [ "$product_name" = "switch" ]; then
  scope="device_${device} isttransactions merchants exptransaction key_managements openid"
elif [ "$product_name" = "clearing" ]; then
  scope="device_${device} clearing openid"
elif [ "$product_name" = "mas" ]; then
  scope="device_$device masmerchants clearing openid"
else
  echo "Unsupported product_name: $product_name"
  exit 1
fi

post_data="grant_type=password&username=admin&password=admin&scope=${scope}"
auth_header="Authorization: Basic <+pipeline.variables.bearer_token>"

echo "Token URL: $token_url"
echo "POST Data: $post_data"
echo "Auth Header: $auth_header"

echo "Executing curl..."
token_response=$(curl -k -s -X POST "$token_url" -d "$post_data" -H "$auth_header")

echo "üì® Raw response from WSO2 (unmasked):"
echo "----------------------------------------"
echo "$token_response"
echo "----------------------------------------"

access_token=$(echo "$token_response" | sed 's/.*"access_token"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/')

echo "üîç Extracted access token (unmasked):"
echo "$access_token"

if [ -n "$access_token" ] && [ "$access_token" != "$token_response" ]; then
  echo "‚úÖ Access token retrieved successfully."
  export WSO2_ACCESS_TOKEN_RAW="$access_token"
  echo "üßæ WSO2_ACCESS_TOKEN_RAW=$WSO2_ACCESS_TOKEN_RAW"
else
  echo "‚ùå Failed to retrieve access token. Full response:"
  echo "$token_response"
  exit 1
fi

------------------------------------------transaction-------------------

#!/bin/sh

selected_user="<+pipeline.variables.USER_ACCOUNT>"

# Determine the switch command based on OS
if [ "$(uname)" = "Linux" ]; then
  switch_cmd="dzdo su - $selected_user"
else
  switch_cmd="su $selected_user -s /bin/sh"
fi

# Use eval with a quoted command and unquoted here-document
eval "$switch_cmd" << 'EOF'

cd <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>
#cd /apps/eftpos4/harness/dev/apitest/tgz
#cd /ist_qa/iswtqa1/harness/dev/api/tgz


echo "Current user: $(whoami)"



# Step 6: Send the payload via curl
basename_without_tgz="<+pipeline.stages.Dowload_Artifacts.spec.execution.steps.Download_Artifacts_0.output.outputVariables.basename_without_tgz>"
product_name="<+pipeline.variables.PRODUCT_NAME>"
TOKEN="<+pipeline.stages.WS02_installation.spec.execution.steps.accesstoken_0.output.outputVariables.WSO2_ACCESS_TOKEN_RAW>"
# Step 1: Generate UUID, trace, and refnum
# Detect platform
if [ "$(uname)" = "Linux" ]; then
  uuid=$(uuidgen)
else
  uuid=$(python3 -c "import uuid; print(uuid.uuid4())")
fi

echo "Generated UUID: $uuid"

trace=$(awk -v min=1 -v max=999999 'BEGIN{srand(); print int(min+rand()*(max-min+1))}')
refnum="123456$trace"

echo "UUID: $uuid"
echo "Trace: $trace"
echo "Refnum: $refnum"

msgId='11'$uuid
echo $msgId


# Step 2: Inject JSON from Harness expression into a file
cat > transaction.json <<INNER_EOF
<+pipeline.stages.transaction.spec.configFiles.apitransaction.gitFiles[0].fileContent>
INNER_EOF

# Step 3: Confirm the file was written
echo "----- RAW JSON -----"
cat transaction.json
echo "---------------------"

# Step 4: Substitute variables into the JSON
export trace refnum

# Ensure we're in a writable directory
if [ ! -w "$(pwd)" ]; then
  echo "‚ùå Current directory is not writable. Switching to /tmp"
  cd /tmp
fi

# Perform substitution
if command -v envsubst >/dev/null 2>&1; then
  envsubst < transaction.json > final_payload.json
else
  sed "s|\${trace}|$trace|g; s|\${refnum}|$refnum|g" transaction.json > final_payload.json
fi

# Step 5: Confirm final payload
echo "----- FINAL PAYLOAD -----"
cat final_payload.json
echo "--------------------------"

# Create temp file for body
body_file=$(mktemp)

if [ -z "$TOKEN" ]; then
  echo "‚ùå Token is empty. Aborting."
  exit 1
fi


# # Capture status code separately and ensure it's only 3 digits
# http_status=$(curl -k -v -o "$body_file" -w "%{http_code}" -X POST "https://<+pipeline.variables.api_switch_link_host>:<+pipeline.variables.gateway_port>/<+pipeline.variables.contextpath>/authorizations" \
#   -H "accept: application/json" \
#   -H "uuid: $uuid" \
#   -H "msg-id: $msgId" \
#   -H "Content-Type: application/json" \
#   -H "Authorization: Bearer $TOKEN" \
#   --data @final_payload.json)



# Decide which curl to run based on product_name
if [ "$product_name" = "switch" ]; then
  echo "Running curl for product: switch"
  http_status=$(curl -k -v -o "$body_file" -w "%{http_code}" -X POST \
    "https://<+pipeline.variables.api_switch_link_host>:<+pipeline.variables.gateway_port>/<+pipeline.variables.contextpath>/authorizations" \
    -H "accept: application/json" \
    -H "uuid: $uuid" \
    -H "msg-id: $msgId" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $TOKEN" \
    --data @final_payload.json)
elif [ "$product_name" = "clearing" ]; then
  echo "Running curl for product: $product_name"
  http_status=$(curl -k -v -o "$body_file" -w "%{http_code}" -X GET \
    "https://<+pipeline.variables.api_switch_link_host>:<+pipeline.variables.gateway_port>/<+pipeline.variables.contextpath>" \
    -H "accept: application/json" \
    -H "uuid: $uuid" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $TOKEN")
elif [ "$product_name" = "mas" ]; then
  echo "Running curl for product: $product_name"
  http_status=$(curl -k -v -o "$body_file" -w "%{http_code}" -X GET \
    "https://<+pipeline.variables.api_switch_link_host>:<+pipeline.variables.gateway_port>/<+pipeline.variables.contextpath>" \
    -H "accept: application/json" \
    -H "uuid: $uuid" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $TOKEN")
else
  echo "‚ùå Unsupported product_name: $product_name"
  exit 1
fi



# Trim to first 3 digits in case of malformed output
http_status=$(echo "$http_status" | cut -c1-3)

# Display response
echo "Response Body:"
cat "$body_file"
echo "HTTP Status Code: $http_status"

# # Extract responseCode and responseMessage (portable)
# response_code=$(sed -n 's/.*"responseCode":\([0-9]*\).*/\1/p' "$body_file")
# response_message=$(sed -n 's/.*"responseMessage":"\([^"]*\)".*/\1/p' "$body_file")

# Extract responseCode (numeric) and responseMessage (string) using sed
response_code=$(sed -n 's/.*"responseCode":[[:space:]]*\([0-9][0-9]*\).*/\1/p' "$body_file")
response_message=$(sed -n 's/.*"responseMessage":[[:space:]]*"\([^"]*\)".*/\1/p' "$body_file")




# Print extracted values
echo "Extracted Response Code: $response_code"
echo "Extracted Response Message: $response_message"

# # Export to output file for pipeline use
# echo "responseCode=$response_code" > response_output.txt
# echo "responseMessage=$response_message" >> response_output.txt


echo "$response_code" > response_output.txt
echo "$response_message" >> response_output.txt
echo "$http_status" >> response_output.txt

# # Export variables in key=value format so Harness captures them
# echo "responseCode=$response_code"
# echo "responseMessage=$response_message"


# Check status code
if [ "$http_status" = "200" ]; then
  echo "‚úÖ Request succeeded"
  exit 0
else
  echo "‚ùå Request failed with status $http_status"
  exit 1  # Exit immediately with failure
fi


EOF



# responseCode=$(cat <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/response_output.txt)
# responseMessage=$(cat <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/response_output.txt)
# httpStatus=$(cat <+pipeline.stages.Set_Up_Environment.spec.execution.steps.Set_up_variables.output.outputVariables.Working_Directory>/response_output.txt)

# --- back in parent shell ---
# Capture exit code of the su block right away
exit_status=$?

# Read back values from response_output.txt safely
responseCode=$(sed -n '1p' response_output.txt)
responseMessage=$(sed -n '2p' response_output.txt)
httpStatus=$(sed -n '3p' response_output.txt)

echo "responseCode: $responseCode"
echo "responseMessage: $responseMessage"
echo "httpStatus: $httpStatus"

# Propagate the exit status from the su block
if [ $exit_status -ne 0 ]; then
  exit $exit_status
fi
















